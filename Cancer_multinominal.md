Proyecto de Clasificaci√≥n de C√°ncer de Mama mediante Predicci√≥n con
Algoritmo Naive Bayes Multinomial y Comparaci√≥n con Algoritmo k-NN
================
Alejandro Figueroa Rojas
29 de Diciembre, 2025

- [Contexto cl√≠nico](#contexto-cl√≠nico)
  - [Motivaci√≥n personal](#motivaci√≥n-personal)
  - [Resumen ejecutivo](#resumen-ejecutivo)
  - [Objetivos del an√°lisis](#objetivos-del-an√°lisis)
  - [Justificaci√≥n metodol√≥gica](#justificaci√≥n-metodol√≥gica)
  - [Estructura del documento](#estructura-del-documento)
- [Fundamentos Te√≥ricos: Naive Bayes
  Multinomial](#fundamentos-te√≥ricos-naive-bayes-multinomial)
  - [Teorema de Bayes](#teorema-de-bayes)
    - [Planteamiento](#planteamiento)
  - [Clasificador Naive Bayes](#clasificador-naive-bayes)
  - [Teorema de Bayes para
    Clasificaci√≥n](#teorema-de-bayes-para-clasificaci√≥n)
  - [Supuesto de Independencia Condicional
    (‚ÄúNaive‚Äù)](#supuesto-de-independencia-condicional-naive)
  - [Naive Bayes Multinomial: Caso
    Aplicado](#naive-bayes-multinomial-caso-aplicado)
    - [Definici√≥n](#definici√≥n)
    - [Aplicaci√≥n al Dataset de C√°ncer de
      Mama](#aplicaci√≥n-al-dataset-de-c√°ncer-de-mama)
  - [Modelo Probabil√≠stico](#modelo-probabil√≠stico)
  - [Estimaci√≥n de Par√°metros](#estimaci√≥n-de-par√°metros)
    - [Definici√≥n de $\theta$](#definici√≥n-de-theta)
    - [M√°xima Verosimilitud (MLE) con Suavizado de
      Laplace](#m√°xima-verosimilitud-mle-con-suavizado-de-laplace)
  - [Regla de Decisi√≥n MAP (Maximum A
    Posteriori)](#regla-de-decisi√≥n-map-maximum-a-posteriori)
  - [Ejemplo Aplicado: Clasificaci√≥n de un
    Tumor](#ejemplo-aplicado-clasificaci√≥n-de-un-tumor)
    - [Criterio de Clasificaci√≥n
      Final](#criterio-de-clasificaci√≥n-final)
  - [‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî](#section)
  - [Algoritmo Naive Bayes Multinomial: Paso a
    Paso](#algoritmo-naive-bayes-multinomial-paso-a-paso)
    - [Fase 1: Entrenamiento](#fase-1-entrenamiento)
    - [Fase 2: Predicci√≥n](#fase-2-predicci√≥n)
  - [Explicaci√≥n del Modelo Naive Bayes Multinomial en
    R](#explicaci√≥n-del-modelo-naive-bayes-multinomial-en-r)
  - [Nota sobre Fronteras de Decisi√≥n en
    Gr√°ficos](#nota-sobre-fronteras-de-decisi√≥n-en-gr√°ficos)
- [Carga de datast](#carga-de-datast)
- [Estructura](#estructura)
- [Preprocesamiento de datos](#preprocesamiento-de-datos)
  - [Limpieza y transformaciones](#limpieza-y-transformaciones)
  - [Verificar valores faltantes o
    √∫nicos](#verificar-valores-faltantes-o-√∫nicos)
  - [Verificaci√≥n de variables](#verificaci√≥n-de-variables)
  - [Ver cu√°ntos niveles tiene cada
    variable](#ver-cu√°ntos-niveles-tiene-cada-variable)
  - [Visualizaci√≥n 3D t-SNE de c√°ncer de
    mama](#visualizaci√≥n-3d-t-sne-de-c√°ncer-de-mama)
  - [Test œá¬≤ de Pearson de Independencia: asociaci√≥n
    predictor-clase](#test-œá¬≤-de-pearson-de-independencia-asociaci√≥n-predictor-clase)
    - [Definici√≥n del marco de hip√≥tesis para el Test
      œá¬≤](#definici√≥n-del-marco-de-hip√≥tesis-para-el-test-œá¬≤)
    - [Pipeline œá¬≤ de selecci√≥n e interpretaci√≥n de variables
      predictivas](#pipeline-œá¬≤-de-selecci√≥n-e-interpretaci√≥n-de-variables-predictivas)
    - [Justificaci√≥n de grados de libertad reducidos en
      Mitoses](#justificaci√≥n-de-grados-de-libertad-reducidos-en-mitoses)
    - [Reporte interpretativo del test
      chi-cuadrado](#reporte-interpretativo-del-test-chi-cuadrado)
    - [Visualizaci√≥n distribuciones
      chi-cuadrado](#visualizaci√≥n-distribuciones-chi-cuadrado)
  - [Detecci√≥n de outliers](#detecci√≥n-de-outliers)
    - [configuracion boxplot outliers](#configuracion-boxplot-outliers)
    - [Boxplot multicapa para estructura de
      outliers](#boxplot-multicapa-para-estructura-de-outliers)
- [Preparaci√≥n de Datos y An√°lisis de
  Predictores](#preparaci√≥n-de-datos-y-an√°lisis-de-predictores)
  - [Separacion train/test](#separacion-traintest)
  - [Verificacion split](#verificacion-split)
  - [Verificacion test tipos](#verificacion-test-tipos)
  - [Verificar que sean factores](#verificar-que-sean-factores)
  - [Ranking de importancia de variables v√≠a œá¬≤ en algoritmo Naive Bayes
    Multinomial](#ranking-de-importancia-de-variables-v√≠a-œá¬≤-en-algoritmo-naive-bayes-multinomial)
  - [Correlaci√≥n entre variables
    predictoras](#correlaci√≥n-entre-variables-predictoras)
- [Entrenamiento, Evaluaci√≥n y Diagn√≥stico del
  Modelo](#entrenamiento-evaluaci√≥n-y-diagn√≥stico-del-modelo)
  - [Entrenamiento naive bayes
    multinomial](#entrenamiento-naive-bayes-multinomial)
  - [Verificaci√≥n de consistencia de
    preprocesamiento](#verificaci√≥n-de-consistencia-de-preprocesamiento)
  - [Comparaci√≥n de fronteras de decisi√≥n: modelo real vs modelo
    suavizado](#comparaci√≥n-de-fronteras-de-decisi√≥n-modelo-real-vs-modelo-suavizado)
    - [Preparaci√≥n de datos y modelos](#preparaci√≥n-de-datos-y-modelos)
    - [Interpretaci√≥n de las diferencias
      observadas](#interpretaci√≥n-de-las-diferencias-observadas)
  - [Verificacion pre evaluacion](#verificacion-pre-evaluacion)
  - [Verificar que los √≠ndices no
    cambiaron](#verificar-que-los-√≠ndices-no-cambiaron)
  - [Matriz de confusi√≥n y m√©tricas ‚Äì test set (9 var
    predictoras)](#matriz-de-confusi√≥n-y-m√©tricas--test-set-9-var-predictoras)
  - [Visualizaci√≥n matriz de
    confusi√≥n](#visualizaci√≥n-matriz-de-confusi√≥n)
  - [Distribuci√≥n de predicciones por
    Clase](#distribuci√≥n-de-predicciones-por-clase)
- [Evaluaci√≥n de Desempe√±o Probabil√≠stico en Test Set: An√°lisis AUC-ROC
  y
  PR-AUC](#evaluaci√≥n-de-desempe√±o-probabil√≠stico-en-test-set-an√°lisis-auc-roc-y-pr-auc)
  - [Preparaci√≥n para c√°lculo de
    AUPRC](#preparaci√≥n-para-c√°lculo-de-auprc)
  - [C√°lculo de AUPRC y preparaci√≥n de curva
    Precision-Recall](#c√°lculo-de-auprc-y-preparaci√≥n-de-curva-precision-recall)
    - [Visualizaci√≥n de curva
      precisi√≥n-sensibilidad](#visualizaci√≥n-de-curva-precisi√≥n-sensibilidad)
  - [Preparaci√≥n de probabilidades para c√°lculo
    AUC-ROC](#preparaci√≥n-de-probabilidades-para-c√°lculo-auc-roc)
  - [C√°lculo de AUC ROC y preparaci√≥n de curva
    ROC](#c√°lculo-de-auc-roc-y-preparaci√≥n-de-curva-roc)
    - [Visualizaci√≥n de curva ROC](#visualizaci√≥n-de-curva-roc)
- [An√°lisis de errores](#an√°lisis-de-errores)
  - [An√°lisis de errores en test set](#an√°lisis-de-errores-en-test-set)
  - [Detalle de analisis errores en test
    set](#detalle-de-analisis-errores-en-test-set)
    - [Resumen estad√≠stico(media) por tipo de error de test
      set](#resumen-estad√≠sticomedia-por-tipo-de-error-de-test-set)
- [Datos nuevos (Validaci√≥n para ambos
  algoritmos)](#datos-nuevos-validaci√≥n-para-ambos-algoritmos)
  - [Matriz de confusi√≥n y m√©tricas: naive bayes multinomial
    (validaci√≥n)](#matriz-de-confusi√≥n-y-m√©tricas-naive-bayes-multinomial-validaci√≥n)
    - [Visualizaci√≥n matriz de confusi√≥n multinominal naive
      bayes(Validaci√≥n)](#visualizaci√≥n-matriz-de-confusi√≥n-multinominal-naive-bayesvalidaci√≥n)
- [Evaluaci√≥n de Desempe√±o Probabil√≠stico en Datos de Validaci√≥n:
  An√°lisis AUC-ROC y
  PR-AUC](#evaluaci√≥n-de-desempe√±o-probabil√≠stico-en-datos-de-validaci√≥n-an√°lisis-auc-roc-y-pr-auc)
  - [C√°lculo AUC ROC y prec√°lculo para curva
    ROC](#c√°lculo-auc-roc-y-prec√°lculo-para-curva-roc)
    - [Visualizaci√≥n Curva ROC - Naive bayes
      multinominal(Validaci√≥n)](#visualizaci√≥n-curva-roc---naive-bayes-multinominalvalidaci√≥n)
  - [C√°lculo PR AUC (Validaci√≥n) y prec√°lculo para curva
    precisi√≥n-recall(Validaci√≥n)](#c√°lculo-pr-auc-validaci√≥n-y-prec√°lculo-para-curva-precisi√≥n-recallvalidaci√≥n)
    - [Visualizaci√≥n curva
      precision-recall](#visualizaci√≥n-curva-precision-recall)
- [**Algoritmo k-Nearest Neighbors (k-NN): Fundamentos
  Completos**](#algoritmo-k-nearest-neighbors-k-nn-fundamentos-completos)
  - [M√©tricas de Distancia](#m√©tricas-de-distancia)
  - [Algoritmo k-NN: Paso a Paso](#algoritmo-k-nn-paso-a-paso)
    - [Fase 1: Entrenamiento
      (Memorizaci√≥n)](#fase-1-entrenamiento-memorizaci√≥n)
    - [Fase 2: Predicci√≥n](#fase-2-predicci√≥n-1)
    - [Selecci√≥n del Hiperpar√°metro
      $k$](#selecci√≥n-del-hiperpar√°metro-k)
    - [Complejidad Computacional](#complejidad-computacional)
  - [Preparaci√≥n de datos para k-NN](#preparaci√≥n-de-datos-para-k-nn)
  - [Entrenamiento y Optimizaci√≥n de k-NN con las 9 variables
    predictoras](#entrenamiento-y-optimizaci√≥n-de-k-nn-con-las-9-variables-predictoras)
    - [Pipeline k-NN con 9 Variables: Estandarizaci√≥n, Selecci√≥n de k
      √ìptimo y Evaluaci√≥n en
      Test](#pipeline-k-nn-con-9-variables-estandarizaci√≥n-selecci√≥n-de-k-√≥ptimo-y-evaluaci√≥n-en-test)
    - [Visualizaci√≥n: optimizaci√≥n de k en k-NN mediante validaci√≥n
      cruzada (Accuracy vs
      knn)](#visualizaci√≥n-optimizaci√≥n-de-k-en-k-nn-mediante-validaci√≥n-cruzada-accuracy-vs-knn)
    - [Visualizaci√≥n l√≠nea de decisi√≥n k-NN(variables m√°s d√≠scriminante)
      /train
      set](#visualizaci√≥n-l√≠nea-de-decisi√≥n-k-nnvariables-m√°s-d√≠scriminante-train-set)
  - [Matrix confusion k-NN en el Test
    Set](#matrix-confusion-k-nn-en-el-test-set)
    - [Visualizaci√≥n l√≠nea de decisi√≥n k-NN en Test Set (k √≥ptimo, 9
      variables)](#visualizaci√≥n-l√≠nea-de-decisi√≥n-k-nn-en-test-set-k-√≥ptimo-9-variables)
  - [Optimizaci√≥n y selecci√≥n del hiperpar√°metro k en k-NN - variables
    m√°s
    d√≠scriminantes](#optimizaci√≥n-y-selecci√≥n-del-hiperpar√°metro-k-en-k-nn---variables-m√°s-d√≠scriminantes)
    - [Estandarizaci√≥n de Predictoras para
      k-NN](#estandarizaci√≥n-de-predictoras-para-k-nn)
    - [Selecci√≥n del k √ìptimo mediante Validaci√≥n Cruzada
      (10-fold)](#selecci√≥n-del-k-√≥ptimo-mediante-validaci√≥n-cruzada-10-fold)
  - [Evaluaci√≥n comparativa de k-NN mediante matrices de Confusi√≥n (k
    √≥ptimo vs k cl√≠nicamente
    estable)](#evaluaci√≥n-comparativa-de-k-nn-mediante-matrices-de-confusi√≥n-k-√≥ptimo-vs-k-cl√≠nicamente-estable)
    - [Comparaci√≥n visual k-NN: k √≥ptimo CV vs k seleccionado
      cl√≠nicamente](#comparaci√≥n-visual-k-nn-k-√≥ptimo-cv-vs-k-seleccionado-cl√≠nicamente)
    - [Visualizaci√≥n l√≠nea de decisi√≥n con k=5 y gradiente de
      confianza - Train
      Set](#visualizaci√≥n-l√≠nea-de-decisi√≥n-con-k5-y-gradiente-de-confianza---train-set)
  - [**Evaluaci√≥n de k-NN en Test
    Set**](#evaluaci√≥n-de-k-nn-en-test-set)
    - [Visualizaci√≥n l√≠nea de decisi√≥n k-NN en test
      set](#visualizaci√≥n-l√≠nea-de-decisi√≥n-k-nn-en-test-set)
  - [Evaluaci√≥n de rendimiento de k-NN por tipo de distancia (Euclidiana
    vs
    Manhattan)](#evaluaci√≥n-de-rendimiento-de-k-nn-por-tipo-de-distancia-euclidiana-vs-manhattan)
    - [Visualizaci√≥n l√≠nea de decisi√≥n k-NN con gradiente (k=17, Test
      Set)](#visualizaci√≥n-l√≠nea-de-decisi√≥n-k-nn-con-gradiente-k17-test-set)
  - [Comparaci√≥n matrices de confusi√≥n con k(1,5,19) en el mismo test
    set
    (n=204)](#comparaci√≥n-matrices-de-confusi√≥n-con-k1519-en-el-mismo-test-set-n204)
    - [Reporte comparativo de m√©tricas k-NN en Test
      Set](#reporte-comparativo-de-m√©tricas-k-nn-en-test-set)
  - [**Comparaci√≥n Final: naive bayes multinominal vs k-NN (9 variables,
    mismo test set
    n=204)**](#comparaci√≥n-final-naive-bayes-multinominal-vs-k-nn-9-variables-mismo-test-set-n204)
  - [Veredicto comparativo Final: NB MUltinomial vs k-NN
    Manhattan](#veredicto-comparativo-final-nb-multinomial-vs-k-nn-manhattan)
- [Conclusi√≥n final: selecci√≥n del modelo
  √≥ptimo](#conclusi√≥n-final-selecci√≥n-del-modelo-√≥ptimo)
  - [Radar de m√©tricas escaladas para comparaci√≥n NBM vs
    KNN](#radar-de-m√©tricas-escaladas-para-comparaci√≥n-nbm-vs-knn)
- [An√°lisis comparativo de rendimiento de ambos algortimos a nivel de
  observaciones individuales, identificando patrones de error y zonas de
  discrepancia
  diagn√≥stica.](#an√°lisis-comparativo-de-rendimiento-de-ambos-algortimos-a-nivel-de-observaciones-individuales-identificando-patrones-de-error-y-zonas-de-discrepancia-diagn√≥stica)
  - [Preparaci√≥n de datos para comparaci√≥n
    visual](#preparaci√≥n-de-datos-para-comparaci√≥n-visual)
  - [Matrices de Confusi√≥n
    Comparativas](#matrices-de-confusi√≥n-comparativas)
  - [Comparaci√≥n de M√©tricas de
    Rendimiento](#comparaci√≥n-de-m√©tricas-de-rendimiento)
  - [Mapa de Aciertos y Errores por
    Caso](#mapa-de-aciertos-y-errores-por-caso)
  - [An√°lisis de Discrepancias entre
    Algoritmos](#an√°lisis-de-discrepancias-entre-algoritmos)
    - [=== Casos con predicciones diferentes
      ===](#-casos-con-predicciones-diferentes-)
    - [üèÜ Resultado Final](#trophy-resultado-final)
  - [Resumen Ejecutivo de la Comparaci√≥n
    Visual](#resumen-ejecutivo-de-la-comparaci√≥n-visual)
- [Conclusi√≥n Final: Selecci√≥n del Modelo
  √ìptimo](#conclusi√≥n-final-selecci√≥n-del-modelo-√≥ptimo-1)
- [Referencias](#referencias)

# Contexto cl√≠nico

El c√°ncer de mama representa la neoplasia maligna m√°s diagnosticada a
nivel mundial, con aproximadamente 2.3 millones de casos nuevos anuales
(OMS, 2023). La detecci√≥n temprana mediante t√©cnicas de screening
aumenta la supervivencia a 5 a√±os hasta un 99% para tumores localizados,
en comparaci√≥n con un 27% en estadios metast√°sicos (SEER, 2024).

La aspiraci√≥n con aguja fina (FNA) es un procedimiento m√≠nimamente
invasivo que permite obtener c√©lulas mamarias para an√°lisis citol√≥gico.
Sin embargo, la interpretaci√≥n histopatol√≥gica depende de la experiencia
del especialista y presenta una variabilidad interobservador reportada
entre 10‚Äì15% (Elmore et al., 1994).

<img src="Invasive_ductal_carcinoma.jpg" width="88%" style="display: block; margin: auto;" />

<br>

**Carcinoma ductal infiltrante de mama (H&E, 100√ó)**

Microfotograf√≠a histol√≥gica de tejido mamario te√±ida con Hematoxilina y
Eosina (H&E), t√©cnica en la que los n√∫cleos celulares se ti√±en de azul
por la hematoxilina, mientras que el citoplasma y el estroma adoptan
tonos rosados por la eosina.

En la imagen se identifica una proliferaci√≥n de c√©lulas tumorales con
p√©rdida de la arquitectura glandular e invasi√≥n del estroma, hallazgos
t√≠picos de un carcinoma ductal infiltrante con grado moderado de
diferenciaci√≥n. En este tipo de lesiones, las c√©lulas cancerosas
muestran morfolog√≠a m√°s anormal y un crecimiento ligeramente m√°s
acelerado respecto a las c√©lulas normales. Estudios con otras
coloraciones especiales como Mallory, donde el col√°geno del estroma se
ti√±e intensamente de azul y las c√©lulas tumorales adquieren tonos
rojizos confirman la desorganizaci√≥n estructural y la interacci√≥n
tumor-estroma. Este patr√≥n infiltrativo contrasta con el tejido mamario
benigno, que mantiene l√≠mites bien definidos y una organizaci√≥n regular.

En el an√°lisis, los modelos alcanzan 98,04% de precisi√≥n utilizando s√≥lo
nueve variables de citolog√≠a FNA para identificar este tipo de lesiones
con alta confiabilidad.

## Motivaci√≥n personal

Este proyecto nace de un prop√≥sito de aprendizaje profundo: **dominar
cada algoritmo de machine learning comprendiendo sus virtudes y
limitaciones reales**, no solo aplic√°ndolos mec√°nicamente.

**¬øPor qu√© estos dos m√©todos espec√≠ficos?**

Naive Bayes Multinomial y k-NN representan dos filosof√≠as matem√°ticas
fundamentalmente opuestas, lo que los convierte en el laboratorio
perfecto para entender c√≥mo diferentes supuestos afectan el rendimiento:

**Naive Bayes**: Asume independencia condicional (sabiendo que es
falsa), conf√≠a en el teorema de Bayes y, parad√≥jicamente, funciona
extraordinariamente bien. Es la elegancia de la inferencia
probabil√≠stica bajo supuestos ‚Äúingenuos‚Äù.

**k-NN**: No asume nada sobre la distribuci√≥n de los datos. Conf√≠a
√∫nicamente en la geometr√≠a del espacio de caracter√≠sticas y la similitud
local. Es la pureza del razonamiento no param√©trico.

Comparar ambos en el mismo dataset me permite responder: ¬øCu√°ndo un
modelo simple con supuestos fuertes supera a uno libre de supuestos? ¬øY
cu√°ndo ocurre lo contrario?

**¬øPor qu√© c√°ncer de mama?**

Porque la medicina es donde las matem√°ticas trascienden lo abstracto y
salvan vidas. Cada probabilidad posterior de Naive Bayes, cada distancia
euclidiana en k-NN, cada umbral en validaci√≥n cruzada‚Ä¶ no son solo
c√°lculos: son decisiones que impactan el pron√≥stico de una persona real.
Este contexto obliga a evaluar m√°s all√° del accuracy: un falso negativo
(c√°ncer no detectado) tiene un peso √©tico radicalmente distinto a un
falso positivo (biopsia innecesaria). Aprender a equilibrar m√©tricas en
este escenario es formaci√≥n invaluable.

**Filosof√≠a del proyecto:**

Este documento no es solo un an√°lisis de datos. Es un ejercicio de
rigor, de confrontar teor√≠a con evidencia, de defender cada decisi√≥n
metodol√≥gica con fundamentos s√≥lidos. Es mi forma de honrar tanto las
matem√°ticas como la medicina que buscan servir, construyendo intuici√≥n
real sobre cu√°ndo y por qu√© un algoritmo funciona.

*‚ÄúLos modelos no predicen el futuro; revelan la estructura oculta de lo
que ya existe. Entender esa estructura y sus l√≠mites es el verdadero
aprendizaje.‚Äù*

## Resumen ejecutivo

**Resultados en Test Set Independiente (n=204)**

<table class="table table-striped table-condensed table-responsive" style="font-size: 13px; color: black; width: auto !important; margin-left: auto; margin-right: auto;">

<thead>

<tr>

<th style="text-align:left;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

Modelo
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

Accuracy
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

Sens.
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

Spec.
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

FN
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

FP
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

Errores
</th>

</tr>

</thead>

<tbody>

<tr>

<td style="text-align:left;width: 9cm; font-weight: bold;background-color: rgba(242, 242, 242, 255) !important;">

Multinomial NB (9 vars)
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

96.08%
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

94.37%
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

96.99%
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

4
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

4
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

8
</td>

</tr>

<tr>

<td style="text-align:left;width: 9cm; font-weight: bold;background-color: rgba(242, 242, 242, 255) !important;">

k-NN (Manhattan, k=17)
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

98.04%
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

97.18%
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

98.50%
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

2
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

2
</td>

<td style="text-align:center;width: 1.8cm; background-color: rgba(242, 242, 242, 255) !important;">

4
</td>

</tr>

</tbody>

</table>

**Ganador:** k-NN con distancia Manhattan (+1.96 pp accuracy, -3 errores
totales)

- Solo 2 c√°nceres no detectados de 71 (2.82%)
- M√°ximo rendimiento hist√≥rico del proyecto
- Modelo recomendado para implementaci√≥n cl√≠nica

## Objetivos del an√°lisis

Este estudio implementa algoritmos de Machine Learning para clasificar
tumores mamarios en benignos o malignos utilizando el dataset Wisconsin
Breast Cancer (Dr.¬†William H. Wolberg, 1992), que contiene 699
observaciones con 9 variables morfol√≥gicas evaluadas en escala ordinal
1-10.

**Objetivo General:**

Comparar el rendimiento del clasificador **Naive Bayes Multinomial**
frente a **k-Nearest Neighbors (k-NN)** en la predicci√≥n del
diagn√≥stico, evaluando:

- Accuracy, sensibilidad (recall de malignos) y especificidad
- Curvas ROC y Precision-Recall (PR)
- Capacidad de generalizaci√≥n en datos de validaci√≥n independientes

**Objetivos Espec√≠ficos:**

1.  **Validar relevancia estad√≠stica** de las variables predictoras
    mediante test œá¬≤ de independencia
2.  **Cuantificar colinealidad** entre predictores via matriz de
    correlaciones
3.  **Identificar las variables m√°s discriminantes** mediante:
    - Ranking de importancia en Naive Bayes (estad√≠stico œá¬≤)
    - Frontera de decisi√≥n con 2 variables clave (Bare.nuclei +
      Cell.size)
4.  **Visualizar separabilidad de clases** en espacio reducido (t-SNE
    3D)

## Justificaci√≥n metodol√≥gica

**Naive Bayes Multinomial:**

Apropiado para variables categ√≥ricas ordinales (escalas 1-10) que
representan conteos o intensidades discretas. Asume independencia
condicional entre predictores dado el diagn√≥stico, un supuesto ‚Äúnaive‚Äù
que parad√≥jicamente produce resultados competitivos en clasificaci√≥n
m√©dica.

**k-Nearest Neighbors:**

M√©todo no param√©trico que clasifica seg√∫n similitud geom√©trica
(distancia Euclidiana) en el espacio de caracter√≠sticas. No asume
distribuci√≥n subyacente de datos, siendo robusto para patrones no
lineales.

## Estructura del documento

1.  **Preprocesamiento:** Limpieza, transformaci√≥n de variables y
    an√°lisis exploratorio
2.  **An√°lisis estad√≠stico:** Test œá¬≤, correlaciones, detecci√≥n de
    outliers
3.  **Modelado Naive Bayes:** Entrenamiento, validaci√≥n cruzada y
    evaluaci√≥n en test set
4.  **Validaci√≥n con datos nuevos:** Generalizaci√≥n del modelo en
    conjunto independiente
5.  **Comparaci√≥n con k-NN:** Optimizaci√≥n de hiperpar√°metros y m√©tricas
    comparativas
6.  **Conclusiones:** Selecci√≥n del modelo √≥ptimo para screening
    oncol√≥gico

------------------------------------------------------------------------

**Nota t√©cnica:**  
Todos los an√°lisis se realizan en **R 4.5.2** con reproducibilidad
garantizada mediante `set.seed(123)` para todas las particiones y
algoritmos aleatorios.

Paquetes clave utilizados:  
- `mlbench` ‚Äì carga del dataset Wisconsin Breast Cancer  
- `caret` ‚Äì particiones train/test, validaci√≥n cruzada, matrices de
confusi√≥n y entrenamiento supervisado  
- `naivebayes` ‚Äì clasificador **Naive Bayes Multinomial**  
- `kknn` ‚Äì k-Nearest Neighbors con **distancia Manhattan** (modelo
ganador: 98.04% accuracy)  
- `class` ‚Äì implementaci√≥n base de k-NN (complementaria a `kknn`)  
- `pROC` y `PRROC` ‚Äì curvas ROC y Precision-Recall (PR) para evaluaci√≥n
avanzada  
- `dplyr`, `tidyr` ‚Äì manipulaci√≥n y transformaci√≥n de datos  
- `ggplot2`, `plotly`, `Rtsne`, `corrplot`, `kableExtra`, `fmsb` ‚Äì
visualizaciones (t-SNE 3D interactivo, radar chart, tablas est√©ticas,
etc.).

<br>

------------------------------------------------------------------------

# Fundamentos Te√≥ricos: Naive Bayes Multinomial

## Teorema de Bayes

### Planteamiento

$$P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B)}$$

**Componentes:**

- $P(A \mid B)$: **Probabilidad a posteriori** - probabilidad de $A$
  despu√©s de observar $B$
- $P(A)$: **Probabilidad a priori** - conocimiento inicial sobre $A$
- $P(B \mid A)$: **Verosimilitud** - probabilidad de observar $B$ dado
  $A$
- $P(B)$: **Evidencia** - probabilidad marginal, constante de
  normalizaci√≥n

**Interpretaci√≥n:** Permite invertir probabilidades condicionales,
infiriendo causas (diagn√≥stico) a partir de efectos (s√≠ntomas
observados).

------------------------------------------------------------------------

## Clasificador Naive Bayes

**Definici√≥n:**

M√©todo de aprendizaje supervisado que aplica el Teorema de Bayes bajo el
**supuesto de independencia condicional** entre caracter√≠sticas.

**Variantes seg√∫n tipo de datos:**

- **Bernoulli NB**: Variables binarias (0/1)
- **Gaussiano NB**: Variables continuas (distribuci√≥n normal)
- **Multinomial NB**: Variables discretas con conteos/frecuencias

------------------------------------------------------------------------

## Teorema de Bayes para Clasificaci√≥n

Para $K$ clases y vector de caracter√≠sticas
$\mathbf{x} = (x_1, \ldots, x_n)$:

$$P(y \mid \mathbf{x}) = \frac{P(y) \cdot P(\mathbf{x} \mid y)}{\sum_{k=1}^{K} P(y_k) \cdot P(\mathbf{x} \mid y_k)}$$

**Notaci√≥n:**

- $y$: Variable de clase ($y \in \{\text{benign}, \text{malignant}\}$)
- $\mathbf{x}$: Vector de caracter√≠sticas observadas
- $P(y \mid \mathbf{x})$: Probabilidad posterior (lo que queremos
  calcular)
- $P(y)$: Probabilidad a priori de la clase
- $P(\mathbf{x} \mid y)$: Verosimilitud de las caracter√≠sticas dada la
  clase

------------------------------------------------------------------------

## Supuesto de Independencia Condicional (‚ÄúNaive‚Äù)

**Supuesto clave:** Dada la clase $y$, las caracter√≠sticas son
independientes:

$$P(\mathbf{x} \mid y) = P(x_1, \ldots, x_n \mid y) = \prod_{i=1}^{n} P(x_i \mid y)$$

**Implicaci√≥n pr√°ctica:** En lugar de estimar la distribuci√≥n conjunta
$P(\mathbf{x} \mid y)$ (complejidad exponencial), estimamos $n$
distribuciones univariadas.

**En el dataset c√°ncer:** Aunque `Cell.size` y `Cell.shape` est√°n
correlacionadas ($r=0.907$), el algoritmo asume independencia.
Sorprendentemente, esto funciona bien porque solo necesita preservar el
**orden** de las probabilidades posteriores, no sus valores exactos.

------------------------------------------------------------------------

## Naive Bayes Multinomial: Caso Aplicado

### Definici√≥n

**Naive Bayes Multinomial:** Variante para caracter√≠sticas que
representan **conteos** o **frecuencias** de eventos discretos.

Aunque originalmente dise√±ada para bag-of-words en texto (donde $x_i$ =
frecuencia de palabra $i$), se aplica con √©xito a **variables
categ√≥ricas ordinales discretas** trat√°ndolas como conteos en una
distribuci√≥n multinomial.

**Aplicaciones principales del modelo:**

Este enfoque es estad√≠sticamente apropiado en m√∫ltiples dominios donde
las variables son naturalmente discretas, entre ellos la clasificaci√≥n
de textos mediante conteo de palabras, el an√°lisis de variables
ordinales en escalas num√©ricas como las utilizadas en este estudio
(escala 1-10 en citolog√≠a), la evaluaci√≥n de secuencias categ√≥ricas
mediante conteo de s√≠mbolos, y el an√°lisis de opiniones basado en
frecuencia de t√©rminos. En todos estos casos, el modelo multinomial
captura correctamente la naturaleza discreta de los datos sin asumir
distribuciones continuas que no corresponden a la realidad del fen√≥meno
medido.

### Aplicaci√≥n al Dataset de C√°ncer de Mama

**Contexto espec√≠fico de este an√°lisis:**

- **Variables:** 9 caracter√≠sticas citol√≥gicas en escala ordinal 1-10
  - `Cl.thickness`, `Cell.size`, `Cell.shape`, `Marg.adhesion`,
    `Epith.c.size`
  - `Bare.nuclei`, `Bl.cromatin`, `Normal.nucleoli`, `Mitoses`
- **Clases:** 2 categor√≠as mutuamente excluyentes
  - $y_1$: `benign` (benigno)
  - $y_2$: `malignant` (maligno)
- **Tratamiento de datos:** Cada variable ordinal (1-10) se trata como
  una categor√≠a discreta independiente

**¬øPor qu√© Multinomial y no Gaussiano?**

Las variables NO son continuas, son evaluaciones subjetivas discretas
del pat√≥logo en escala 1-10. Un valor de 5 no es ‚Äú5.0 unidades medidas‚Äù,
sino ‚Äúnivel 5 en escala ordinal‚Äù. Por tanto, el modelo multinomial es
estad√≠sticamente apropiado.

------------------------------------------------------------------------

## Modelo Probabil√≠stico

Para un vector de observaciones $\mathbf{x} = (x_1, \ldots, x_9)$ donde
cada $x_i \in \{1, 2, \ldots, 10\}$:

$$P(\mathbf{x} \mid y) = P(n) \cdot \frac{n!}{\prod_{i=1}^{9} x_i!} \prod_{i=1}^{9} \theta_{yi}^{x_i}$$

**Componentes:**

- $\mathbf{x}$: vector de valores ordinales (ej: `Cell.size=7`,
  `Bare.nuclei=10`, etc.)
- $\theta_{yi}$: probabilidad de que la caracter√≠stica $i$ tome su valor
  observado en la clase $y$
  - Sub√≠ndice $y$: clase (benign/malignant)
  - Sub√≠ndice $i$: n√∫mero de caracter√≠stica (1 a 9)
- $\theta_{yi}^{x_i}$: contribuci√≥n de caracter√≠stica $i$ elevada a su
  valor observado

**Simplificaci√≥n pr√°ctica:** El coeficiente multinomial
$\frac{n!}{\prod x_i!}$ es constante para una observaci√≥n dada y se
cancela al comparar clases:

$$P(\mathbf{x} \mid y) \propto \prod_{i=1}^{9} \theta_{yi}^{x_i}$$

------------------------------------------------------------------------

## Estimaci√≥n de Par√°metros

### Definici√≥n de $\theta$

$\boldsymbol{\theta}$: Vector de **todos los par√°metros** del modelo
estimados desde datos de entrenamiento.

En Naive Bayes Multinomial para c√°ncer de mama:

$$\boldsymbol{\theta} = \{P(y), \theta_{y,\text{Cl.thickness}}, \theta_{y,\text{Cell.size}}, \ldots, \theta_{y,\text{Mitoses}}\}$$

### M√°xima Verosimilitud (MLE) con Suavizado de Laplace

**Para probabilidades a priori:**

$$\hat{P}(y) = \frac{n_y}{N}$$

**Ejemplo real (Train Set n=479):**

$$\hat{P}(\text{benign}) = \frac{305}{479} \approx 0.6368$$

$$\hat{P}(\text{malignant}) = \frac{174}{479} \approx 0.3632$$

**Para probabilidades condicionales (con Laplace** $\alpha=1$):

$$\hat{\theta}_{yi} = \frac{N_{yi} + 1}{N_y + 10}$$

Donde:

- $N_{yi}$: conteo de veces que caracter√≠stica $i$ toma su valor en
  clase $y$
- $N_y$: total de observaciones en clase $y$
- $V_i = 10$: n√∫mero de valores posibles (escala 1-10)

**Ejemplo num√©rico concreto:**

Para tumores malignos ($N_{\text{malignant}} = 174$):

- Si `Bare.nuclei=10` aparece 80 veces:

$$\hat{\theta}_{\text{malignant, Bare.nuclei=10}} = \frac{80 + 1}{174 + 10} = \frac{81}{184} \approx 0.440$$

- Si `Bare.nuclei=1` nunca aparece (0 veces):

$$\hat{\theta}_{\text{malignant, Bare.nuclei=1}} = \frac{0 + 1}{184} = \frac{1}{184} \approx 0.0054$$

**Importancia del suavizado:** Sin Laplace, el segundo caso dar√≠a
probabilidad 0, anulando todo el c√°lculo posterior independientemente de
las dem√°s variables.

------------------------------------------------------------------------

## Regla de Decisi√≥n MAP (Maximum A Posteriori)

Para clasificar una nueva observaci√≥n $\mathbf{x}^{\text{new}}$:

$$\hat{y} = \arg\max_{y} \left[ \log \hat{P}(y) + \sum_{i=1}^{9} \log \hat{\theta}_{y, x_i} \right]$$

**Versi√≥n expandida para c√°ncer de mama:**

$$\hat{y} = \underset{y \in \{\text{benign}, \text{malignant}\}}{\operatorname{argmax}} \Bigg[ \log P(y) + \log \theta_{y,\text{Cl.thickness}=x_1} + \log \theta_{y,\text{Cell.size}=x_2} + \cdots + \log \theta_{y,\text{Mitoses}=x_9} \Bigg]$$

**¬øPor qu√© logaritmos?**

1.  Evita underflow num√©rico (productos de 9 probabilidades peque√±as ‚Üí
    0)
2.  Convierte productos en sumas (m√°s eficiente)
3.  Preserva el orden (logaritmo es mon√≥tono creciente)

------------------------------------------------------------------------

## Ejemplo Aplicado: Clasificaci√≥n de un Tumor

**Caso cl√≠nico hipot√©tico:**

Paciente con FNA mostrando:

- `Cl.thickness` = 8
- `Cell.size` = 7
- `Cell.shape` = 7
- `Marg.adhesion` = 5
- `Epith.c.size` = 6
- `Bare.nuclei` = 10
- `Bl.cromatin` = 9
- `Normal.nucleoli` = 8
- `Mitoses` = 3

**Paso 1: Score para ‚Äúbenign‚Äù**

$$\text{score}(\text{benign}) = \log(0.637) + \log \theta_{\text{benign}, \text{Cl.thick}=8} + \log \theta_{\text{benign}, \text{Cell.size}=7} + \ldots$$

Supongamos que al sumar todos los log-t√©rminos obtenemos:

$$\text{score}(\text{benign}) \approx -45.2$$

**Paso 2: Score para ‚Äúmalignant‚Äù**

$$\text{score}(\text{malignant}) = \log(0.363) + \log \theta_{\text{malignant}, \text{Cl.thick}=8} + \log \theta_{\text{malignant}, \text{Cell.size}=7} + \ldots$$

Resultado:

$$\text{score}(\text{malignant}) \approx -12.8$$

**Paso 3: Decisi√≥n MAP**

$$\hat{y} = \arg\max\{-45.2, -12.8\} = \text{malignant}$$

**Clasificaci√≥n:** MALIGNO

**Interpretaci√≥n:** Los valores altos en `Bare.nuclei=10`,
`Cell.size=7`, `Bl.cromatin=9` son mucho m√°s probables en tumores
malignos que benignos, dominando la decisi√≥n final.

### Criterio de Clasificaci√≥n Final

El modelo clasifica una nueva observaci√≥n como **MALIGNO** si y solo si:

$$P(\text{malignant} \mid \mathbf{x}) > P(\text{benign} \mid \mathbf{x})$$

O equivalentemente (dado que las probabilidades suman 1):

$$P(\text{malignant} \mid \mathbf{x}) > 0.5$$

**En t√©rminos del score MAP calculado:**

$$\hat{y} = \begin{cases} 
\text{malignant} & \text{si } \text{score}(\text{malignant}) > \text{score}(\text{benign}) \\
\text{benign} & \text{en caso contrario}
\end{cases}$$

**Aplicaci√≥n al ejemplo anterior:**

- Score(benign) = -45.2
- Score(malignant) = -12.8
- **Comparaci√≥n:** -12.8 \> -45.2 ‚úì
- **Decisi√≥n:** Como
  $\text{score}(\text{malignant}) > \text{score}(\text{benign})$ ‚Üí
  **Clasificaci√≥n final: MALIGNO**

**Nota:** Los scores son logaritmos de probabilidades. Valores menos
negativos (m√°s cercanos a 0) indican mayor probabilidad. En este caso,
-12.8 es mucho mayor que -45.2, indicando que la evidencia citol√≥gica
apunta fuertemente hacia malignidad.

## ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

## Algoritmo Naive Bayes Multinomial: Paso a Paso

### Fase 1: Entrenamiento

**Entrada:** Datos de entrenamiento
$\{(\mathbf{x}^{(1)}, y^{(1)}), \ldots, (\mathbf{x}^{(N)}, y^{(N)})\}$

**Pasos:**

1.  **Calcular probabilidades a priori:**

    Para cada clase $y_k$:

    $$\hat{P}(y_k) = \frac{\text{N√∫mero de casos en clase } y_k}{N}$$

2.  **Contar frecuencias por clase y variable:**

    Para cada clase $y_k$ y cada variable $i$ (ej: `Bare.nuclei`),
    contar cu√°ntas veces aparece cada valor (1-10):

    $$N_{y_k, i, v} = \text{conteo de casos donde variable } i = v \text{ en clase } y_k$$

3.  **Estimar par√°metros con Laplace:**

    $$\hat{\theta}_{y_k, i, v} = \frac{N_{y_k, i, v} + 1}{N_{y_k} + 10}$$

4.  **Almacenar modelo:**

    $$\text{Modelo} = \{\hat{P}(y_k), \{\hat{\theta}_{y_k, i, v}\}_{i=1,\ldots,9; v=1,\ldots,10}\}_{k=1,2}$$

### Fase 2: Predicci√≥n

**Entrada:** Nueva observaci√≥n
$\mathbf{x}^{\text{new}} = (x_1, \ldots, x_9)$

**Pasos:**

1.  **Calcular scores MAP para cada clase:**

    $$\text{score}(y_k) = \log \hat{P}(y_k) + \sum_{i=1}^{9} \log \hat{\theta}_{y_k, i, x_i}$$

2.  **Clasificar:**

    $$\hat{y} = \arg\max_{y_k} \text{score}(y_k)$$

**Salida:** Clase predicha
$\hat{y} \in \{\text{benign}, \text{malignant}\}$

**Complejidad computacional:**

- Entrenamiento: $O(N \cdot n)$ donde $N$ = casos, $n$ = variables
- Predicci√≥n: $O(K \cdot n)$ donde $K$ = clases (2 en este caso)

------------------------------------------------------------------------

## Explicaci√≥n del Modelo Naive Bayes Multinomial en R

Se describe c√≥mo funciona la configuraci√≥n de un modelo Naive Bayes
Multinomial en R. Se basa en c√≥digo que ya fue implementado previamente,
enfoc√°ndose en ayudar a entender qu√© hace cada parte y por qu√© est√°
configurado de esa manera espec√≠fica.

El modelo se crea usando la librer√≠a naivebayes de R, que proporciona
las herramientas necesarias para entrenar clasificadores bayesianos.la
funci√≥n principal que se utiliza es naive_bayes(), la cual entrena el
modelo directamente con los datos de entrenamiento.

La estructura b√°sica utiliza una f√≥rmula donde se especifica que
queremos predecir la variable Class utilizando todas las dem√°s columnas
disponibles en el conjunto de datos de entrenamiento. Esto se expresa
mediante la notaci√≥n est√°ndar de R donde el punto representa ‚Äútodas las
dem√°s variables‚Äù.

Lo verdaderamente cr√≠tico en esta configuraci√≥n son dos par√°metros
espec√≠ficos que determinan c√≥mo funciona internamente el modelo.

El primero es **usekernel**,que se establece en FALSE,Esta decisi√≥n es
fundamental porque al ponerlo en FALSE, estamos forzando al modelo a
trabajar con conteos de frecuencia puros en lugar de asumir
distribuciones continuas gaussianas. Esto transforma el clasificador en
un Naive Bayes Multinomial genuino, que es el enfoque correcto cuando
trabajamos con datos categ√≥ricos o de conteo

El segundo par√°metro crucial es **laplace**, configurado con valor
uno.Este implementa lo que se conoce como suavizado de Laplace, que
a√±ade un pseudo-conteo de uno a cada posible valor de cada
caracter√≠stica.

La raz√≥n para hacer esto es evitar un problema matem√°tico serio: si
durante el entrenamiento nunca observamos cierta combinaci√≥n de
caracter√≠stica y clase, su probabilidad ser√≠a cero, y dado que Naive
Bayes multiplica probabilidades, un solo cero destruir√≠a todo el
c√°lculo. El suavizado previene esto asegurando que ninguna probabilidad
sea exactamente cero.

En esencia, esta configuraci√≥n crea un clasificador que cuenta
frecuencias directamente y est√° protegido contra el problema de
encontrar combinaciones no vistas en datos nuevos.

**Par√°metros cr√≠ticos:**

- `usekernel = FALSE`: Fuerza distribuci√≥n multinomial basada en conteos
  de frecuencia
- `laplace = 1`: A√±ade pseudo-conteo de 1 a cada valor posible (evita
  probabilidades cero)

------------------------------------------------------------------------

## Nota sobre Fronteras de Decisi√≥n en Gr√°ficos

**Pregunta:** ¬øLas probabilidades a priori son iguales en las gr√°ficas
de l√≠nea de decisi√≥n?

**Respuesta:** **NO**, se usan las probabilidades emp√≠ricas del
entrenamiento.

En las visualizaciones de frontera (`Bare.nuclei` vs `Cell.size`), el
modelo usa:

$$P(\text{benign}) \approx 0.637 \quad \text{y} \quad P(\text{malignant}) \approx 0.363$$

Esto afecta la posici√≥n de la frontera: al ser `benign` m√°s frecuente,
la frontera se desplaza ligeramente hacia la regi√≥n maligna, requiriendo
evidencia m√°s fuerte para clasificar como maligno.

Si fueran uniformes ($P = 0.5$ para ambas), la frontera ser√≠a
perfectamente sim√©trica respecto a la diagonal.

**Comprobaci√≥n en el c√≥digo:**

El modelo `modelo_bc` almacena internamente estas probabilidades y las
usa autom√°ticamente al llamar `predict()`. No necesitas especificarlas
manualmente.

# Carga de datast

``` r
library(mlbench)

data(BreastCancer)

bc <- na.omit(BreastCancer)
bc$Class <- as.factor(bc$Class)

names(bc)
```

     [1] "Id"              "Cl.thickness"    "Cell.size"       "Cell.shape"     
     [5] "Marg.adhesion"   "Epith.c.size"    "Bare.nuclei"     "Bl.cromatin"    
     [9] "Normal.nucleoli" "Mitoses"         "Class"          

<br>

**Descripci√≥n de Variables - Dataset Breast Cancer (Wisconsin)**

**Fuente:** Wisconsin Diagnostic Breast Cancer Database (Dr.¬†William H.
Wolberg, 1992)

| Variable | Nombre Espa√±ol | Escala | Descripci√≥n |
|----|----|----|----|
| `Cl.thickness` | Grosor del grupo celular | 1-10 | Espesor de la capa de c√©lulas epiteliales. Tumores malignos presentan m√∫ltiples capas (valor \>3) |
| `Cell.size` | Tama√±o celular | 1-10 | Uniformidad del tama√±o. C√©lulas cancerosas presentan mayor variaci√≥n |
| `Cell.shape` | Forma celular | 1-10 | Uniformidad morfol√≥gica. C√©lulas malignas pierden forma regular |
| `Marg.adhesion` | Adhesi√≥n marginal | 1-10 | Capacidad de adhesi√≥n entre c√©lulas. Menor adhesi√≥n facilita met√°stasis |
| `Epith.c.size` | Tama√±o c√©lula epitelial | 1-10 | Tama√±o del citoplasma. C√©lulas malignas tienen citoplasma aumentado |
| `Bare.nuclei` | N√∫cleos desnudos | 1-10 | Frecuencia de n√∫cleos sin citoplasma. M√°s com√∫n en tumores malignos |
| `Bl.cromatin` | Cromatina blanda | 1-10 | Textura de cromatina nuclear. Cromatina gruesa indica malignidad |
| `Normal.nucleoli` | Nucl√©olos normales | 1-10 | Presencia de nucl√©olos prominentes. Tumores malignos: nucl√©olos grandes y m√∫ltiples |
| `Mitoses` | Mitosis | 1-10 | Frecuencia de divisi√≥n celular. Alta actividad mit√≥tica sugiere c√°ncer |
| `Class` | Clase diagn√≥stica | Factor | **benign** = benigno / **malignant** = maligno |

**Definici√≥n clases**

- Benigno: Indica que el crecimiento celular (tumor o masa) no es
  canceroso. Las c√©lulas no se propagan a otras partes del cuerpo (no
  son invasivas o metast√°sicas), y el pron√≥stico suele ser favorable.

- Maligno: Indica que el crecimiento celular es canceroso. Estas c√©lulas
  tienen la capacidad de invadir tejidos cercanos y propagarse a otras
  partes del cuerpo (met√°stasis), lo que requiere tratamiento.

**Nota cl√≠nica:** Todas las variables (excepto `Class`) son evaluaciones
microsc√≥picas subjetivas realizadas por pat√≥logos mediante aspiraci√≥n
con aguja fina (FNA).

# Estructura

    'data.frame':   683 obs. of  11 variables:
     $ Id             : chr  "1000025" "1002945" "1015425" "1016277" ...
     $ Cl.thickness   : Ord.factor w/ 10 levels "1"<"2"<"3"<"4"<..: 5 5 3 6 4 8 1 2 2 4 ...
     $ Cell.size      : Ord.factor w/ 10 levels "1"<"2"<"3"<"4"<..: 1 4 1 8 1 10 1 1 1 2 ...
     $ Cell.shape     : Ord.factor w/ 10 levels "1"<"2"<"3"<"4"<..: 1 4 1 8 1 10 1 2 1 1 ...
     $ Marg.adhesion  : Ord.factor w/ 10 levels "1"<"2"<"3"<"4"<..: 1 5 1 1 3 8 1 1 1 1 ...
     $ Epith.c.size   : Ord.factor w/ 10 levels "1"<"2"<"3"<"4"<..: 2 7 2 3 2 7 2 2 2 2 ...
     $ Bare.nuclei    : Factor w/ 10 levels "1","2","3","4",..: 1 10 2 4 1 10 10 1 1 1 ...
     $ Bl.cromatin    : Factor w/ 10 levels "1","2","3","4",..: 3 3 3 3 3 9 3 3 1 2 ...
     $ Normal.nucleoli: Factor w/ 10 levels "1","2","3","4",..: 1 2 1 7 1 7 1 1 1 1 ...
     $ Mitoses        : Factor w/ 9 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 5 1 ...
     $ Class          : Factor w/ 2 levels "benign","malignant": 1 1 1 1 1 2 1 1 1 1 ...
     - attr(*, "na.action")= 'omit' Named int [1:16] 24 41 140 146 159 165 236 250 276 293 ...
      ..- attr(*, "names")= chr [1:16] "24" "41" "140" "146" ...

          Id             Cl.thickness   Cell.size     Cell.shape  Marg.adhesion
     Length:683         1      :139   1      :373   1      :346   1      :393  
     Class :character   5      :128   10     : 67   2      : 58   2      : 58  
     Mode  :character   3      :104   3      : 52   10     : 58   3      : 58  
                        4      : 79   2      : 45   3      : 53   10     : 55  
                        10     : 69   4      : 38   4      : 43   4      : 33  
                        2      : 50   5      : 30   5      : 32   8      : 25  
                        (Other):114   (Other): 78   (Other): 93   (Other): 61  
      Epith.c.size  Bare.nuclei   Bl.cromatin  Normal.nucleoli    Mitoses   
     2      :376   1      :402   3      :161   1      :432     1      :563  
     3      : 71   10     :132   2      :160   10     : 60     2      : 35  
     4      : 48   2      : 30   1      :150   3      : 42     3      : 33  
     1      : 44   5      : 30   7      : 71   2      : 36     10     : 14  
     6      : 40   3      : 28   4      : 39   8      : 23     4      : 12  
     5      : 39   8      : 21   5      : 34   6      : 22     7      :  9  
     (Other): 65   (Other): 40   (Other): 68   (Other): 68     (Other): 17  
           Class    
     benign   :444  
     malignant:239  
                    
                    
                    
                    
                    

<br>

**An√°lisis del resumen de datos (DATASET: BIOPSIA DE C√ÅNCER DE MAMA)**

1.  DIMENSIONES Y TIPO DE DATOS:

- El dataset contiene 683 observaciones (pacientes).
- Las variables est√°n tratadas como factores (categor√≠as), por eso R
  muestra conteos en lugar de medias o medianas.

2.  M√©tricas celulares:

- Cada columna muestra , el valor de la escala (1-10) que es la
  frecuencia de aparici√≥n.

Ejemplos:

- Cell.size: El valor ‚Äò1‚Äô aparece 373 veces. Indica que la mayor√≠a de
  las c√©lulas son de tama√±o normal, sugiriendo una tendencia hacia casos
  benignos.
- Mitoses: El valor ‚Äò1‚Äô (poca divisi√≥n celular) es dominante con 563
  casos, Este es un indicador fuerte de que el tejido no es agresivo en
  su mayor√≠a.

3.  Variable objetivo (Class):

- benign (Benigno): 444 casos (~65%)
- malignant (Maligno): 239 casos (~35%)

**Nota: Existe un desbalanceo de clases, lo cual es normal en datos
m√©dicos,pero debe tenerse en cuenta al entrenar modelos predictivos.**

4.  Hallazgos principales:

- Los datos ya han sido pre-procesados (se eliminaron filas con NAs,
  dejando las 683 observaciones limpias).
- La mayor√≠a de las caracter√≠sticas presentan valores bajos (1, 2 o 3),
  lo que se correlaciona con la mayor cantidad de tumores benignos
  detectados.

# Preprocesamiento de datos

## Limpieza y transformaciones

``` r
# Eliminar columna ID (no es predictiva)
bc <- bc[, -1]

# El dataset ya viene con factores - simplemente asegurar que est√©n ordenados
bc[, 1:9] <- lapply(bc[, 1:9], function(x) {
  if(!is.factor(x)) x <- factor(x, levels = 1:10, ordered = TRUE)
  x })

# Confirmar estructura
str(bc)
```

    'data.frame':   683 obs. of  10 variables:
     $ Cl.thickness   : Ord.factor w/ 10 levels "1"<"2"<"3"<"4"<..: 5 5 3 6 4 8 1 2 2 4 ...
     $ Cell.size      : Ord.factor w/ 10 levels "1"<"2"<"3"<"4"<..: 1 4 1 8 1 10 1 1 1 2 ...
     $ Cell.shape     : Ord.factor w/ 10 levels "1"<"2"<"3"<"4"<..: 1 4 1 8 1 10 1 2 1 1 ...
     $ Marg.adhesion  : Ord.factor w/ 10 levels "1"<"2"<"3"<"4"<..: 1 5 1 1 3 8 1 1 1 1 ...
     $ Epith.c.size   : Ord.factor w/ 10 levels "1"<"2"<"3"<"4"<..: 2 7 2 3 2 7 2 2 2 2 ...
     $ Bare.nuclei    : Factor w/ 10 levels "1","2","3","4",..: 1 10 2 4 1 10 10 1 1 1 ...
     $ Bl.cromatin    : Factor w/ 10 levels "1","2","3","4",..: 3 3 3 3 3 9 3 3 1 2 ...
     $ Normal.nucleoli: Factor w/ 10 levels "1","2","3","4",..: 1 2 1 7 1 7 1 1 1 1 ...
     $ Mitoses        : Factor w/ 9 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 5 1 ...
     $ Class          : Factor w/ 2 levels "benign","malignant": 1 1 1 1 1 2 1 1 1 1 ...

## Verificar valores faltantes o √∫nicos

``` r
faltantes <- colSums(is.na(bc))
hay_faltantes <- any(faltantes > 0)

cat("¬øExisten valores faltantes?:", ifelse(hay_faltantes, "TRUE ‚ö†Ô∏è", "FALSE ‚úÖ"), "\n\n")
```

    ¬øExisten valores faltantes?: FALSE ‚úÖ 

## Verificaci√≥n de variables

    Todas las variables est√°n completas.

## Ver cu√°ntos niveles tiene cada variable

``` r
sapply(bc, function(x) length(unique(x))) 
```

       Cl.thickness       Cell.size      Cell.shape   Marg.adhesion    Epith.c.size 
                 10              10              10              10              10 
        Bare.nuclei     Bl.cromatin Normal.nucleoli         Mitoses           Class 
                 10              10              10               9               2 

Inferencia

Esta respuesta indica la cantidad de valores unicos por variables

## Visualizaci√≥n 3D t-SNE de c√°ncer de mama

**¬øQu√© es t-SNE?**

- t-SNE (t-distributed Stochastic Neighbor Embedding) es un algoritmo de
  reducci√≥n de dimensionalidad no lineal.
- Su objetivo principal es tomar datos muy complejos y con muchas
  variables y proyectarlos en un espacio de 2D o 3D para que podamos
  visualizarlos mejor.
- Lo m√°s importante: preserva las relaciones locales entre los puntos,
  es decir, mantiene juntos a los datos que eran similares en el espacio
  original.
- √ötil para explorar y visualizar datos complejos.

``` r
library(Rtsne)     
library(plotly)

# Crear bc_bin sin tocar bc original
bc_bin <- bc
bc_bin[, 1:9] <- lapply(bc_bin[, 1:9], function(x) as.integer(as.numeric(as.character(x)) >= 5))
bc_bin$Class <- factor(bc$Class, levels = c("benign", "malignant"))

set.seed(42)
tsne <- Rtsne(bc_bin[, -10], 
              dims = 3, perplexity = 30, theta = 0.5, max_iter = 1000,
              check_duplicates = FALSE,verbose = FALSE)

df <- data.frame(tsne$Y, Diagn√≥stico = bc_bin$Class)
names(df)[1:3] <- c("tSNE1", "tSNE2", "tSNE3")

graf_tsne <- plot_ly(df, 
        x = ~tSNE1, y = ~tSNE2, z = ~tSNE3,
        color = ~Diagn√≥stico,
        colors = c("benign" = "#2ecc71", "malignant" = "#f39c12"),
        marker = list(size = 7, opacity = 0.95, line = list(color = "black", width = 0.8)),
        text = ~paste("Clase:", Diagn√≥stico),
        hoverinfo = "text") %>%
  add_markers() %>%
  layout(
    title = "<b>t-SNE 3D ‚Äì C√°ncer de Mama </b><br><sub>Separaci√≥n pr√°cticamente perfecta ‚Üí modelo infalible</sub>",
    scene = list(
      xaxis = list(title = "t-SNE 1", gridcolor = "gray80"),
      yaxis = list(title = "t-SNE 2", gridcolor = "gray80"),
      zaxis = list(title = "t-SNE 3", gridcolor = "gray80"),
      bgcolor = "white",
      camera = list(eye = list(x = 1.8, y = 1.8, z = 1.2))
    ),
    legend = list(title = list(text = "<b>Diagn√≥stico</b>"), bgcolor = "white")
  )

graf_tsne
```

<div class="plotly html-widget html-fill-item" id="htmlwidget-667a7144502575696858" style="width:100%;height:800px;"></div>
<script type="application/json" data-for="htmlwidget-667a7144502575696858">{"x":{"visdat":{"36341a3c7390":["function () ","plotlyVisDat"]},"cur_data":"36341a3c7390","attrs":{"36341a3c7390":{"x":{},"y":{},"z":{},"marker":{"size":7,"opacity":0.94999999999999996,"line":{"color":"black","width":0.80000000000000004}},"text":{},"hoverinfo":"text","color":{},"colors":["#2ecc71","#f39c12"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"<b>t-SNE 3D ‚Äì C√°ncer de Mama <\/b><br><sub>Separaci√≥n pr√°cticamente perfecta ‚Üí modelo infalible<\/sub>","scene":{"xaxis":{"title":"t-SNE 1","gridcolor":"gray80"},"yaxis":{"title":"t-SNE 2","gridcolor":"gray80"},"zaxis":{"title":"t-SNE 3","gridcolor":"gray80"},"bgcolor":"white","camera":{"eye":{"x":1.8,"y":1.8,"z":1.2}}},"legend":{"title":{"text":"<b>Diagn√≥stico<\/b>"},"bgcolor":"white"},"hovermode":"closest","showlegend":true},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":[-5.5432224857507499,-1.654035730208947,4.9301744076602771,-3.9386596217907544,3.7006048984550532,0.96790752182754658,1.008676185187563,2.435591335651246,-0.14452919877212708,3.0191008593424726,-1.1400567167623914,5.636610523766417,2.321807682697457,4.1374776136212246,-6.6882481114264856,2.5717069732755502,0.82151135368729411,0.23551512711170922,-7.33409308095443,3.956863793442797,1.9450762315864765,-0.35050998763390956,3.9906581706166793,1.0422061935310982,2.9243213648803277,-2.8545462794376641,-4.1106839591894593,4.8646841688036018,0.60369080557499089,3.6470050731797228,2.9692823246822293,3.0858004646973867,1.7989813457875914,1.8359606852689312,-6.4338873538433257,3.9488938376915965,2.4532841664368505,0.59984940412273191,-8.5255343346419927,7.6023516049743103,1.2247239478073415,3.9488948346202659,2.6532208481272441,-7.0078654056544973,3.948911390376475,6.0730538114206256,-1.7289566047509712,5.8177736676064278,3.160640377345572,5.4751906720677121,4.1307632282042226,3.3817467097353648,2.0651027487554852,1.8916092318419806,-7.8846129898696748,2.5755287764614851,2.5478101249982763,3.9488962855573555,2.1808384256781266,0.96790752182626993,-7.0507547351908135,3.9140254311882714,1.5483738495818495,3.0970440382272222,1.7780582105089333,1.9976585932264104,1.8186511160278898,1.5468329686885531,-6.9483062276075902,2.4823066820259898,3.8876873318779115,1.5164326787288989,-7.4649135463845875,3.8624254821550186,0.81933284630222758,1.4767832342143383,2.2671619000946599,1.5019847025538795,0.96790752182803197,3.3134958932207099,1.976438182481115,2.2118594362388313,1.0667033289109971,1.8349375347772265,2.0141432797711976,1.0044178713193932,0.95522274160691933,1.7169411790850462,5.9903599970136501,2.4355909178148045,-1.9565787001164581,-0.57236290247893673,1.140866516409299,3.9907716967106026,0.27751532957168468,-3.3953173080716743,6.3541201727360672,1.400692029748859,3.1959968087153992,1.3321402654570955,-7.0492787308078926,2.7204831149122062,1.5187209610431551,-8.0740745172477677,3.1793895834645483,2.4029038882580864,1.6230350453973157,-0.406363205320594,-6.0456822374789008,2.5004759644695382,-2.1588980367447741,2.9720461391818151,-8.9767402259677507,2.2815035076863168,3.4450092258145117,1.1610563675505579,-8.6493334834596549,1.8997491248218763,2.5493472325655051,2.9747794506570879,-7.2527780508008481,1.240814401988461,-1.5525916407980029,-0.54239087431507793,-8.2882492283054034,0.21980037212096937,-5.510736356037091,-4.0176633187137432,0.13899166085367243,1.4259018364424778,3.1137236571174909,-7.513501365479371,0.21980001722484913,-1.6791092132467356,-1.7611259533391208,-2.720634975974626,-0.14936142697204538,3.4652678768946998,-0.68459314565128493,-8.6640178057510582,1.1533226239777057,-5.8418238316042146,1.2335187503161475,3.0347357019499079,0.95181436792683927,2.6369441946967966,2.7928376395660619,3.7875212021439637,1.7649222264829454,2.8899178991151881,2.3491076062452558,-3.7954208742354023,-6.8619727984215322,3.4198024202499293,3.4475310456213735,3.7316443509920201,1.0941037924656611,1.4259216312152903,1.8560356443240302,0.6229354797062342,3.1747353415411643,1.4849982238937851,1.5468407523121852,1.3070307430965773,0.33039453815109665,4.5714589399948506,1.7777643893235551,7.4002895585668744,-7.429779684813294,-5.3712565500428147,2.4618686803274028,0.48218165245396866,-1.796218028638634,4.4740846960367824,3.8430644488353085,7.721861513780266,1.4114238667748173,-7.2480353053249953,5.9141571091268412,-7.9300714114781501,-0.54239087431507793,-5.8705363034882749,4.8344623715053032,4.6241054617412143,4.2314454712843972,6.4759429556844808,3.1202232338902842,-0.82619709891607507,-1.2872922931246233,4.5626306026331225,3.7166911261439002,-0.20468581620148898,-1.2685677897374077,-8.3864762732665827,2.7977988183752029,5.2947607518313653,2.8629023214757834,4.2326915701727632,1.8897649574785365,-7.5228157082564016,-0.49680132728807946,0.62922503083022552,-0.71252196340444751,3.8412142689998503,3.0039612964902904,-9.4427566471242397,1.732840814446827,-8.9227918233812531,3.257927958531345,3.2540717293308719,7.1473131089450401,3.6870294053245436,6.5244679288757883,-0.41538316720311497,7.949784006771873,0.048906232759738079,-0.91249772821822428,0.46879574920481665,-8.4769490363420097,-2.8545462794376641,4.4894756807813154,6.1511553324600161,5.4887361379884441,1.2999247269192549,-1.3680587690162596,0.19791767031972721,-0.17462955254473342,-6.4318379467800417,0.15800647488830954,0.35411547246796599,-5.8034152340699627,1.5468482621717596,5.3837971107657587,5.5947074437998321,-8.0590768019435313,0.93269307970007054,-8.2882709226072464,8.4096441996921119,2.8610023100594169,6.5244679288757883,-7.9832211539319076,-7.1336997356228924,-1.4605015870412832,0.50057103944005255,-3.8620460992505681,3.09853348821296,-8.6623726167477315,-6.4102158393931408,2.852486380558279,7.8601899427012931,-4.6001651328625277,1.4117498245245592,1.0568006240365591,-9.4926974139735218,5.4089425947549081,2.6573010675991635,-7.1939151325242241,-2.9533626219804079,3.7260988554639662,-6.9493661815198386,-8.160552849168182,-7.5749770343241414,0.96790752182365658,-7.3988570819243122,4.3291531998319446,7.883522844292048,4.3090017367482876,4.0719872642364479,-1.8076019571541728,-6.4299731557873203,-6.2973838282192967,2.5275095624837292,-8.7658823914352926,0.9668013428380311,7.5897240372422559,-1.5525916407980029,-6.3619363810049636,-7.2623890482966837,-8.3725869032920297,-7.0837538624846808,-3.1764135538245086,-1.1772344323002495,2.9349889427004872,5.1714351135467762,-1.5990353638635724,1.590087170625786,8.9671775750534941,1.7715567468609814,-1.6190211196060273,1.3183016711803344,-8.1864017276418153,5.6319692660654379,2.2395487369149847,5.1808913785769537,-0.67681543958553236,4.0978234045550836,1.8836143915840768,-7.3367933572188937,0.29597704107990791,7.2351108235215005,-6.3619453006027564,-6.4852881991492408,6.784430102778078,0.044935758799817059,-0.6928070659439618,7.08678619733492,6.1723266694491539,3.8480046956804106,-2.7989289367918997,4.3523570363267741,2.9587956394154786,1.0295313535455017,-8.8977436819673361,-1.0447163777099591,6.0975284315748413,3.4646806372840691,2.6268373201415169,0.63179531593976745,-2.5679390633584203,-7.4882060902740308,-7.6288879814368897,3.7241256180710378,-5.6895946493379927,-8.2874652037463523,4.1783895374608617,-6.7668876139025871,-1.3211619347438466,3.4446494503043619,-6.1731197752149232,-0.25954294303847525,2.2277504484457662,4.944325133427121,2.5706369543498568,6.0504406873738299,0.96790752182760409,-2.7836565906947697,0.21998866765355515,-8.6717996120903429,-9.144794969737772,-0.14452919877212708,-7.59391743277373,-8.0094485962302446,-7.6818873090619482,0.51984270665679044,-1.1675908527443382,5.9473274705180117,5.3680313884031614,2.4187983092518865,3.5097810891002292,6.1050323344335382,-8.3538563888044006,-6.446676659051076,6.9986945904372426,1.1023538559390931,1.4368130378181037,-7.6730999546345373,2.4054966041843504,-4.6001651309728171,2.8767747836378259,-6.21127338919863,-7.9630327724909602,-6.887053742738658,-6.3889334627289456,2.2452963752150845,-9.1898268881809511,1.400692029748859,-6.5098333829395907,1.1784886139128932,5.6920766664666802,-1.4605015870412832,5.7285926129771685,-3.0972332180719859,-5.7678010640545807,6.1027754469683178,2.8115604950612414,7.7814752592476566,2.6962289254532381,-1.6550164186740275,-6.3884419608202085,6.9873214506485324,-4.110795411869268,-7.33476483131391,-1.5604169986744536,-9.2620997708137072,-4.0770730054867057,0.9679075218280685,3.9469357313161622,5.6652603825877259,-9.0962297314638683,-7.8994967540460976,2.7861046543241135,-0.80060036872495632,-0.37715605750042386,3.6750396257776128,-3.1405133700099297,-6.5886490894300485,3.2124036947545296,3.9847547014274021,2.3134724145948558,6.1027754469683178,1.0746012503803843,1.7822084227949766,-1.9024879739084868,4.183593055336873,0.48449719154908116,1.3212965731939648,5.890634503127357,-8.221390379621214,8.4668449267762806,8.322281963914941,4.5419729265249016,-9.1160112285845241,-5.6155152547896376,5.7390689547332823,-1.0830447621338759,-1.3680587690162596,0.019858016354727635,4.5419729265249016,2.6261553519696932,-3.3426228656376602,-7.0255612362386426,0.82607345595352288,-1.9024879739084868,1.8219410335720241,-6.8626429357525014,2.2872577819108866,2.3739333048206728,8.2335432519128346,-7.8691932740601853,6.577000417411039,5.0668430417373767,-7.7229971159963959,2.3739333048206728,6.577000417411039,-1.0830447621338759,5.0668430417373767,1.7751073597978058,2.4566284723296294,2.4355913450156059,1.873578256454828,2.7789439982426312,0.48449719154908116,2.393989849610207,3.9847547014274021],"y":[2.4424496228320027,9.52147035363034,-18.392552507986014,16.372143924750183,-12.37318383711103,0.64498311262553187,-12.306825513445789,-21.098617282469988,-15.758812571231122,-10.561390867666095,-11.224761226663153,-10.034128820656708,-15.739235874314012,-11.070737874175725,3.1694932962944176,-12.533649058524162,-11.81907082757353,-12.346030546346395,3.3518542343697981,-12.851574904145759,-10.960127852555523,-15.885685642030717,-12.551445798396392,-13.541639975959422,-12.153173361776114,-13.629035668017902,4.6106215213218116,-15.334954823478631,-12.434210585355872,-13.651961434962285,-12.977143974909131,-12.474237123936089,-12.282368082789791,-12.830816705277575,3.3241271750146155,-2.8885880563001458,-11.786455673492444,-13.176770213163767,2.0623643678139629,-12.273911756589985,-18.33719289756506,-2.8885381277742641,-12.666480139156201,2.6655922304894974,-2.8887700246172194,-13.770716467536095,-12.300514695628859,-13.734476252357977,-18.20877047273893,-10.172007846944567,-12.554889037389708,-12.059443272057351,-11.596589559581535,-13.437267181732969,-0.4404299006713403,-11.61672372724383,-17.504986395605361,-2.8885344626105884,-12.114284238712212,0.64498311262561148,1.8224419497234452,-11.783109197345103,-13.883622196962742,-12.668731314887021,-12.602187136284849,-11.378517890137338,-13.196277836409344,-3.9618036767036604,3.4762170941544057,-10.832312308347067,-12.175587369574409,-13.169265861819351,1.0532680027187959,-13.352490364500426,-12.710940686684978,-11.041289611743601,-12.050678408685913,-11.405070251007929,0.64498311262666275,-11.490173420449217,-11.901747239828879,-2.4044805252460844,-11.483277317187484,-14.180789850474536,-12.911727107808966,-11.524339962942477,-13.03548067582747,-14.979386173225182,-12.559525119758993,-21.098612102291256,-17.09855503692263,-18.305464195469924,-16.576050828230468,-8.7465057570354272,-17.712389770129626,-11.251601243044194,-11.272946215311674,-16.005264040197243,-13.292117326532985,-12.792442293307227,-0.31681838187797895,-11.062604304773858,-13.242129847957271,1.1523144876120126,-11.96007540687358,-11.044151900244946,-12.094489925582929,12.334783327690024,3.1360238484279992,-13.534933144311021,-16.099457654749052,-13.171707113573511,2.3024253720320025,-13.498372026083194,-12.65314626336553,-11.722612272245417,3.0358216119128554,-12.425579119757591,-13.271628208986106,-14.20261121142196,0.45788699820001755,-11.967677992259393,-14.986049254990528,-15.682322673728249,5.2019525358584735,-4.0103814250132226,1.0343508210550505,-13.213228834628714,-12.53948932009323,2.3433230845132185,-16.529324753143882,1.738652639393788,-4.0103813768920977,-7.9374950755216336,11.19829152604977,-9.5742658554986928,-16.558087553401656,-13.237899696924542,15.537600625334342,1.3402959868466107,-13.994068542712556,0.32086808468680966,-12.553202099009487,-11.230009152368059,-13.594576018625551,-12.516538844412475,-11.567720460754778,-13.167525205380617,-11.659418875126837,-11.545551500765036,-13.053819916690472,11.873850901082646,4.397420826154133,-11.778467244432523,-13.998945817148025,-11.498949780826306,-7.075326264794251,2.3434349843073932,-11.139095396298723,-12.544096963235988,-11.105094369420737,-13.590902211980639,-3.9618052306148916,2.8148862700081159,-8.9598668093049962,-14.223620643036901,-7.7216236633612185,-11.489779184614868,0.35867395165178662,1.6125158510305719,-16.000421303801449,-15.437070921890969,-12.842208368798163,-15.360496232402305,-9.5132886625539435,-12.910062676466652,-16.1615899973655,1.1629006094853278,-9.6716986320523581,-0.26784856286628711,-15.682322673728249,10.911385738571036,-7.3310225776499713,-17.292238956493005,-10.75705302895436,-8.3383745684709059,-10.960981740522449,-17.259638775057546,-14.281434931488846,-13.677833415117854,-14.700669631634067,-13.736214537945182,-10.400141874399564,3.0009581762390694,-8.7885509295779833,-10.923992704664567,-18.002526410864117,-8.3141178097361763,-13.027832355351658,0.67099600433518536,-13.90804122808747,-11.281967217431182,-10.040983275497899,-10.442885160352706,-16.389824861136535,1.720737300324211,-8.6557055137863301,2.4982863729517049,-16.28165138252141,-7.6288030839570826,-9.389968276150606,-7.5728003424695833,-11.241464658605858,-13.089785723719222,-9.4298778445018741,-11.532945869591099,-8.2061113031759909,-9.3704490618529626,2.169582824803963,-13.629035668017902,-15.779383440833959,-17.131251518927041,-7.3791282660097792,-13.161647945626099,-12.467262054928398,-11.036904524921686,-14.685114513223521,0.8225471583714985,-4.0849237779470737,-9.6396333252833912,2.456919951749041,-3.9618040226992943,-14.592914214979746,-12.36319913598536,2.5318905464190564,-14.327127343680294,5.2018879137526941,-13.067253076444649,-8.8442556992537398,-11.241464658605858,-0.082564638416496791,-0.24210685384135838,-14.630930325589253,16.85788291777601,-13.765500680072885,-13.457904415826464,3.0810056937467638,2.4149814815355484,-14.890852652592487,-14.129672268065605,5.7324729251120834,-17.773212633906443,-9.0662120191825508,0.97524758839526626,-16.200836340083487,-12.289604770121381,2.1991985543680168,-16.689143356961985,-16.65719952867947,2.5138563272534165,1.3957795920934581,0.25595787460475,0.64498311420916354,1.3856227711462332,-17.269202403011583,-15.4944967475281,-8.8258632113239042,-12.835802951069976,-16.3629025196974,0.90139276223594167,2.2103738189683582,-18.891229931492401,0.92386931554641827,-14.607501627980342,-13.50046551454489,-14.986049254990528,0.33798509729430065,2.7023709401074245,0.75961330433987151,0.81899890563100752,-11.743858343387432,-11.371834026540188,-14.616524649200212,-16.225502796407863,9.622917480948221,-16.472267661826699,-13.269377086180345,-10.908807064866066,-14.509460949731119,-14.666376731597127,1.9613580037745475,-11.183832254153504,-9.8378381267678279,-7.96488421039634,-14.081986591283087,-13.496801996616341,-15.981360823324522,-0.47806001595519632,-10.6910906072761,-16.421473667393887,1.4723997136667921,2.9959374252251671,-15.480643071205712,-9.7319840906468063,-8.4667173156249156,-10.597465146577344,-8.8160072387811521,-10.020838569011994,-11.627487206092889,-14.354176523561799,-13.878176569246424,-9.0105117412319995,1.6227727243772416,-8.2199610325837771,-15.306060045721773,-9.8838429268531041,-8.6788826052677184,-15.5605740005812,-9.4059733943666295,2.6250389154611868,1.8010033384789419,-12.433024658651442,1.2995217332278859,0.52890780081034927,-9.285875127116789,1.7548337384523545,-10.314827949703854,-13.632467387938604,2.0096739574140208,-10.930630167124967,-14.384624780099426,-9.9586087820867295,-14.515055638461126,-11.48467440490913,0.64498311262716634,-9.338264860002063,-4.0109883798995485,0.082051809778356355,-1.6018382382973286,-15.758812571231122,3.2305760369861853,0.99197310450690601,1.9225408418292915,-9.581422520647001,-9.8557661901186755,-14.591650626716119,-9.3218078647643203,-14.284497740082193,-12.821853315091031,-14.434155076184854,0.27678703475912048,-0.18403300083901819,-14.901867754078719,-17.806237748660028,-8.8252074374400635,3.4773616163688943,-13.500715226314643,5.7324729518160566,-7.2565853288305284,2.247428173589626,3.5709611273487334,1.1700089005967953,1.4054175191566012,-9.2226941914458749,2.5070209036202336,-16.005264040197243,0.96047327224217083,-7.3354467866276023,-9.3501547375707457,-14.630930325589253,-14.669305947674346,-13.999143950003441,0.59136062570351577,-13.130700627087046,-14.314363885717093,-9.5633006048120901,-12.466155329541966,-10.724753776217582,0.069434425929888494,-17.045702224602902,4.6106223685327867,1.1051816598962856,-10.975196483192292,1.5106532941978881,-10.899787946578568,0.64498311420882903,-17.886338800269979,-12.96220944636217,0.76799899765109192,2.8965012620822401,-8.9307605331670583,-8.8879934265081815,-17.690968258734138,-15.732220810237452,-11.440507848663927,1.9786664903437434,-16.347099045498812,-15.376282892267367,-11.701028431461202,-13.130700627087046,-9.8377252447064514,-11.35423021217108,-13.124559134222602,-12.135401972003951,-12.726873201492767,-13.125648318245505,-18.172578967618854,1.2953947726254849,-11.281926159917255,-11.389489389753175,-12.280734322707392,0.40262546838261581,11.099473498465514,-16.374611788926057,-12.307046893397438,-12.467262054928398,-15.385324044940766,-12.280734322707392,-9.8494989656862284,-15.347708452353968,2.0701137291740568,-10.733136608222788,-13.124559134222602,-9.8637947891185966,0.19315479075285166,-13.886963452666215,-11.587189341041404,-15.449061307766614,2.6217550335648188,-13.122497867831042,-11.207639255080885,2.3140905841094961,-11.587189341041404,-13.122497867831042,-12.307046893397438,-11.207639255080885,-14.348450949014552,-13.962343529170225,-21.098616350553911,-13.990120521086364,-14.006473466358225,-12.726873201492767,-13.03591147263139,-15.376282892267367],"z":[-13.844281469692252,-8.5303611807490309,6.2932689180464916,-4.3763362882865273,6.2319716566486107,1.4771976234755939,6.3731813671496544,4.6811770491787206,7.546323243339458,1.3964026384416632,10.643793455795775,12.374856815467746,4.7005606838261338,11.946084550563958,-14.942695608620822,8.1836692595264307,7.2972288377550472,10.339099987314322,-13.025035650224368,6.684485377951022,6.8896005949082566,2.3749611749773512,7.7693086748524243,6.8795658837826998,7.5773205336704601,10.087032245423682,-11.013375856573349,3.1861411792675338,7.0056518646683603,8.0770816905775504,7.0085871956995875,5.9550288830954434,7.9494210351170054,8.0523697700949377,-13.5709646739385,3.9394948154467677,6.8233682693189035,7.3253342745575036,-15.355916204875154,11.632981578586072,6.3664912480303792,3.9395086757475095,6.7600597407776144,-12.344042590313681,3.9394705334598665,10.791727695648945,12.161269952879346,2.0387663162351481,10.508038688718836,6.9477291071457401,7.2423997023385791,8.6333314497803606,5.9742387950221305,6.3215379274498735,-14.024065151036888,7.7628365030549968,4.1678847500434131,3.939505464106801,5.8005563055551379,1.4771976234755035,-13.996811364953013,7.0143653267474013,6.5057545398551326,7.6715866145930933,5.76476732049034,8.6093752444908809,8.8614333389582978,7.7942633602084577,-14.111627356719909,7.4715251276335,8.2210158319636957,5.9373389072415126,-13.723525847184144,7.0286532084535702,8.3109644077264413,7.5250688397081458,8.9250966071119713,6.4780533593136589,1.4771976234756048,8.1912351121451952,7.1704365750452048,4.0997072871915021,6.9059625147023045,6.9372717002392426,7.0079361724584217,7.8503241375543569,6.3846815490819102,1.6418440129950536,3.7212158303163378,4.6811374914892001,8.2029828364258233,7.3565595663971468,5.5168421570424284,3.3074995973034,4.0829054647141021,8.6054972395916209,10.704261032454795,9.2100038695194257,5.9365584094830961,8.8270531772419822,-13.519809418489631,8.198845276406459,7.5407481526995905,-12.98589988867738,6.8758159995671448,6.5069331535484505,8.8461393273685385,-9.1128745239764211,-14.364755926614434,6.1565056903658482,10.354958455196444,8.6536203653804069,-13.038317567655424,7.4514085843341702,8.763409589101018,8.4494933225946252,-13.839378529644353,6.7771409795881787,7.8929071531669885,7.7524091263061408,-14.0958023305088,6.1221236734871818,6.1186495120608173,9.3675412638997706,-10.695092142148487,3.3418220356301127,-14.226091716292501,8.1581298698957205,13.702784690502009,0.4649050824564897,12.629979307505064,-12.491007775415515,3.3418499695544441,8.8098105567379701,-9.204118662579674,10.070968478203358,11.174710007889574,6.3896234609750859,-0.63378552880176398,-13.486359386617064,7.3908652053555048,-14.081764188988569,7.2349975356872802,7.41802220237558,8.069793714065062,5.8250195773248556,8.7060008184074142,8.1769861899436993,7.5431746624367744,6.0143618895106492,5.8110957501847933,-7.5852006287850084,-11.104675419733654,6.2998729672816474,6.9923528928899898,7.6503521497988425,5.4578405560559462,0.46486757227839576,8.0698789059920113,7.8697064522551026,6.8217266619395165,8.3887905613507847,7.7942410333601533,0.16599280999684746,9.6503253891437222,10.134837173167005,11.633735186114222,5.2540644279170667,-15.449664430500199,-13.590809967545006,6.248639762330666,5.9096875704077707,2.6461340394085209,9.0791930051441749,9.3555933819156643,3.1349131502455636,3.2968723658098895,-15.862378214123863,5.5564826654583799,-13.172845220101795,9.3675412638997706,-5.2471642987911045,6.9770309913955035,9.966657826721022,2.7582129654481369,6.6576306014023725,3.9025949350926132,5.7341365722821465,3.6729316841702437,4.413560002156486,1.4567159933382956,1.5955833877635528,12.206181343066444,-14.538926389559066,4.4705910524383778,9.4930121311834572,6.0850896762515188,11.577793367511768,1.4913280076639797,-13.2901389249527,5.2413243928504292,12.075570711531881,6.7398219437947215,10.336794376812438,7.9192230431593842,-13.241065222179902,5.9645614720676043,-14.852805603091552,9.2445193673435195,5.6209267221781536,10.43489101740972,9.5204567457358493,8.2521620754872451,11.467820840225883,8.1040256774393935,1.4869962958981824,10.676856956603423,11.452728092899747,-12.39075795389898,10.087032245423682,7.4443482471567206,4.6603845571513132,9.5375821416644389,10.84507612589417,8.8816939816716776,3.5769330398730261,11.159305241978593,-15.525974520571081,3.3388039242013381,2.5393519009392227,-13.038852084698553,7.7942588543726243,6.2507270123704526,12.47933156865709,-15.178323703794126,3.2599254476952995,-10.695127035995478,8.4820299635242993,6.9624875695392561,8.2521620754872451,-15.031421979862357,-14.638875451180114,8.2492601537339372,-1.8212644281014587,6.1698830937416602,10.80079857027464,-13.031039086307231,-14.611479389172201,10.136793474046723,10.147556728115099,-14.202448516142161,10.643028318791869,4.2032501105008437,-13.880246914687428,6.1013727437521457,3.5787579143233286,-14.784513454191297,5.9024183513090245,6.4131980652810858,-13.692896443552662,-11.901799658235879,-12.501621252910295,1.4771976234938349,-14.581996503584222,3.8655609598401472,5.5091255816714968,7.7597570813857688,13.901810845640812,3.9222630138966097,-12.204043429035616,-13.807142621003182,8.4477457221590591,-15.331584616175586,10.279210985978219,4.9429207695990627,6.1186495120608173,-14.873089035864467,-15.624149124166546,-13.804694819364817,-14.773853934070834,4.1190058760016797,6.5996622703193788,3.7059880878503453,11.619410385940178,-9.6064345552508641,7.3130095780592015,6.2828457593731093,4.0208605976060046,12.473382753205522,4.6923913838710449,-13.733800764725791,1.8350283208772364,5.132838194672825,4.9859148752853741,9.6003156806707501,2.7794555095365472,11.158438274029214,-11.043271588697527,5.02805579728797,10.553694679113228,-13.655567663364669,-12.790035135514275,3.3205526730986681,8.2078791025270998,7.5647849276636094,3.5359203478127927,8.5010546484359022,5.0250520953765125,5.9141679122458761,11.921476163304995,8.4827798836467991,7.1967008817648592,-12.390308628294106,5.9180474620544343,9.6705312166319981,13.323293501230722,10.3023461586026,12.996594883904113,7.6319464259178194,-14.045960413104613,-13.302586339007881,1.2666015426678681,-15.055621256233518,-12.415478923817323,6.2340501390748493,-15.489176637187191,5.0557550588764437,7.5741585715611635,-12.582953842824079,9.410945455720336,11.703735699080895,8.3739872742503429,13.589351861189497,6.4367864281743801,1.4771976234754036,5.548611056902069,3.3422360966039752,-13.384147514894938,-14.047482171339345,7.546323243339458,-15.007563679198691,-14.986984802364791,-15.870037996130133,5.8088666750726938,9.265393022316724,4.7981065699061611,10.358856372290164,7.9077711787263691,12.146497719064762,12.46987284492856,-14.481137073591739,-14.111650119657089,7.1042579220636712,8.2782897044335346,8.624376084139687,-14.308210943219789,3.7061479174585776,-14.202448518037709,7.8343940752283023,-15.483057148980484,-13.547331441806492,-12.731396013345094,-14.642954986986572,2.7279404018668454,-13.925630993357235,9.2100038695194257,-13.601902192594908,9.5571992244173209,3.6876910040805888,8.2492601537339372,8.0714648502172395,4.3407795084339238,-13.121314992414925,9.0503199717032157,7.1040844044600018,5.7026563275653004,9.054457011354982,3.0639805672705429,-13.189323645239007,6.9528127056674771,-11.0133750569403,-11.880337242807768,7.9811007032509931,-14.890186039778174,6.7853349069662912,1.4771976234945448,7.8733047827809184,5.3244018957509311,-12.828368817211164,-12.529824951379123,8.4081477884793312,4.1280686809263418,9.5790916247114666,10.837663158121911,10.716388224194461,-11.938905442513866,2.3497952641957833,5.1057265572470198,13.162092617167326,9.0503199717032157,13.297707935564691,2.3165752136691298,6.9621048119717024,3.8890609460391024,3.8127861644850847,12.453026829639548,8.8349947202513288,-15.722345369691697,7.0199681975436912,9.6269737355440732,10.388716176429329,-14.396046124138872,-5.5055194727945667,8.2037304810299325,5.0287890485416327,8.8816939816716776,4.4506698082969391,10.388716176429329,11.5614877261205,8.0056615077307196,-13.087645375626783,10.491887034827188,6.9621048119717024,9.8682104314009926,-12.623503601010999,8.6897849979483315,10.894102573052093,8.3229460159683075,-13.288804120608773,6.8675654018938568,4.9399900521576088,-11.976095665297132,10.894102573052093,6.8675654018938568,5.0287890485416327,4.9399900521576088,7.5816475852151779,6.8730623850529957,4.6811831486038198,8.2613956932977839,6.3031979928097286,3.8127861644850847,8.9843116969609547,5.1057265572470198],"marker":{"color":"rgba(46,204,113,1)","size":7,"opacity":0.94999999999999996,"line":{"color":"black","width":0.80000000000000004}},"text":["Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign","Clase: benign"],"hoverinfo":["text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text"],"type":"scatter3d","mode":"markers","name":"benign","textfont":{"color":"rgba(46,204,113,1)"},"error_y":{"color":"rgba(46,204,113,1)"},"error_x":{"color":"rgba(46,204,113,1)"},"line":{"color":"rgba(46,204,113,1)"},"frame":null},{"x":[2.0790523678778694,-5.6028967598447474,1.797319290025662,-7.7782091795510038,0.07761431476975153,-0.53084330462208706,-1.3142225470453726,-3.7954208737989434,1.0938205945721178,-1.6740876739778014,-0.40639248425262547,-1.4071064155780868,-2.6970698895036405,1.0939572915957434,-2.9458218409441317,-3.1957959894040617,-3.6597049144786009,-3.4878061419084498,-2.3237740606961763,-9.2720703981612402,-3.7393480724218087,3.3814332782953263,3.0065397683014758,-3.4861752658310459,-3.4870816617950267,-4.0125043416036377,-1.4717392629053074,0.50402278340821316,-1.8236830189973345,-0.68212776168011702,-5.2869368175097211,-7.6572006910722985,-4.5077161461127728,-2.8998214372170867,-0.070333518736826278,-2.6104442844812263,-8.9560038449803798,3.4218449106723714,-1.4323450851364878,0.042436608922524183,4.7201681147350989,-0.57246658685416296,1.4868410854167513,-4.3880864008589375,0.48157258408941789,-4.0129523017403148,0.10260762976112767,-7.6572006910737294,0.07658546503617461,4.7216025819457448,-1.9853227237012385,-0.72647169789821797,-0.31654447335907193,1.0939870112054368,3.7064539525012301,1.094121409559299,0.0058942588858031369,2.3633230554168811,1.275074912978827,-4.38751882613382,0.43457988192764357,-1.1682200941192724,0.042479449141007798,0.66108650409953651,-1.4699527754056119,1.3831192325241126,0.077884542620927949,0.66118714132602385,-1.3137292872441519,0.43994714823774578,-2.8065165360239539,2.2018026054441884,1.0609744386701194,2.1648053618845462,-3.1950374660363643,-2.7906140509268651,2.2401174472024228,1.0610485732257602,4.7202922786589685,2.0290674550114836,0.42540010542699991,2.1063679775213262,0.44001374321784426,2.3460562595610357,1.1952073706690818,2.0301083474989694,-2.0027043137360137,2.0344226145368549,1.3832526821171507,1.8383329157284618,1.3872772095614625,1.6203343885107584,-1.6739133257342267,-1.4903307590769916,0.6598237576328515,0.76650898084369923,1.3825378389412839,-2.1898067732806448,1.3826670380555659,-1.3144681926169333,-2.8565948861631116,1.960151071321611,-1.3008499204753532,-0.57145221484565534,-2.7323203743501976,0.50752232487347404,-0.52760316179931444,2.0249838407438094,-3.7048128787571444,-0.31539788748038067,1.0942288996404834,-0.68431152661483985,-3.4870904912894827,2.1614568288556173,2.0320314810942022,-1.3140573322658351,-0.062861262266394685,-3.0891556700644727,-1.1674866689226597,1.6722799578183607,-3.8267596606818728,-3.7386031140356315,1.6717120410791857,-5.6881078203128661,-1.9913545039532003,0.428828336340358,0.81840479352950568,-2.5551230852400586,2.1462290054863726,0.50752232346617132,-2.3162754648605151,0.4412734973633527,-1.5990784878177202,3.0096128330702063,-0.40640406978330773,-1.5462013216472084,2.0336902088560556,-1.5990765049204396,-3.7953792122839993,-0.33677018635683692,-3.3863580486200928,-0.68377589685116436,2.3225009134070183,0.82232225260973146,-0.84558958179191412,-0.5276031617993554,-3.9419805066580746,0.0027183572229348544,0.81815109631338123,-0.8457507709593225,-1.1706699924570723,0.077614314769374429,0.077115374288358282,-2.3162754648569144,0.42500840061619977,1.532701811202678,0.42882833633626172,4.5902602257200726,-7.94683070724101,3.3835372228168765,-3.5700298471532048,-3.7401477407821555,2.0320680147165087,4.6082831193268294,2.0320681726768579,2.1116866884937977,1.1548729318556841,1.0609749700401807,-2.1921790471910341,3.8718300876996694,-1.6735014162796045,-2.1919825975401133,3.0079554515912448,3.0065390030882249,1.6622319089407966,-3.6383936531159122,1.0610485961635474,-3.5744786157665547,-0.31523145519353096,1.6359663424167594,4.7202292375637578,-3.7048128787589594,1.5930587978642956,-1.5078072974375969,-1.6736666315101896,-2.1914488597961532,1.3824606309463014,3.314623993792408,2.0283194623199652,1.7981878337042962,3.3821566952840949,0.82955108532515176,-8.338685367962162,1.060972358784418,1.6656479298063747,0.50714390755591188,1.3854788418777191,1.3770463200059277,2.0841045004457923,0.822807664890431,2.1620679331501886,-2.316275520433237,1.3828511329921078,1.1562790613942322,1.9622775708705329,-4.5076039495237268,3.1014382267624194,0.74084955177322009,1.6082499416023806,-3.6384195112006052,1.4839714625420695,1.3826670384421686,2.3041692257206461,-2.9453035513969459,3.569738715824482,3.3139147342562558,-1.5990784878175095,2.0841045004482055,-1.546159769497357,-0.5307001988482698,-1.3075255543641251,3.0065393587470548,-0.31539788747798858,-1.6736569959470557,2.0299760595862395,4.7172205543402548,-3.6988609700666006,-1.6736666643792177,0.10380116174528267,2.1604787763085036,-3.6989264288106551,1.9351691661895274,4.4568625293663446,2.0297717576345717,1.3833965114819962,0.077539047250427456,-3.195796243273771,-3.6985181138188437,3.4099008305143688],"y":[20.261815657928853,2.1674375982342582,21.217010679021953,5.3092213288769203,14.092842233737768,9.9888403185918815,18.762808684938204,11.873850900061797,15.105216402528661,22.646138599214275,12.334914163856967,19.255412167217028,12.651944333863396,15.105377840233777,21.849074857265624,19.87753096176419,15.040923966528291,15.061539463962518,13.583823802252581,1.8948754410843438,13.178911613800175,21.504957984751869,18.002320130112892,15.063039954094171,15.062949039211139,5.0817224625028956,8.7404633411250767,12.933832268822018,16.925074419493711,15.537449298358679,10.839007537770373,-0.81274421307682521,11.12559474955836,14.256499794139634,24.259957524449757,12.24979945187618,4.5042676326280686,22.671218867198981,21.20391404457957,4.7675781350697211,20.321926725191375,21.490460848732965,21.222214544700741,12.006045819246706,-0.36321645589945373,5.0802451733370741,24.120964257024855,-0.81274421308390377,14.093785538174435,20.320256949001333,15.692912592223999,15.626226074772314,10.298716453889012,15.105567232356044,17.433866680702785,15.104340040856075,10.636397687485832,21.640047991101941,15.644105717006099,12.006339723101954,20.516123104164969,13.974172360288174,4.7672365265763244,22.682609614984521,8.7401106749100475,17.150636561717445,14.093028535732504,22.682527933563673,18.763067741073087,20.506428259744428,21.944000471586524,22.940496502160176,13.03606227499094,20.980127171447439,19.877624285368,8.8325475804880451,21.695387662697204,13.036211511634392,20.32202786952795,23.333250742544141,20.671251919389107,21.032650541818668,20.505932005895701,21.334461838011453,15.436905585880631,23.339724579592172,18.051542690556001,23.343577706536806,17.14949085938477,21.786809965102172,17.153025899978548,21.426859554127024,22.648715510108605,19.220539064075506,0.82124489192256489,12.904363149339195,17.149016750544828,16.178086773952259,17.150216783271212,18.762726157045613,14.113454697586466,21.646086774722409,12.03465124858786,21.489939452267141,21.724378223988804,21.972850633252712,8.8542063759568439,21.05294896255532,7.8770084165176684,10.298971313636967,15.104325253088668,15.537155885211137,15.062941240244852,14.854708500523378,23.339002949576148,18.762523888535366,11.940886088412809,22.962618970220994,13.975626020794541,10.517298545473142,17.698784136327099,13.180397881196303,10.517063612041804,1.3490358775868332,13.702343450037384,13.087404829797457,11.098770206551341,12.807259190840444,21.833593582774984,21.97285065457849,12.710596171850602,20.50715847189112,9.623062806514989,18.000835258379439,12.334926913356215,17.193341360229166,23.344290886746681,9.6232172838078167,14.724971074818992,17.800633064827775,21.526754281083527,15.53465780560734,21.36382788805988,16.052912770701436,12.448775687668501,8.8542063759573075,20.623957127596302,10.634254700092232,11.098700497206055,12.448903422205168,13.975308528547608,14.092842233734885,13.697592869459289,12.710596172004193,20.669764899976649,-3.9899288262587551,13.087404829814991,20.764576806434032,2.0577559662310634,21.50714070688667,19.934247715193617,13.17932092417005,23.339249088143681,18.715382958421092,23.339246039309838,21.460304442489402,15.528862924363178,13.036062171019594,16.17875150926578,21.453836253291005,22.64577188973097,16.178717231541405,18.002097444378126,18.00228975678824,21.599558758058503,17.563548101790747,13.036211516053452,19.935508424313031,10.299260798433641,21.172215814720804,20.321916716266628,7.8770084168441947,21.034890020211897,22.995625715713981,22.645776807291288,16.179781660846569,17.150454711376536,17.187686353989534,23.334509327157061,21.812371910242152,21.506629935145558,-7.1427342350259506,1.3329663283885447,13.036069754826249,21.695696893259438,21.971812824318096,17.151451973276149,14.670916588062648,12.184073451791262,11.102706802924436,14.856624090658027,12.710596169767415,17.148916081320319,15.52955425169778,21.415605327657151,11.126654613404153,18.333260196358086,15.811254849187225,16.533359673106251,17.564871820276501,21.616024041652441,17.150216788877739,21.58217651755044,21.848969881969769,15.120543020137404,17.187045273243985,9.6230628065114807,12.184073451791672,17.193512878247663,9.9888236779999247,18.779726953549208,18.002321229764508,10.298971313636962,22.645800701676375,23.335095089194802,20.488715618562182,20.526945997299535,22.645776585610143,24.123603072228502,14.855739881050141,20.527612437023823,21.000162795331033,18.779607329996871,23.334525047753555,17.151550346219079,14.092764796977033,19.877532063429346,17.547224597459167,15.145458838664874],"z":[-4.2609949800281459,-14.616360386015511,-5.4011628559439098,-10.472370637955326,-3.6697360895815532,-8.0269687812714796,-3.824456221383318,-7.5852006290475913,-0.16108155111326941,-4.4613975623976776,-9.1127912811339211,-5.4132800171352189,-9.0291099128750822,-0.16081659366156936,-1.5856368431111274,-4.3261968263463588,-3.9890494983523528,-4.2978894300272534,-1.6245232858356204,-14.228494551824513,-5.7902824272788846,-0.35377253696989636,-1.7357229384692421,-4.2966903880414105,-4.2974068122911202,-9.6484826199100038,-6.8238013836867042,-0.85260180993582024,-8.9996527561298496,-0.63579720614018975,-6.3195668480390097,-17.740114578667697,-6.6123517220892172,-7.0175901542724493,-2.3909540419494886,-5.216309776768985,-15.092544746937003,-1.578925183524682,-0.41510835585558953,0.55921688817839588,-4.4569255136212647,-0.059381432313345195,-4.9385504295709142,-5.5609518259582789,1.8004907360462281,-9.6488512537367974,-2.2851427644115714,-17.740114578432401,-3.6708804629104241,-4.45936731643818,-6.6206045464317498,0.0048081081275876576,-8.8872195898414148,-0.160965490181116,-6.5842726705346886,-0.16121330125312566,-2.3017534181461019,-6.518602958718307,-8.8058913731875919,-5.5603691078460891,-2.5508988280018627,-2.0889327159617683,0.5593123174817175,0.43792669435734649,-6.8233127354194405,-7.3422285974900214,-3.6695949325222887,0.43754105530321441,-3.8241254020624722,-2.5588839232279192,-1.3131858985405471,-0.26678864655522322,-1.3026444318037798,-5.047274819456689,-4.3259050172942723,-7.4466724139320224,-4.7567949836151247,-1.302663298247474,-4.4568848467501976,-1.0055969555389135,-6.6284726272413668,-5.1940032703501533,-2.5594271242886197,-4.7887266674363698,-0.34385937706991815,-0.99992053035910988,-2.3332929390725012,-0.99971857939696107,-7.3449369635868056,-4.7602329205308154,-7.3428560162703587,-5.3384162221205305,-4.4612824545786847,-5.18281173441855,1.7742421452540784,-1.3870291657018123,-7.344172828155199,-5.6058917609952701,-7.3423879222427963,-3.8244510195231589,-6.918670298420694,-5.3887382189991744,-5.0449359741737085,-0.061718304105935914,-2.9374424641539343,-0.8028258379727512,-7.0368053215457955,-4.7135708700522487,-9.0752599811117332,-8.8864886508740391,-0.16083376663364887,-0.63384912997994203,-4.2973970792361298,-3.8881836741230318,-1.0018312884580018,-3.8246681104857738,-8.6237063304905792,-3.7770355307988979,-2.0879542721767108,-1.2778995155722424,-5.290650696635641,-5.7929257138462731,-1.2777658890429704,-12.727265104217096,-1.7320927730054474,-9.3554569948866195,-1.9551588494687495,-5.7151181622988911,-5.0385364846500629,-0.80282586796068656,-8.4939451024858528,-2.5580277944458505,-9.6062165002480189,-1.73428825791844,-9.1128339567507428,-8.9547653229107649,-0.99897939548548331,-9.6059568613606245,-5.028311805282125,-7.8897414454490447,-3.2181826086447898,-0.63269500585770044,-5.2278122634834405,0.93888559955547179,-5.0115217490718393,-7.0368053215458337,-3.5155332379770132,-2.3007900474158287,-1.9568217866811783,-5.0116775920379153,-2.0897724316829551,-3.6697360895814435,-3.8430848108217117,-8.4939451026403407,-6.6291312434121208,7.8492278320788627,-9.3554569948822639,-3.8593678533317934,-14.336337380318469,-0.35329366367164949,-2.990476074880565,-5.7938491952901883,-1.0014551775346272,-2.7117104677053212,-1.0014554550584129,-4.5773200116405208,-8.6259723570286209,-1.3026444165918607,-5.6043881344711535,-0.81117789212883618,-4.4603705888275247,-5.6043325799382613,-1.7317359307969922,-1.7357002402402526,-4.6522731253554177,-5.299972493011099,-1.3026632996045298,-2.989568465920363,-8.8858920498047986,-4.7091117044480955,-4.4569379010491614,-9.0752599811119072,-5.0159815080510528,-4.0823824110682505,-4.4607242489830305,-5.604279806344743,-7.3464636279759814,-6.657636043058992,-1.0046461001770162,-5.0908937911024061,-0.35314875669750578,7.3221003730176264,-14.382837080701188,-1.3026553787339186,-5.2320384174026717,-0.80320388021993827,-7.3436774272839491,-8.8192170000526868,-1.2961993073522864,-1.9746559427994252,-3.8847649552061227,-8.4939455776301909,-7.3433166229407858,-8.626750966568391,-4.5096141348094783,-6.6120822982154666,-1.5395327314907419,0.62715747038995939,-6.784381301639014,-5.3007652353135564,-4.9008546248897193,-7.34238792203326,-5.1317718474266867,-1.5857725242611105,-4.0992566635174361,-6.658237670755784,-9.6062165002480899,-1.2961993073528928,-8.954603349334544,-8.0269974873810135,-3.8149896941277239,-1.7357084468697386,-8.8864886508739449,-4.4607239321465793,-1.0042252865123942,-4.5383880852889131,-4.4736223872689491,-4.4607229625252911,-2.283222467342775,-3.8854664441222173,-4.473603820784259,-5.2485133949421163,-2.6839137713093835,-1.0025574155347596,-7.3452006756280426,-3.6697508786432831,-4.326214604868186,-5.4179131294234439,-4.0731418905662506],"marker":{"color":"rgba(243,156,18,1)","size":7,"opacity":0.94999999999999996,"line":{"color":"black","width":0.80000000000000004}},"text":["Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant","Clase: malignant"],"hoverinfo":["text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text"],"type":"scatter3d","mode":"markers","name":"malignant","textfont":{"color":"rgba(243,156,18,1)"},"error_y":{"color":"rgba(243,156,18,1)"},"error_x":{"color":"rgba(243,156,18,1)"},"line":{"color":"rgba(243,156,18,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>

## Test œá¬≤ de Pearson de Independencia: asociaci√≥n predictor-clase

Antes de ajustar cualquier modelo, verificamos si existe asociaci√≥n
estad√≠sticamente significativa entre cada variable citol√≥gica y el
diagn√≥stico de malignidad (Benigno/Maligno).

El test œá¬≤ de Pearson eval√∫a la independencia entre dos variables
categ√≥ricas mediante la comparaci√≥n de las frecuencias observadas frente
a las esperadas bajo la hip√≥tesis nula de independencia. Un **p-valor \<
0.05** rechaza dicha hip√≥tesis e indica que la variable tiene poder
discriminante real para predecir el c√°ncer.

**En t√©rminos simples:** el test œá¬≤ compara lo que ‚Äúdeber√≠a pasar‚Äù si la
variable y el diagn√≥stico fueran independientes, con lo que realmente
observamos en los datos. Cuanto mayor sea la discrepancia, m√°s poder
predictivo tiene la variable.

**Regla de decisi√≥n:**

Si **œá¬≤calculado \> œá¬≤cr√≠tico** ‚Üí se rechaza H‚ÇÄ (la variable S√ç
discrimina entre clases)

Formalmente, el test contrasta la hip√≥tesis nula mediante el
estad√≠stico:

$$
\chi^2 = \sum \frac{(O_{ij} - E_{ij})^2}{E_{ij}}
$$

donde: $O_{ij}$ son las frecuencias observadas y $E_{ij}$ las esperadas
bajo independencia.

**Nota metodol√≥gica:** Los supuestos del test (frecuencias esperadas ‚â• 5
en ‚â• 80% de celdas) se cumplen holgadamente gracias a las 10 categor√≠as
ordenadas de nuestras variables. La ausencia de warnings en R lo
confirma.

### Definici√≥n del marco de hip√≥tesis para el Test œá¬≤


    === Test chi-cuadrado de indepencia ===
    Nivel de significancia (Œ±): 0.05
    Hip√≥tesis Nula (H0): La variable NO est√° asociada con el diagn√≥stico
    Hip√≥tesis Alternativa (Ha): La variable S√ç est√° asociada con el diagn√≥stico
    Regla de decisi√≥n: Si œá¬≤_calc > œá¬≤_cr√≠tico ‚Üí Rechazar H0

### Pipeline œá¬≤ de selecci√≥n e interpretaci√≥n de variables predictivas

``` r
# Configuraci√≥n test
alpha <- 0.05  # Nivel de significancia

# C√°lculo chi-cuadrado por  varaible
chi_results <- lapply(names(bc)[1:9], function(var) {
  tabla <- table(bc[[var]], bc$Class)
  test <- chisq.test(tabla, correct = FALSE)
  
  gl <- test$parameter  # Grados de libertad
  chi2_calc <- test$statistic  # œá¬≤ calculado
  chi2_crit <- qchisq(1 - alpha, gl)  # œá¬≤ cr√≠tico de tabla
  p_val <- test$p.value
  
  # Decisi√≥n estad√≠stica
  if(chi2_calc > chi2_crit) {
    decision <- "Rechaza H0"
    significancia <- "Variable SIGNIFICATIVA (ayuda a predecir)"
  } else {
    decision <- "No rechaza H0"
    significancia <- "Variable NO significativa"
  }
  
  data.frame(
    Variable = var,
    Chi2_Calculado = round(chi2_calc, 2),
    Chi2_Critico = round(chi2_crit, 2),
    gl = gl,
    p_value = ifelse(p_val < 2.2e-16, "< 2.2e-16", 
                     format(p_val, scientific = TRUE, digits = 3)),
    Decision = decision,
    Interpretacion = significancia,
    stringsAsFactors = FALSE
  )
})

df_chi <- do.call(rbind, chi_results)
df_chi <- df_chi[order(df_chi$Chi2_Calculado, decreasing = TRUE), ]
row.names(df_chi) <- NULL

knitr::kable(df_chi,
             col.names = c("Variable", "œá¬≤ Calculado", "œá¬≤ Cr√≠tico", 
                          "g.l.", "p-value", "Decisi√≥n", "Interpretaci√≥n"),
             caption = "Test œá¬≤ de Independencia - Asociaci√≥n con Diagn√≥stico de C√°ncer",
             align = "lccclll")
```

| Variable | œá¬≤ Calculado | œá¬≤ Cr√≠tico | g.l. | p-value | Decisi√≥n | Interpretaci√≥n |
|:---|:--:|:--:|:--:|:---|:---|:---|
| Cell.size | 539.79 | 16.92 | 9 | \< 2.2e-16 | Rechaza H0 | Variable SIGNIFICATIVA (ayuda a predecir) |
| Cell.shape | 523.07 | 16.92 | 9 | \< 2.2e-16 | Rechaza H0 | Variable SIGNIFICATIVA (ayuda a predecir) |
| Bare.nuclei | 489.01 | 16.92 | 9 | \< 2.2e-16 | Rechaza H0 | Variable SIGNIFICATIVA (ayuda a predecir) |
| Bl.cromatin | 453.21 | 16.92 | 9 | \< 2.2e-16 | Rechaza H0 | Variable SIGNIFICATIVA (ayuda a predecir) |
| Epith.c.size | 447.86 | 16.92 | 9 | \< 2.2e-16 | Rechaza H0 | Variable SIGNIFICATIVA (ayuda a predecir) |
| Normal.nucleoli | 416.63 | 16.92 | 9 | \< 2.2e-16 | Rechaza H0 | Variable SIGNIFICATIVA (ayuda a predecir) |
| Marg.adhesion | 390.06 | 16.92 | 9 | \< 2.2e-16 | Rechaza H0 | Variable SIGNIFICATIVA (ayuda a predecir) |
| Cl.thickness | 378.08 | 16.92 | 9 | \< 2.2e-16 | Rechaza H0 | Variable SIGNIFICATIVA (ayuda a predecir) |
| Mitoses | 191.97 | 15.51 | 8 | \< 2.2e-16 | Rechaza H0 | Variable SIGNIFICATIVA (ayuda a predecir) |

Test œá¬≤ de Independencia - Asociaci√≥n con Diagn√≥stico de C√°ncer

### Justificaci√≥n de grados de libertad reducidos en Mitoses

    === Diagn√≥stico Mitoses: Tabla de contingencia y g.l. ===
    Tabla cruzada Mitoses vs Diagn√≥stico:

        
         benign malignant
      1     431       132
      2       8        27
      3       2        31
      4       0        12
      5       1         5
      6       0         3
      7       1         8
      8       1         7
      10      0        14

    Niveles observados en Mitoses: 9
    N√∫mero de clases: 2
    Grados de libertad te√≥ricos: (niveles_con_datos - 1) √ó (clases - 1) = 8
    Nota: Mitoses tiene 8 g.l. porque solo 9 niveles totales, uno sin datos.

### Reporte interpretativo del test chi-cuadrado


    === Test Chi-cuadrado ===

    Hip√≥tesis:
      H‚ÇÄ: Variable independiente del diagn√≥stico (NO discrimina)
      Ha: Variable asociada al diagn√≥stico (S√ç discrimina)

    Regla de desici√≥n: Si œá¬≤calc > œá¬≤crit(Œ±=0.05) ‚Üí Rechazar H‚ÇÄ

    Resultados claves (Top 3):
      ‚Ä¢ Cell.size:   œá¬≤=540.02 (32√ó > cr√≠tico) | p<2.2e-16
      ‚Ä¢ Cell.shape:  œá¬≤=523.21 (31√ó > cr√≠tico) | p<2.2e-16
      ‚Ä¢ Bare.nuclei: œá¬≤=489.32 (29√ó > cr√≠tico) | p<2.2e-16

    Conclusi√≥n:
      Las 9 variables rechazan H‚ÇÄ con evidencia abrumadora.
      Todas son estad√≠sticamente significativas (p<2.2e-16)
      para predecir c√°ncer de mama.

**Descripci√≥n variables top 3 en c√°ncer de mama**

**a) Cell.size (Tama√±o celular)**

Mide la uniformidad del tama√±o de las c√©lulas. En tejidos sanos, las
c√©lulas mantienen tama√±os similares; en c√°ncer, aparece una marcada
variabilidad (anisocitosis), indicador t√≠pico de malignidad.

**b) Cell.shape (Forma celular)**

Eval√∫a la regularidad morfol√≥gica de las c√©lulas. La p√©rdida de forma
uniforme (anisocariosis) es un signo clave de transformaci√≥n maligna,
donde las c√©lulas adoptan contornos irregulares y desorganizados.

**c) Bare.nuclei (N√∫cleos desnudos)**

Corresponde a la presencia de n√∫cleos sin citoplasma visible. Su aumento
se asocia fuertemente a tumores malignos, ya que las c√©lulas cancerosas
suelen perder estructura y cohesi√≥n, dejando el n√∫cleo m√°s expuesto.

### Visualizaci√≥n distribuciones chi-cuadrado

``` r
library(ggplot2)
library(gridExtra)

plots_list <- lapply(1:9, function(i) {
  
  var_name <- df_chi$Variable[i]
  gl <- df_chi$gl[i]
  chi2_crit <- df_chi$Chi2_Critico[i]
  chi2_calc <- df_chi$Chi2_Calculado[i]
  
  x_min <- 0
  x_max <- ifelse(chi2_calc > 300,
                 chi2_calc * 1.05,
                 min(max(chi2_crit * 8, chi2_calc * 1.6), 600))
  x_vals <- seq(x_min, x_max, length.out = 1000)
  y_vals <- dchisq(x_vals, df = gl)
  df_curva <- data.frame(x = x_vals, y = y_vals)
  df_critica <- df_curva[df_curva$x >= chi2_crit, ]
  
  x_flecha <- chi2_crit + (x_max - chi2_crit) * 0.5
  y_flecha <- max(y_vals) * 0.35
  
  ggplot(df_curva, aes(x = x, y = y)) +
    geom_line(color = "#2C3E50", linewidth = 1.8) +  # ‚Üê Aumentado
    geom_area(data = df_critica, fill = "#FF4F00", alpha = 0.9) +
    
    geom_vline(xintercept = chi2_crit, 
               linetype = "dashed", color = "#27ae60", linewidth = 2) +  # ‚Üê Aumentado
    geom_vline(xintercept = pmin(chi2_calc, x_max * 0.95),
               linetype = "solid", color = "#8e44ad", linewidth = 1.8) +  # ‚Üê Aumentado
    
    annotate("segment",
             x = x_flecha * 0.7, xend = chi2_crit + (x_max - chi2_crit) * 0.15,
             y = y_flecha - max(y_vals) * 0.08,yend = max(y_vals) * 0.05,
             arrow = arrow(length = unit(0.3, "cm"), type = "closed"),  # ‚Üê Flecha m√°s grande
             color = "#FF6B35", linewidth = 1.5) +
    
    annotate("text", 
             x = x_flecha * 0.55, y = y_flecha + max(y_vals) * 0.07,
             label = expression(atop("Zona cr√≠tica", paste("(Rechazo ", H[0], ")"))),
             color = "#CC3A00", fontface = "bold", size = 5.9,  # ‚Üê Aumentado de 3.5
             hjust = 0.5) +
    
    annotate("text", 
             x = chi2_crit, y = max(y_vals) * 0.90,
             label = paste0("œá¬≤crit\n", round(chi2_crit, 1)),
             color = "#27ae60",fontface = "bold",size = 5.5,  # ‚Üê Aumentado de 3.8
             hjust = -0.2) +
    
    annotate("text", 
             x = pmin(chi2_calc, x_max * 0.95), 
             y = max(y_vals) * 0.75,label = paste0("œá¬≤calc\n", round(chi2_calc, 0)),
             color = "#8e44ad", fontface = "bold", 
             size = 7,  # ‚Üê Aumentado de 6
             hjust = 1.2) +
    
    annotate("text", 
             x = mean(c(chi2_crit, x_max)), 
             y = max(y_vals) * 0.55,label = paste0("Œ± = ", alpha), color = "#27ae60", 
             fontface = "bold", size = 6.5,  # ‚Üê Aumentado de 5
             angle = 0) +  # ‚Üê Sin √°ngulo para mejor lectura
    
    labs(title = var_name,
         subtitle = paste0("gl = ", gl),
         x = NULL, y = NULL)+
    scale_x_continuous(limits = c(0, x_max), expand = c(0, 0)) +
    theme_minimal(base_size = 18) +  # ‚Üê Aumentado de 22 (coherencia)
    theme(
      strip.text = element_text(face = "bold", size = 12),# agregado linea 
      plot.title = element_text(face = "plain", hjust = 0.5, size = 20,color = "gray20",
                                margin = margin(t = 10, b = 20)),  # ‚Üê Espacio up down agraga line
      plot.subtitle = element_text(hjust = 0.5, size = 16, color = "gray20"),  # ‚Üê 12‚Üí16
      axis.text = element_text(size = 14),  # ‚Üê 8‚Üí14
      panel.grid.minor = element_blank(),
      panel.grid.major = element_line(color = "gray90", linewidth = 0.5),  # ‚Üê M√°s visible
      plot.margin = margin(10, 10,10,10)  # ‚Üê M√°s espacio entre paneles
    )
})

# Grid final # "Zona naranja: Regi√≥n cr√≠tica
grid.arrange(
  grobs = plots_list, ncol = 3,
  top = grid::textGrob(
    "Distribuciones œá¬≤ por Variable - Test de Independencia",
    gp = grid::gpar(fontsize = 22, fontface = "bold", lineheight = 2.0)
  ),
  bottom = grid::textGrob(
    expression("Zona naranja: Regi√≥n cr√≠tica (rechazo " * H[0] * 
               ") | Verde: œá¬≤crit | Morado: œá¬≤calc"),
    gp = grid::gpar(fontsize = 18, col = "gray10")
  ),
  padding = unit(2, "line"))
```

<img src="Cancer_multinominal_files/figure-gfm/plot chi2-1.png" width="100%" style="display: block; margin: auto;" />

<br>

**Interpretaci√≥n de las distribuciones œá¬≤ por variable**

Este panel de 9 gr√°ficos muestra la distribuci√≥n te√≥rica œá¬≤
(chi-cuadrado) para cada variable predictora, permitiendo visualizar el
fundamento estad√≠stico del test de independencia.

**Elementos del gr√°fico:**

- **Curva negra**: Distribuci√≥n te√≥rica œá¬≤ con sus respectivos grados de
  libertad (gl)
- **Zona naranja**: Regi√≥n cr√≠tica donde se rechaza H‚ÇÄ (Œ± = 0.05)
- **L√≠nea verde punteada**: œá¬≤cr√≠tico (umbral de decisi√≥n a partir de
  tablas estad√≠sticas)
- **L√≠nea morada s√≥lida**: œá¬≤calculado (valor observado en los datos)
- **Flecha naranja**: Se√±ala la ubicaci√≥n de la zona cr√≠tica

**C√≥mo interpretar:**

1.  Si œá¬≤calc cae **dentro de la zona naranja** (derecha de œá¬≤crit) ‚Üí se
    rechaza H‚ÇÄ
2.  Cuanto m√°s alejado est√© œá¬≤calc hacia la derecha, mayor evidencia
    contra H‚ÇÄ
3.  En este dataset, **todas las variables** tienen œá¬≤calc
    extremadamente superior a œá¬≤crit

**Casos especiales observados:**

- **Bare.nuclei, Cell.size, Cell.shape**: œá¬≤calc \> 480 ‚Üí asociaci√≥n
  masiva con el diagn√≥stico
- **Mitoses** (gl = 8): √önico con 8 grados de libertad debido a ausencia
  de datos en alg√∫n nivel (1-10)
- **Cl.thickness** (œá¬≤calc = 378): Aunque ‚Äúmenor‚Äù que otras, sigue
  siendo 22√ó superior al umbral cr√≠tico

**Conclusi√≥n visual:**

La distancia abismal entre las l√≠neas verde (œá¬≤crit) y morada (œá¬≤calc)
confirma que **no existe posibilidad estad√≠stica** de que estas
variables sean independientes del diagn√≥stico de c√°ncer. Todas superan
con creces el umbral de significancia, validando su inclusi√≥n como
predictoras en el modelo.

**Confirmaci√≥n de la Idoneidad del Algoritmo**

    ======================================================
    ‚úÖ Confirmaci√≥n para Naive Bayes Multinomial:
    El Test Chi-cuadrado valida que cada predictor (variables 1-10)
    tiene una asociaci√≥n altamente significativa (p-values < 2.2e-16)
    con la clase de diagn√≥stico. Dado que las variables son Factores
    (categ√≥ricas discretas), el uso del Naive Bayes Multinomial
    es el enfoque estad√≠sticamente apropiado para este dataset.
    ======================================================

## Detecci√≥n de outliers

``` r
library(tidyr)

# Convertir variables a num√©ricas expl√≠citamente
bc_num <- bc
bc_num[, 1:9] <- lapply(bc_num[, 1:9], function(x) as.numeric(as.character(x)))

# Funci√≥n de detecci√≥n de outliers
detect_outliers <- function(data, class_col = "Class") {
  outliers_list <- list()
  
  for(col in setdiff(names(data), class_col)) {
    x <- data[[col]]
    Q1 <- quantile(x, 0.25, na.rm = TRUE)
    Q3 <- quantile(x, 0.75, na.rm = TRUE)
    IQR_val <- Q3 - Q1
    lower <- Q1 - 1.5 * IQR_val
    upper <- Q3 + 1.5 * IQR_val
    
    outliers_idx <- which(x < lower | x > upper)
    
    if(length(outliers_idx) > 0) {
      outliers_list[[col]] <- data.frame(
        Variable = col,
        √çndice = outliers_idx,
        Valor = x[outliers_idx],
        Clase = data[[class_col]][outliers_idx],
        stringsAsFactors = FALSE)
    }
  }
  return(outliers_list)
}

# Aplicar
outliers_bc <- detect_outliers(bc_num)

cat("DETECCI√ìN DE OUTLIERS ‚Äì Breast Cancer\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Observaciones : ", nrow(bc_num), 
    "  |  Outliers detectados en ", length(outliers_bc), " de 9 variables\n\n",
    sep = "")
```

    DETECCI√ìN DE OUTLIERS ‚Äì Breast Cancer
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    Observaciones : 683  |  Outliers detectados en 5 de 9 variables

``` r
if(length(outliers_bc) > 0) {
  for(var in names(outliers_bc)) {
    n <- nrow(outliers_bc[[var]])
    pct <- round(n / nrow(bc_num) * 100, 2)
    cat(sprintf("  ‚Ä¢ %-15s : %3d outliers (%4.2f%%)\n", var, n, pct))
  }
} else {
  cat("  Ninguna variable presenta outliers seg√∫n la regla del IQR.\n")
}
```

      ‚Ä¢ Marg.adhesion   :  59 outliers (8.64%)
      ‚Ä¢ Epith.c.size    :  54 outliers (7.91%)
      ‚Ä¢ Bl.cromatin     :  20 outliers (2.93%)
      ‚Ä¢ Normal.nucleoli :  75 outliers (10.98%)
      ‚Ä¢ Mitoses         : 120 outliers (17.57%)

<br>

**Interpretaci√≥n de los outliers detectados**

La presencia de outliers en variables morfol√≥gicas del dataset de c√°ncer
de mama suele reflejar comportamientos celulares an√≥malos propios de
tejidos malignos, m√°s que errores de medici√≥n. En este contexto:

- Marg.adhesion (adhesi√≥n marginal): Outliers indican c√©lulas que
  pierden cohesi√≥n, un rasgo t√≠pico de tumores invasivos. Reflejan
  grados extremos de separaci√≥n celular.

- Epith.c.size (tama√±o del epitelio): Los valores at√≠picos representan
  c√©lulas muy grandes o muy peque√±as, coherentes con la fuerte
  desregulaci√≥n del ciclo celular en tumores malignos.

- Bl.cromatin (cromatina): Outliers sugieren patrones de cromatina
  inusualmente densa o irregular, asociados a actividad nuclear alterada
  en c√©lulas cancerosas.

- Normal.nucleoli: La variabilidad extrema en nucleolos es esperable en
  malignidad, donde estos aumentan de tama√±o y n√∫mero debido a alta
  actividad de s√≠ntesis.

- Mitoses: Es la variable con m√°s outliers, indicando tasas an√≥malamente
  altas de divisi√≥n celular, un sello distintivo del crecimiento tumoral
  acelerado.

En conjunto, los outliers no implican ruido, sino evidencia de
heterogeneidad tumoral, reforzando su valor como se√±ales discriminantes
para la clasificaci√≥n entre benigno y maligno.

<br>

### configuracion boxplot outliers

``` r
# Variables con outliers
vars_outliers <- c("Marg.adhesion","Epith.c.size",
  "Bl.cromatin","Normal.nucleoli",
  "Mitoses")

# Convertir datos a formato largo
bc_out_long <- bc_num %>%
  dplyr::select(all_of(vars_outliers), Class) %>%
  tidyr::pivot_longer(
    cols = vars_outliers,
    names_to = "Variable",values_to = "Valor" )

# Reordenar factores seg√∫n tu ranking discriminante
bc_out_long$Variable <- factor(
  bc_out_long$Variable,
  levels = c("Mitoses","Normal.nucleoli",
    "Marg.adhesion","Epith.c.size",
    "Bl.cromatin"))
```

### Boxplot multicapa para estructura de outliers

``` r
# Reordenar las variables seg√∫n el poder discriminante visual
bc_out_long$Variable <- factor(
  bc_out_long$Variable,
  levels = c("Mitoses","Normal.nucleoli","Marg.adhesion",
    "Epith.c.size","Bl.cromatin" ))

# TRUCO: capa dummy para crear la leyenda del P95
p95_legend <- data.frame(
  x = 1, y = 1, label = "Percentil 95")

# Gr√°fico
g_plot_outlier <- ggplot(bc_out_long, aes(x = Class, y = Valor, fill = Class)) +
                  
  # Boxplot
  geom_boxplot(alpha = 0.85, width = 0.65, outlier.shape = NA) +

  # Mediana (rombo negro)
  stat_summary(fun = median, geom = "point",
               color = "black", size = 3, shape = 18) +

  # Percentil 95 (tri√°ngulo rojo)
  stat_summary(fun = function(z) quantile(z, 0.95),
               geom = "point",
               aes(shape = "Percentil 95"),   # <-- aparece en la leyenda
               color = "darkred", size = 2.7) +

  # Capa dummy para que la leyenda exista aunque un facet no tenga p95 visible
  geom_point(data = p95_legend,
             aes(x = x, y = y, shape = "Percentil 95"),
             color = "darkred", size = 0, inherit.aes = FALSE) +

  # Jitter (ruido controlado)
  geom_jitter(aes(color = Class),
              width = 0.18, alpha = 0.35, size = 1.7) +

  facet_wrap(~ Variable, scales = "free_y") +

  # Colores
  scale_fill_manual(values = c("benign"    = "#7B1FA2",
    "malignant" = "#EF6C00")) +
  scale_color_manual(values = c(
    "benign"    = "#7B1FA2",
    "malignant" = "#EF6C00"
  )) +

  # Definir c√≥mo se muestra la leyenda del P95
  scale_shape_manual( name = "Indicadores estad√≠sticos",
    values = c("Percentil 95" = 17)   # 17 = tri√°ngulo s√≥lido
  ) +

  theme_minimal(base_size = 14) +

  labs(title = "Estructura de Outliers con Mediana y Percentil 95 ‚Äì Breast Cancer",
    x = "Clase", y = "Valor", fill = "Clase",
    color = "Clase")+
  theme(
    strip.text = element_text(face = "bold", size = 12),
    plot.title = element_text(face = "bold", size = 15, hjust = 0.5,
                              margin = margin(b = 16)),  # ‚Üê Espacio bajo t√≠tulo
    axis.text.x = element_text(angle = 0),
    legend.position = "right",
    plot.margin = margin(10,15,10,15) )

print(g_plot_outlier)
```

<img src="Cancer_multinominal_files/figure-gfm/Boxplot Multicapa para Estructura de Outliers-1.png" style="display: block; margin: auto;" />

<br>

**üìù Descripci√≥n del Gr√°fico: Boxplot + Jitter + Percentil 95 (P95)**

1.  Nube de puntos (jitter): distribuci√≥n completa

Los puntos dispersos representan todas las observaciones reales del
dataset, no solo los outliers. Su objetivo es mostrar la dispersi√≥n,
densidad, y el rango real de valores en ambas clases.

- Puntos muy concentrados ‚Üí baja variabilidad.
- Puntos muy dispersos ‚Üí alta variabilidad.
- Diferencias claras en la vertical ‚Üí separaci√≥n entre clases.

2.  Boxplot: estructura central del comportamiento

El boxplot resume la distribuci√≥n:

- Mediana (l√≠nea negra gruesa): nivel central t√≠pico.

- Caja (IQR): rango donde est√° el 50% de los datos.

- Bigotes: rango de variaci√≥n sin considerar outliers.

Comparar el tama√±o y posici√≥n de las cajas permite evaluar solapamiento
o separaci√≥n entre las clases.

3.  Tri√°ngulo rojo (Percentil 95 ‚Äì P95): comportamiento extremo t√≠pico

El tri√°ngulo en color rojo indica el percentil 95, es decir:

‚ÄúEl punto donde se ubica el 95% de los datos; solo el 5% m√°s alto queda
por encima.‚Äù

**El P95 no es un outlier, sino un indicador del nivel alto
caracter√≠stico antes de llegar a valores extremos.** Sirve para comparar
cu√°n ‚Äúalta‚Äù es la cola de cada grupo.

- P95 alto en malignant ‚Üí presencia de valores muy elevados t√≠picos en
  esa clase.

- P95 bajo en benign ‚Üí comportamiento m√°s estable y limitado.

Esta m√©trica refleja robustamente la diferencia en los extremos sin
depender del criterio del boxplot para outliers.

**An√°lisis del Gr√°fico**

1)  Mitoses ‚Äî M√°ximo poder separativo

- Benign se concentra casi completamente en valores muy bajos.

- Malignant presenta alta dispersi√≥n y una cola larga hacia valores
  elevados.

- El P95 de malignant queda muy por encima del de benign.

Conclusi√≥n

Variable extremadamente discriminante; las clases pr√°cticamente no se
traslapan.

2)  Normal.nucleoli ‚Äî Separaci√≥n muy marcada

- Benign: valores bajos y poco variables.

- Malignant: amplia dispersi√≥n y valores altos frecuentes.

- El P95 indica una brecha fuerte entre ambas clases.

Conclusi√≥n

Variable robusta y altamente diferenciadora.

3)  Marg.adhesion ‚Äî Diferenciaci√≥n s√≥lida

- Benign presenta valores bajos y consistentes.

- Malignant muestra mayor rango y mediana m√°s alta.

- Existe cierto traslape, pero el P95 es notablemente superior en
  malignant.

Conclusi√≥n

Buena variable discriminante, aunque con m√°s solapamiento que las dos
anteriores.

4)  Epith.c.size ‚Äî Separaci√≥n moderada

- Benign tiene valores m√°s bajos, pero con algo de dispersi√≥n.

- Malignant va desde valores medios a altos, con traslape visible.

Conclusi√≥n

Aporta diferenciaci√≥n, pero su poder separativo es medio.

5)  Bl.cromatin ‚Äî Menor poder discriminante del grupo

- Las medianas difieren entre clases, pero el solapamiento es
  considerable.

- El P95 de malignant sigue siendo mayor, aunque menos contrastado.

Conclusi√≥n

Variable √∫til, pero menos decisiva para diferenciar benign vs malignant.

**Conclusi√≥n**

- Mitoses y Normal.nucleoli son variables de m√°xima capacidad
  discriminante.

- Marg.adhesion es fuerte, pero con mayor traslape.

- Epith.c.size y Bl.cromatin aportan informaci√≥n, aunque son menos
  diferenciadoras.

- El P95 (tri√°ngulo rojo) es clave para entender la extensi√≥n de la cola
  alta t√≠picamente asociada a malignidad.

# Preparaci√≥n de Datos y An√°lisis de Predictores

En esta secci√≥n se realiza el procesamiento t√©cnico necesario para
garantizar que el algoritmo **Naive Bayes Multinomial** reciba los datos
en el formato correcto, evaluando adem√°s la calidad de las variables
predictoras.

## Separacion train/test

``` r
# Split train/test
library(caret)
set.seed(123)

# Clave: Usar 'bc' (datos 1-10 Factor) 
train_idx <- createDataPartition(bc$Class, p = 0.7, list = FALSE) 
train_data <- bc[train_idx, ] # Contiene la escala 1-10
test_data <- bc[-train_idx, ] # Contiene la escala 1-10

# 1. Hash para detectar cambios en los √≠ndices
if(requireNamespace("digest", quietly = TRUE)) {
  cat("üîê Hash de train_idx:", digest::digest(train_idx, algo = "md5"), "\n")
}
```

    üîê Hash de train_idx: 51a4688d6c732bf7844bf84c241d0b07 

**Verificaci√≥n del particionado (hash MD5)**

Para asegurar la reproducibilidad del an√°lisis, se calcula un hash MD5
del vector de √≠ndices usado en la partici√≥n train/test. Este hash act√∫a
como una ‚Äúhuella digital‚Äù: si en futuras ejecuciones cambia, significa
que se modific√≥ el dataset, el orden de las filas o la semilla del
particionado. Mantener un hash estable garantiza que el entrenamiento se
realiza siempre sobre el mismo subconjunto de datos.

## Verificacion split

``` r
cat(
  "üîé Verificaci√≥n del split train/test\n",
  "------------------------------------\n",
  sprintf("‚Ä¢ Tama√±os reales:\n   - Train: %d\n   - Test : %d\n   - Total: %d\n",
          nrow(train_data), nrow(test_data), nrow(bc)),
  "‚Ä¢ Distribuci√≥n de clases (Train):\n",
  paste("   -", names(table(train_data$Class)), "=", 
        table(train_data$Class), collapse = "\n"),
  "\n",
  sep = ""
)
```

    üîé Verificaci√≥n del split train/test
    ------------------------------------
    ‚Ä¢ Tama√±os reales:
       - Train: 479
       - Test : 204
       - Total: 683
    ‚Ä¢ Distribuci√≥n de clases (Train):
       - benign = 311
       - malignant = 168

## Verificacion test tipos

``` r
cat(
  "üîé Verificaci√≥n del Test y Tipos de Variables\n",
  "--------------------------------------------\n",
  "‚Ä¢ Distribuci√≥n de clases (Test):\n",
  paste("   -", names(table(test_data$Class)), "=", table(test_data$Class), collapse = "\n"), "\n",
  
  "\n‚Ä¢ Tipos de variables predictoras (9 citol√≥gicas):\n",
  paste(sprintf("   - %s: %s", 
                names(train_data)[1:9], 
                sapply(train_data[1:9], function(x) paste(class(x), collapse = " "))),
        collapse = "\n"), "\n",
  
  "\n‚Ä¢ Variable respuesta:\n",
  "   - Tipo de Class: ", class(train_data$Class), "\n",
  "   - Niveles: ", paste(levels(train_data$Class), collapse = ", "), "\n",
  sep = ""
)
```

    üîé Verificaci√≥n del Test y Tipos de Variables
    --------------------------------------------
    ‚Ä¢ Distribuci√≥n de clases (Test):
       - benign = 133
       - malignant = 71

    ‚Ä¢ Tipos de variables predictoras (9 citol√≥gicas):
       - Cl.thickness: ordered factor
       - Cell.size: ordered factor
       - Cell.shape: ordered factor
       - Marg.adhesion: ordered factor
       - Epith.c.size: ordered factor
       - Bare.nuclei: factor
       - Bl.cromatin: factor
       - Normal.nucleoli: factor
       - Mitoses: factor

    ‚Ä¢ Variable respuesta:
       - Tipo de Class: factor
       - Niveles: benign, malignant

**¬øPor qu√© esta verificaci√≥n es absolutamente cr√≠tica?**

El √©xito del clasificador Naive Bayes Multinomial depende
**fundamentalmente** de que R interprete correctamente la naturaleza de
las variables. Esta verificaci√≥n no es un simple chequeo rutinario, sino
una **validaci√≥n metodol√≥gica esencial** que confirma que el modelo
funcionar√° exactamente como esperas.

**Observaci√≥n cr√≠tica en la salida del sistema**

Al examinar los tipos de datos, observamos una aparente inconsistencia
que en realidad **no lo es**:

- **6 variables** aparecen como `ordered factor` (ordenadas):
  Cl.thickness, Cell.size, Cell.shape, Marg.adhesion, Epith.c.size,
  Mitoses
- **3 variables** aparecen como `factor` simple (sin orden):
  Bare.nuclei, Bl.cromatin, Normal.nucleoli

**Esta diferencia es COMPLETAMENTE IRRELEVANTE para el algoritmo
multinomial.** Perm√≠teme demostr√°rtelo con precisi√≥n t√©cnica.

------------------------------------------------------------------------

**Implicaci√≥n t√©cnica: Por qu√© ambos tipos son equivalentes**

La raz√≥n por la cual tanto `ordered factor` como `factor` funcionan
**id√©nticamente** en Naive Bayes Multinomial radica en c√≥mo el algoritmo
procesa internamente la informaci√≥n:

1.  Naturaleza categ√≥rica preservada

**Todas las 9 variables siguen siendo categ√≥ricas discretas con valores
1-10**, independiente del atributo ‚Äúordered‚Äù.

El atributo ‚Äúordered‚Äù es simplemente **metadata adicional** que R
almacena para ciertos an√°lisis estad√≠sticos que *s√≠* aprovechan el orden
(como regresi√≥n ordinal), pero que **Naive Bayes Multinomial IGNORA por
completo**.

2.  C√°lculo de frecuencias absolutamente id√©ntico

**Este es el punto CR√çTICO para entender el funcionamiento interno del
modelo.**

El algoritmo **no pregunta ‚Äú¬øest√° ordenada esta variable?‚Äù**.
Simplemente pregunta **‚Äú¬øcu√°ntas veces apareci√≥ este valor en esta
clase?‚Äù** y cuenta las ocurrencias.

------------------------------------------------------------------------

**Ejemplo: Demostraci√≥n matem√°tica**

1.  Escenario de entrenamiento

- Conjunto de entrenamiento: **n = 479 casos**
- Tumores malignos: **174 casos**
- De esos 174 malignos: **80 tienen Bare.nuclei = 10**

2.  C√°lculo para variable `factor` simple (Bare.nuclei)

El algoritmo necesita calcular: *¬øCu√°l es la probabilidad de observar
Bare.nuclei = 10 dado que el tumor es maligno?*

**Suavizado de Laplace (**$\alpha = 1$):

$$P(\text{Bare.nuclei}=10 \mid \text{malignant}) = \frac{n_{\text{malignant, Bare.nuclei=10}} + 1}{n_{\text{malignant}} + V}$$

donde:

- $n_{\text{malignant, Bare.nuclei=10}} = 80$ (conteo de casos malignos
  con Bare.nuclei = 10)
- $n_{\text{malignant}} = 174$ (total de casos malignos)
- $V = 10$ (valores posibles en la escala 1-10)

**Sustituyendo:**

$$P(\text{Bare.nuclei}=10 \mid \text{malignant}) = \frac{80 + 1}{174 + 10} = \frac{81}{184} \approx 0.4402$$

3.  C√°lculo para variable `ordered factor` (Cell.size)

Ahora hagamos **exactamente el mismo c√°lculo** para Cell.size, que
**s√≠** tiene el atributo ordered.

Supongamos: de los 174 malignos, **65 tienen Cell.size = 7**

**F√≥rmula (ID√âNTICA):**

$$P(\text{Cell.size}=7 \mid \text{malignant}) = \frac{n_{\text{malignant, Cell.size=7}} + 1}{n_{\text{malignant}} + 10}$$

**Sustituyendo:**

$$P(\text{Cell.size}=7 \mid \text{malignant}) = \frac{65 + 1}{174 + 10} = \frac{66}{184} \approx 0.3587$$

**Conclusi√≥n**

**LA F√ìRMULA ES ID√âNTICA.** El atributo ‚Äúordered‚Äù de Cell.size **no
modific√≥ absolutamente nada** en el c√°lculo.

El modelo simplemente: 1. Cont√≥ cu√°ntas veces apareci√≥ el valor 7 entre
los malignos (65 veces) 2. Sum√≥ 1 por Laplace 3. Dividi√≥ por el total de
malignos m√°s 10 (los valores posibles 1-10)

**El orden jer√°rquico es completamente ignorado por el algoritmo
multinomial.**

------------------------------------------------------------------------

**El papel fundamental de `usekernel=FALSE`**

Al establecer `usekernel=FALSE` en la configuraci√≥n del modelo, le
ordenamos **expl√≠citamente** a R:

> **‚ÄúNO se asume NINGUNA distribuci√≥n continua para estas variables‚Äù**

Sin este par√°metro, R podr√≠a intentar estimar medias $\mu$ y varianzas
$\sigma^2$ como si las variables fueran gaussianas ‚Üí **desastre
metodol√≥gico total**.

Con `usekernel=FALSE`, R est√° **obligado** a usar el enfoque multinomial
puro basado en **conteos de frecuencia discretos**, tratando cada valor
1-10 como una categor√≠a completamente independiente.

**Implicaci√≥n clave:** El valor 5 **no est√° ‚Äúentre‚Äù 4 y 6** desde la
perspectiva del modelo. Es simplemente **otra categor√≠a m√°s** que puede
aparecer o no en los datos.

------------------------------------------------------------------------

**Escenario CATASTR√ìFICO: Si fueran `numeric` o `integer`**

**Para apreciar completamente la importancia de esta verificaci√≥n**,
considera qu√© ocurrir√≠a si tus variables estuvieran codificadas como
`numeric` o `integer`:

**‚ùå Naive Bayes Gaussiano (ERROR METODOL√ìGICO GRAVE)**

R aplicar√≠a autom√°ticamente el modelo gaussiano, que calcular√≠a:

- **Media:** $\mu_{\text{Bare.nuclei | malignant}} \approx 8.2$
- **Desviaci√≥n est√°ndar:**
  $\sigma_{\text{Bare.nuclei | malignant}} \approx 2.1$

Luego usar√≠a la **funci√≥n de densidad de la distribuci√≥n normal** para
predecir:

$$P(\text{Bare.nuclei}=x \mid \text{malignant}) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$$

**Por qu√© esto es un DESASTRE:**

1.  **Datos NO son continuos** ‚Üí no pueden tomar valores como 7.3 o 8.92
2.  **NO siguen distribuciones normales** ‚Üí son evaluaciones ordinales
    subjetivas
3.  **La escala 1-10 NO representa magnitudes cuantitativas reales** ‚Üí
    son categor√≠as de severidad citol√≥gica
4.  **El modelo podr√≠a interpolar entre valores** ‚Üí asumiendo que un 7
    est√° ‚Äúcerca‚Äù de un 8 de manera cuantitativamente significativa

**Resultado:** P√©rdida completa de la estructura categ√≥rica real de los
datos y predicciones estad√≠sticamente inv√°lidas.

------------------------------------------------------------------------

**Conclusi√≥n y validaci√≥n metodol√≥gica**

La presencia de `factor` (con o sin atributo ‚Äúordered‚Äù) confirma
**inequ√≠vocamente** que R tratar√° cada valor 1-10 como una **categor√≠a
independiente** con su propia probabilidad condicional espec√≠fica,
**exactamente como requiere el algoritmo multinomial**.

Esta verificaci√≥n asegura:

‚úÖ **Compatibilidad metodol√≥gica total**  
‚úÖ **Funcionamiento correcto del modelo**  
‚úÖ **Ninguna asunci√≥n err√≥nea sobre continuidad o gaussianidad**  
‚úÖ **Interpretaci√≥n estad√≠sticamente apropiada para datos citol√≥gicos**

**En resumen:**

> Tanto `ordered factor` como `factor` son **v√°lidos y equivalentes**
> para Naive Bayes Multinomial porque el algoritmo **ignora el orden** y
> simplemente **cuenta frecuencias categoriales puras**. La verificaci√≥n
> exitosa confirma que tu implementaci√≥n es **metodol√≥gicamente
> correcta** y **estad√≠sticamente apropiada** para el problema de
> clasificaci√≥n de c√°ncer de mama mediante citolog√≠a FNA.

<br>

Guardar indices debug

``` r
saveRDS(train_idx, "train_idx_debug.rds")
cat("\nüíæ √çndices guardados en 'train_idx_debug.rds'\n")
```


    üíæ √çndices guardados en 'train_idx_debug.rds'

## Verificar que sean factores

``` r
# Verificar que TODAS las variables predictoras son ordered factors
predictoras <- names(train_data)[1:9]  # Las 9 variables citol√≥gicas

tipos <- sapply(train_data[predictoras], function(x) {
  paste(class(x), collapse = " ")
})

# Construir toda la salida en una sola llamada a cat()
cat(
  "üîç Verificaci√≥n de tipos de datos (variables predictoras):\n\n",
  paste(sprintf("  ‚Ä¢ %-15s : %s\n", predictoras, tipos), collapse = ""),
  "\n‚úÖ Todas son 'ordered factor' y 'factor' ‚Üí Correcto para Naive Bayes Multinomial\n",
  sprintf("üìä Tama√±os: Train = %d | Test = %d\n", nrow(train_data), nrow(test_data)),
  sep = ""
)
```

    üîç Verificaci√≥n de tipos de datos (variables predictoras):

      ‚Ä¢ Cl.thickness    : ordered factor
      ‚Ä¢ Cell.size       : ordered factor
      ‚Ä¢ Cell.shape      : ordered factor
      ‚Ä¢ Marg.adhesion   : ordered factor
      ‚Ä¢ Epith.c.size    : ordered factor
      ‚Ä¢ Bare.nuclei     : factor
      ‚Ä¢ Bl.cromatin     : factor
      ‚Ä¢ Normal.nucleoli : factor
      ‚Ä¢ Mitoses         : factor

    ‚úÖ Todas son 'ordered factor' y 'factor' ‚Üí Correcto para Naive Bayes Multinomial
    üìä Tama√±os: Train = 479 | Test = 204

<br>

## Ranking de importancia de variables v√≠a œá¬≤ en algoritmo Naive Bayes Multinomial

``` r
library(naivebayes)

# Extraer tablas de probabilidad condicional
modelo_completo <- naive_bayes(Class ~ ., data = train_data)

# Calcular entrop√≠a condicional por variable
importancia <- sapply(names(train_data)[-10], function(var) {
  tabla <- table(train_data[[var]], train_data$Class)
  chisq.test(tabla)$statistic
})

data.frame(
  Variable = names(importancia),
  Chi2 = round(importancia, 2)
) %>%
  arrange(desc(Chi2)) %>%
  ggplot(aes(x = reorder(Variable, Chi2), y = Chi2)) +
  geom_col(fill = "#3498db") +
  coord_flip() +
  labs(
    title = "Importancia de Variables - Naive Bayes Multinomial",
    x = NULL, 
    y = expression(paste("Estad√≠stico ", chi^2))  # ‚Üê CAMBIO AQU√ç
  ) +
  theme_minimal(base_size = 14) +         
  theme(
    axis.text.y = element_text(size = 10, face = "bold"),
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5))
```

<img src="Cancer_multinominal_files/figure-gfm/ranking Importancia de Variables en Naive Bayes-1.png" style="display: block; margin: auto;" />

## Correlaci√≥n entre variables predictoras

``` r
library(corrplot)
library(RColorBrewer)

# Convertir factores a num√©ricos solo para correlaci√≥n
bc_numeric <- bc
bc_numeric[, 1:9] <- lapply(bc_numeric[, 1:9], function(x) as.numeric(as.character(x)))

# Calcular matriz de correlaci√≥n
cor_matrix <- cor(bc_numeric[, 1:9])

# Paleta personalizada
col_palette <- colorRampPalette(c("#4A148C", "#7B1FA2", "#E1BEE7", 
                                   "#B3E5FC", "#03A9F4", "#01579B"))(200)

# Gr√°fico
corrplot(
  cor_matrix,  method = "color",  type = "upper", col = col_palette, addCoef.col = "black", 
  number.cex = 0.85, number.digits = 2, tl.col = "black",  tl.srt = 45,
  tl.cex = 0.9, cl.cex = 0.8,# tama√±o numero en matriz
  title = "Correlaci√≥n entre Predictores - Breast Cancer",
  mar = c(0, 0, 2, 0),addgrid.col = "grey80",outline = TRUE,
  order = "hclust", hclust.method = "ward.D2"
)
```

<img src="Cancer_multinominal_files/figure-gfm/Correlaci√≥n Variables Predictoras-1.png" width="80%" style="display: block; margin: auto;" />

``` r
# Identificar correlaciones fuertes
cor_fuertes <- which(abs(cor_matrix) > 0.7 & cor_matrix != 1, arr.ind = TRUE)

if(nrow(cor_fuertes) > 0) {
  cat("\nüü£ Correlaciones Fuertes (|r| > 0.7):\n")
  for(i in 1:nrow(cor_fuertes)) {
    row_idx <- cor_fuertes[i, 1]
    col_idx <- cor_fuertes[i, 2]
    if(row_idx < col_idx) {
      cat(sprintf("  ‚Ä¢ %s ‚Üî %s: r = %.3f\n",
                  rownames(cor_matrix)[row_idx],
                  colnames(cor_matrix)[col_idx],
                  cor_matrix[row_idx, col_idx]))
    }
  }
  cat("\nüìä Interpretaci√≥n:\n",
      "  - Correlaciones > 0.7 indican asociaci√≥n lineal fuerte\n",
      "  - Cell.size y Cell.shape m√°s correlacionadas (r=0.907)\n",
      "  - Viola supuesto de independencia de Naive Bayes\n",
      "  - Modelo tolera este sesgo con buen rendimiento\n",
      sep = "")
}
```


    üü£ Correlaciones Fuertes (|r| > 0.7):
      ‚Ä¢ Cell.size ‚Üî Cell.shape: r = 0.907
      ‚Ä¢ Cell.size ‚Üî Marg.adhesion: r = 0.707
      ‚Ä¢ Cell.size ‚Üî Epith.c.size: r = 0.754
      ‚Ä¢ Cell.shape ‚Üî Epith.c.size: r = 0.722
      ‚Ä¢ Cell.shape ‚Üî Bare.nuclei: r = 0.714
      ‚Ä¢ Cell.size ‚Üî Bl.cromatin: r = 0.756
      ‚Ä¢ Cell.shape ‚Üî Bl.cromatin: r = 0.735
      ‚Ä¢ Cell.size ‚Üî Normal.nucleoli: r = 0.719
      ‚Ä¢ Cell.shape ‚Üî Normal.nucleoli: r = 0.718

    üìä Interpretaci√≥n:
      - Correlaciones > 0.7 indican asociaci√≥n lineal fuerte
      - Cell.size y Cell.shape m√°s correlacionadas (r=0.907)
      - Viola supuesto de independencia de Naive Bayes
      - Modelo tolera este sesgo con buen rendimiento

# Entrenamiento, Evaluaci√≥n y Diagn√≥stico del Modelo

## Entrenamiento naive bayes multinomial

``` r
# CR√çTICO: Resetear semilla justo antes del modelo, garantiza reproducibilidad

set.seed(123)

# Configurar semillas para cada fold de validaci√≥n cruzada

seeds <- vector(mode = "list", length = 11)  # 10 folds + 1 final
for(i in 1:11) seeds[[i]] <- 123

ctrl <- trainControl(method = "cv", number = 10,
  seeds = seeds,  # ‚Üê Esto fuerza reproducibilidad en cada fold
  savePredictions = FALSE,classProbs = FALSE)

# Entrenar modelo ,FORZAR usekernel = FALSE para multinomial
modelo_bc <- train(
  Class ~ .,data = train_data, method = "naive_bayes", 
  trControl = ctrl,tuneGrid = expand.grid(laplace = 1,
    usekernel = FALSE,  # Multinomial puro
    adjust = 1))

# Verificaciones post-entrenamiento
cat(
  "‚úÖ Modelo entrenado\n",
  "   Observaciones usadas: ", nrow(modelo_bc$trainingData), "\n",
  "   Accuracy (CV): ", round(modelo_bc$results$Accuracy, 4), "\n",
  "   Kappa (CV)   : ", round(modelo_bc$results$Kappa, 4), "\n",
  sep = "")
```

    ‚úÖ Modelo entrenado
       Observaciones usadas: 479
       Accuracy (CV): 0.9457
       Kappa (CV)   : 0.8813

<br>

**Interpretaci√≥n del modelo entrenado**

El modelo Naive Bayes se entren√≥ utilizando 479 observaciones del
conjunto de entrenamiento. El desempe√±o obtenido durante la validaci√≥n
cruzada es s√≥lido:

Accuracy de 0.9457: el modelo clasifica correctamente cerca del 95% de
los casos.

Kappa de 0.8813: indica un nivel de concordancia muy alto entre las
predicciones del modelo y las clases reales, considerando el azar.

**Conclusi√≥n**

Aun con el supuesto ‚Äúnaive‚Äù de independencia, el modelo alcanza
**excelencia diagn√≥stica** en validaci√≥n cruzada.  
Es un rendimiento **cl√≠nicamente √∫til y muy robusto** antes siquiera de
evaluar en el test set independiente.

Guardar el modelo para debugging(modelo entrenado se guard√≥)

``` r
saveRDS(modelo_bc, "modelo_bc_debug.rds")
cat("\nüíæ Modelo guardado en 'modelo_bc_debug.rds'\n")
```


    üíæ Modelo guardado en 'modelo_bc_debug.rds'

## Verificaci√≥n de consistencia de preprocesamiento

``` r
# Forzar factores en bc antes de verificar
bc[, 1:9] <- lapply(bc[, 1:9], function(x) {
  factor(as.character(x), levels = 1:10, ordered = TRUE)
})

# Verificaci√≥n
cat("\nVerificaci√≥n Multinomial NB:\n",
    "  Dataset base tiene factores: ", is.factor(bc$Cl.thickness), "\n",
    "  usekernel = FALSE          : ", !modelo_bc$finalModel$usekernel, "\n",# confirma modelo entrenado us√≥ distr multinomial
    "  ‚Üí Modelo                   : ", 
    ifelse(!modelo_bc$finalModel$usekernel && is.factor(bc$Cl.thickness),
           "‚úÖ Multinomial NB", "‚ùå NO Multinomial"), "\n",
    sep = "")
```


    Verificaci√≥n Multinomial NB:
      Dataset base tiene factores: TRUE
      usekernel = FALSE          : TRUE
      ‚Üí Modelo                   : ‚úÖ Multinomial NB

<br>

## Comparaci√≥n de fronteras de decisi√≥n: modelo real vs modelo suavizado

### Preparaci√≥n de datos y modelos

**Nota metodol√≥gica importante:**  
Para esta visualizaci√≥n 2D, se convierten temporalmente las variables a
num√©ricas para facilitar la creaci√≥n del grid de predicci√≥n. Sin
embargo, el modelo `usekernel=FALSE` con `laplace=1` sigue aplicando la
l√≥gica multinomial de conteo de frecuencias por categor√≠a (1-10), no una
distribuci√≥n Gaussiana. La conversi√≥n a `numeric` solo afecta la
interpolaci√≥n visual del grid, no el m√©todo de clasificaci√≥n subyacente.

``` r
# Variables para visualizaci√≥n
var_x <- "Cell.size"
var_y <- "Cell.shape"

# Preparar datos num√©ricos (una sola vez)
train_2d <- data.frame(
  x = as.numeric(train_data[[var_x]]),
  y = as.numeric(train_data[[var_y]])
)

# Entrenar ambos modelos
modelo_real <- naive_bayes(train_2d, train_data$Class, usekernel = FALSE, laplace = 1)
modelo_suave <- naive_bayes(train_2d, train_data$Class, usekernel = TRUE, laplace = 0)

# Grid de predicci√≥n
grid <- expand.grid(x = seq(1, 10, length.out = 300), 
                    y = seq(1, 10, length.out = 300))

# Predicciones y probabilidades
grid$Clase_Real <- predict(modelo_real, grid)
grid$Clase_Suave <- predict(modelo_suave, grid)
grid$Prob_Real <- predict(modelo_real, grid, type = "prob")[, "malignant"]
grid$Prob_Suave <- predict(modelo_suave, grid, type = "prob")[, "malignant"]

# Datos reales para puntos
bc_plot <- data.frame(
  x = as.numeric(bc[[var_x]]),
  y = as.numeric(bc[[var_y]]),
  Class = bc$Class
)

# Funci√≥n para crear gr√°fico (elimina duplicaci√≥n)
plot_frontera <- function(data, clase_col, prob_col, titulo, subtitulo) {
  ggplot() +
    geom_raster(data = data, aes(x = x, y = y, fill = .data[[clase_col]]), alpha = 0.85) +
    geom_contour(data = data, aes(x = x, y = y, z = .data[[prob_col]]), 
                 breaks = 0.5, color = "black", linewidth = 1.2) +
    geom_point(data = bc_plot, aes(x = x, y = y, color = Class), 
               size = 2.5, alpha = 0.95, 
               position = position_jitter(width = 0.22, height = 0.22, seed = 123)) +
    scale_fill_manual(values = c(benign = "#D1C4E9", malignant = "#FFCDD2"),
                      name = paste("Predicci√≥n del\n", gsub("_", " ", clase_col))) +
    scale_color_manual(values = c(benign = "#673AB7", malignant = "#E57373"),
                       name = "Clase Real") +
    scale_x_continuous(breaks = 1:10, limits = c(1, 10)) +
    scale_y_continuous(breaks = 1:10, limits = c(1, 10)) +
    labs(title = titulo, subtitle = subtitulo,
         x = "Tama√±o Celular (Cell.size)", y = "Forma Celular (Cell.shape)") +
    theme_minimal(base_size = 26) +
    theme(
      plot.title = element_text(face = "bold", size = 24, hjust = 0.5),
      plot.subtitle = element_text(size = 22, hjust = 0.5, color = "gray5"),
      axis.title = element_text(face = "bold", size = 22),
      panel.border = element_rect(fill = NA, color = "black"),
      legend.position = "right",
      legend.text = element_text(size = 17),
      legend.title = element_text(size = 20, face = "bold")
    )
}

# Generar ambos gr√°ficos
p1 <- plot_frontera(grid, "Clase_Real", "Prob_Real",
                    "Frontera de Decisi√≥n del Modelo Real",
                    "Multinomial NB puro (Laplace=1, sin kernel)")

p2 <- plot_frontera(grid, "Clase_Suave", "Prob_Suave",
                    "Frontera Conceptual Suavizada",
                    "Estimaci√≥n kernel de densidad (usekernel=TRUE)")

# Grid final
grid.arrange(
  grobs = list(p1, p2), ncol = 2,
  top = grid::textGrob(
    "Comparaci√≥n de Fronteras de Decisi√≥n: Naive Bayes Multinomial",
    gp = grid::gpar(fontsize = 28, fontface = "bold"), vjust = 0.5
  ),
  bottom = grid::textGrob(
    "Zona morada suave: benigno | Zona rosa suave: maligno | L√≠nea negra: frontera P(Maligno)=0.5",
    gp = grid::gpar(fontsize = 20, col = "gray2")
  ),
  padding = unit(1.5, "cm")
)
```

<img src="Cancer_multinominal_files/figure-gfm/frontera-nb-compta-1.png" width="100%" style="display: block; margin: auto;" />

**¬øQu√© es P=0.5 y por qu√© es la frontera de decisi√≥n?**

**P=0.5 es el umbral de probabilidad donde el modelo cambia su decisi√≥n
de ‚Äúbenigno‚Äù a ‚Äúmaligno‚Äù.**

**Explicaci√≥n**

1.  **Probabilidades posteriores calculadas por Naive Bayes**

- Para cada punto del grid, el modelo calcula:
- P(Maligno\|caracter√≠sticas)
- P(Benigno\|caracter√≠sticas)

2.  **Regla de decisi√≥n MAP (Maximum A Posteriori):**

- Si P(Maligno) ‚â• 0.5 ‚Üí Clasifica como MALIGNO
- Si P(Maligno) \< 0.5 ‚Üí Clasifica como BENIGno

<br>

**Nota**

La frontera izquierda muestra saltos discretos porque el modelo
multinomial calcula probabilidades bas√°ndose en conteos de frecuencia en
las 10 categor√≠as ordenadas (1-10).

La frontera derecha usa estimaci√≥n kernel de densidad para revelar la
tendencia subyacente sin el ruido de la discretizaci√≥n. Ambas
representaciones son v√°lidas: la primera muestra c√≥mo el modelo decide
realmente; la segunda, c√≥mo conceptualizamos la separaci√≥n de clases.

### Interpretaci√≥n de las diferencias observadas

**An√°lisis comparativo de las fronteras de decisi√≥n**

La comparaci√≥n lado a lado revela diferencias fundamentales en c√≥mo
ambos modelos representan la separaci√≥n entre clases benignas y
malignas:

**Gr√°fico izquierdo (Modelo Real - Multinomial puro):**

El modelo real utiliza tablas de frecuencia discretas para estimar las
probabilidades condicionales. Cada combinaci√≥n de Cell.size y Cell.shape
(ambas en escala 1-10) genera una probabilidad posterior basada en
conteos observados en el entrenamiento, ajustados por el suavizado
Laplace. Esto produce una frontera que puede mostrar transiciones
abruptas o zonas escalonadas, especialmente en regiones donde hay pocos
datos de entrenamiento.

La l√≠nea negra marca exactamente donde la probabilidad posterior de
malignidad cruza el umbral del cincuenta por ciento. Esta es la frontera
de decisi√≥n real que usa el modelo en producci√≥n: si un nuevo caso cae a
la derecha o arriba de esta l√≠nea, ser√° clasificado como maligno; si cae
a la izquierda o abajo, como benigno.

**Gr√°fico derecho (Modelo Suavizado - Estimaci√≥n Kernel):**

El modelo con kernel aplica estimaci√≥n de densidad continua (t√≠picamente
gaussiana) sobre las mismas variables. Esto suaviza las probabilidades
posteriores, eliminando discontinuidades y produciendo una frontera m√°s
org√°nica y fluida. La transici√≥n entre zonas benignas y malignas es
gradual en lugar de escalonada.

Esta representaci√≥n es conceptualmente m√°s intuitiva y visualmente m√°s
elegante, pero no refleja exactamente c√≥mo el modelo de producci√≥n toma
decisiones. Es una idealizaci√≥n que muestra la tendencia general de
separaci√≥n sin el ruido inherente a la discretizaci√≥n de variables
categ√≥ricas.

**¬øCu√°l frontera es la correcta?**

Ambas son correctas, pero responden a preguntas diferentes. La frontera
real muestra c√≥mo el modelo clasificar√° casos nuevos en la pr√°ctica
cl√≠nica: con todas sus imperfecciones, saltos y zonas de incertidumbre.
La frontera suavizada muestra el patr√≥n conceptual subyacente que el
modelo intenta capturar: la estructura fundamental de c√≥mo las dos
variables discriminan entre tumores benignos y malignos.

Para prop√≥sitos de implementaci√≥n cl√≠nica y reproducibilidad cient√≠fica,
la frontera izquierda es la representaci√≥n honesta. Para prop√≥sitos de
comunicaci√≥n y comprensi√≥n del fen√≥meno biol√≥gico, la frontera derecha
puede ser m√°s informativa.

**Observaci√≥n clave:**

A pesar de las diferencias metodol√≥gicas, ambas fronteras coinciden en
las zonas cr√≠ticas donde est√°n concentradas la mayor√≠a de las
observaciones. Las discrepancias aparecen principalmente en las esquinas
y bordes del espacio de caracter√≠sticas, donde hay pocos o ning√∫n dato
de entrenamiento. Esto confirma que ambos modelos han aprendido
esencialmente el mismo patr√≥n discriminante subyacente, solo lo
representan con diferentes niveles de suavidad.

## Verificacion pre evaluacion

``` r
# Primero imprimes el encabezado con cat
{cat("üî¨ Verificaci√≥n antes de evaluar\n\n",
    "**Dimensiones test_data:** ", paste(dim(test_data), collapse = " √ó "), "  \n",
    "**Distribuci√≥n clases test:**\n", sep = "")

knitr::kable(table(test_data$Class), col.names = c("Clase", "Cant."), align = "l")}
```

üî¨ Verificaci√≥n antes de evaluar

**Dimensiones test_data:** 204 √ó 10  
**Distribuci√≥n clases test:**

| Clase     | Cant. |
|:----------|:------|
| benign    | 133   |
| malignant | 71    |

## Verificar que los √≠ndices no cambiaron

``` r
if(file.exists("train_idx_debug.rds")) {
  train_idx_saved <- readRDS("train_idx_debug.rds")
  cat("  ¬ø√çndices train coinciden?:", identical(train_idx, train_idx_saved), "\n")
}
```

      ¬ø√çndices train coinciden?: TRUE 

## Matriz de confusi√≥n y m√©tricas ‚Äì test set (9 var predictoras)

``` r
# Predicci√≥n, predict internamente aplica regla de MAP, calcula ambos score y Retorna solo la clase ganadora
pred_bc <- predict(modelo_bc, newdata = test_data)

# Matriz de confusi√≥n
conf_bc <- caret::confusionMatrix(pred_bc, test_data$Class, positive = "malignant")

# Verificaci√≥n post-evaluaci√≥n
print(conf_bc)
```

    Confusion Matrix and Statistics

               Reference
    Prediction  benign malignant
      benign       129         4
      malignant      4        67
                                              
                   Accuracy : 0.9608          
                     95% CI : (0.9242, 0.9829)
        No Information Rate : 0.652           
        P-Value [Acc > NIR] : <2e-16          
                                              
                      Kappa : 0.9136          
                                              
     Mcnemar's Test P-Value : 1               
                                              
                Sensitivity : 0.9437          
                Specificity : 0.9699          
             Pos Pred Value : 0.9437          
             Neg Pred Value : 0.9699          
                 Prevalence : 0.3480          
             Detection Rate : 0.3284          
       Detection Prevalence : 0.3480          
          Balanced Accuracy : 0.9568          
                                              
           'Positive' Class : malignant       
                                              

**Interpretaci√≥n Matriz de Confusi√≥n : Multinomial NB (Test Set)**

**Rendimiento :**

- **Accuracy**: 96.08% (IC 95%: 92.42% - 98.29%),El accuracy est√°
  respaldado por un intervalo de confianza que lo contiene ampliamente,
  lo que certifica la consistencia, reproducibilidad y solidez cl√≠nica
  del clasificador seleccionado.
- **Kappa**: 0.9136 (concordancia casi perfecta)
- **Balanced Accuracy**: 95.68% (indica que el modelo es
  consistentemente bueno para ambas clases, sin sesgo hacia la clase
  mayoritaria.)

**M√©tricas por Clase:**

<table class="table table-striped table-condensed table-hover" style="font-size: 14px; color: black; width: auto !important; margin-left: auto; margin-right: auto;">

<thead>

<tr>

<th style="text-align:left;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

M√©trica
</th>

<th style="text-align:left;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

Valor
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

Interpretaci√≥n
</th>

</tr>

</thead>

<tbody>

<tr>

<td style="text-align:left;width: 5cm; ">

<b>Sensitivity (Recall)</b>
</td>

<td style="text-align:left;width: 3cm; ">

94.37%
</td>

<td style="text-align:center;width: 10cm; ">

Detecta correctamente <b>67 de 71</b> casos malignos
</td>

</tr>

<tr>

<td style="text-align:left;width: 5cm; ">

<b>Specificity</b>
</td>

<td style="text-align:left;width: 3cm; ">

96.99%
</td>

<td style="text-align:center;width: 10cm; ">

Identifica correctamente <b>129 de 133</b> casos benignos
</td>

</tr>

<tr>

<td style="text-align:left;width: 5cm; ">

<b>Precision (PPV)</b>
</td>

<td style="text-align:left;width: 3cm; ">

94.37%
</td>

<td style="text-align:center;width: 10cm; ">

De las <b>71</b> predicciones como maligno, <b>67</b> son correctas
</td>

</tr>

<tr>

<td style="text-align:left;width: 5cm; ">

<b>NPV</b>
</td>

<td style="text-align:left;width: 3cm; ">

96.99%
</td>

<td style="text-align:center;width: 10cm; ">

De las <b>133</b> predicciones como benigno, <b>129</b> son correctas
</td>

</tr>

</tbody>

</table>

<br>

**Detecci√≥n de Casos Malignos:**

- **67 Verdaderos Positivos**: Casos malignos correctamente
  identificados (94.37% de 71 totales)
- **4 Falsos Negativos**: Casos malignos no detectados (5.63%) ‚ùó Riesgo
  cl√≠nico

**Detecci√≥n de Casos Benignos:**

- **129 Verdaderos Negativos**: Casos benignos correctamente
  identificados (96.99% de 133 totales)
- **4 Falsos Positivos**: Casos benignos clasificados err√≥neamente como
  malignos (3.01%)

**Errores del Modelo:**

- **Falsos Negativos (FN)**: 4 casos malignos clasificados como benignos
  (5.63%)‚ùó cr√≠tico cl√≠nicamente)
- **Falsos Positivos (FP)**: 4 casos benignos clasificados como malignos
  (3.01%) Genera ansiedad/procedimientos innecesarios

**Test de McNemar**

¬øQu√© mide? , Mide si hay diferencia significativa entre las tasas de
error de amobos modelos de los casos donde no coincide.

Interpretaci√≥n p-value = 1.0, significa equilibrio perfecto entre
errores:

- FP = FN (4 vs 4)
- El modelo no tiene tendencia a sobrediagnosticar ni infradiagnosticar
- Es cl√≠nicamente neutral: no favorece ning√∫n tipo de error sobre el
  otro

Conclusi√≥n pr√°ctica:

El modelo Naive Bayes est√° perfectamente calibrado: cuando se equivoca,
lo hace sin sesgo direccional. Esto es ideal en screening oncol√≥gico
porque evita dos extremos peligrosos:

- Sesgo a FN ‚Üí dejar√≠a pasar c√°nceres
- Sesgo a FP ‚Üí colapsar√≠a el sistema con alarmas falsas
- p = 1.0, es la mejor se√±al posible de un clasificador equilibrado

**Conclusi√≥n:**

El modelo alcanza rendimiento excelente con **7 errores en 204 casos**.
La tasa de falsos negativos (4.2%) es aceptable pero requiere
supervisi√≥n m√©dica complementaria para evitar diagn√≥sticos omitidos.

<br>

Guardar resultados para comparaci√≥n

``` r
resultados <- list(
  accuracy = conf_bc$overall["Accuracy"],
  sensitivity = conf_bc$byClass["Sensitivity"],
  specificity = conf_bc$byClass["Specificity"],
  matriz = as.matrix(conf_bc$table)
)
saveRDS(resultados, "resultados_test_debug.rds")
cat("\nüíæ Resultados guardados en 'resultados_test_debug.rds'\n")
```


    üíæ Resultados guardados en 'resultados_test_debug.rds'

<br>

**M√©tricas claves**

üìà M√©tricas en Test Set

- **Accuracy:** 0.9608
- **Sensitivity:** 0.9437 *(detecta malignos)*
- **Specificity:** 0.9699 *(detecta benignos)*
- **Precision:** 0.9437
- **F1-Score:** 0.9437

<br>

**Interpretaci√≥n:**

- **Accuracy(96.08%)**: Proporci√≥n total de diagn√≥sticos correctos ‚Üí
  **excelente clasificaci√≥n global**.

- **Sensibilidad (94,37%)**: Detecta correctamente 94 de cada 100
  c√°nceres.

- **Especificidad (96,99%)**: Identifica correctamente 97 de cada 100
  casos benignos.

- **Precision (94.37%)**: De cada 100 predicciones de malignidad, 94 son
  correctas. Minimiza falsas alarmas que generar√≠an procedimientos
  innecesarios.

- **F1-Score (94.37%)**: Media arm√≥nica entre Precision y Sensitivity,
  indica equilibrio perfecto entre detectar malignos y evitar falsos
  positivos.

- **Balance √≥ptimo**: Alta sensibilidad (94.37%) asegura capturar la
  mayor√≠a de casos malignos, mientras que alta precisi√≥n (94.37%) reduce
  alarmas falsas.

El modelo logra rendimiento cl√≠nicamente robusto con solo 8 errores en
204 casos.

<br>

## Visualizaci√≥n matriz de confusi√≥n

``` r
conf_table <- as.data.frame(conf_bc$table)

# Crear columna que identifique tipo de celda
conf_table$Tipo <- with(conf_table, 
                        ifelse(Reference == "benign" & Prediction == "benign", "TP_benign",
                        ifelse(Reference == "malignant" & Prediction == "malignant", "TP_malignant",
                               "Error")))

plot_matriz_confusion <- ggplot(conf_table, aes(x = Reference, y = Prediction, fill = Tipo)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), size = 8, color = "white", fontface = "bold") +
  
  # Colores sem√°nticos:
  scale_fill_manual(values = c(
    "TP_benign"    = "#8e44ad",  # Morado
    "TP_malignant" = "#e74c3c",  # Rojo
    "Error"        = "#bdc3c7"   # Gris neutro
  )) +
  
  labs(
    title = "Matriz de Confusi√≥n - Multinomial Naive Bayes (Test Set)",
    x = "Clase Real",
    y = "Predicci√≥n"
  ) +
  theme_minimal(base_size = 15) +
  theme(legend.position = "none",  plot.title = element_text(hjust = 0.5)
)

print(plot_matriz_confusion)
```

<img src="Cancer_multinominal_files/figure-gfm/plot matriz confusion-1.png" style="display: block; margin: auto;" />

<br>

## Distribuci√≥n de predicciones por Clase

``` r
distr_predicciones <- ggplot(data.frame(Real = test_data$Class, Predicha = pred_bc),
       aes(x = Real, fill = Predicha)) +
  geom_bar(position = "fill") +
  labs(title = "Proporci√≥n de Predicciones en Test Set",
       x = "Clase", y = "Proporci√≥n") +
  scale_fill_manual(values = c("benign" = "#8e44ad", "malignant" = "#e74c3c")) +
theme_minimal(base_size = 15) +
  theme(legend.position = "none",  plot.title = element_text(hjust = 0.5)
)

print(distr_predicciones)
```

<img src="Cancer_multinominal_files/figure-gfm/distribucion predicciones por clase real-1.png" style="display: block; margin: auto;" />

<br>

**Interpretaci√≥n del gr√°fico de proporciones de predicci√≥n**

El gr√°fico muestra el desempe√±o del modelo seg√∫n la clase real en el
conjunto de prueba:

- De los casos que eran **realmente benignos**, el modelo los clasific√≥
  correctamente como benignos con una Especificidad del 96.99%.

La peque√±a proporci√≥n restante, que representa el 3.01% de los casos
benignos reales, constituye los Falsos Positivos (FP) al ser clasificada
err√≥neamente como maligna.

- De los casos que eran **realmente malignos**, el modelo los identific√≥
  correctamente con una Sensibilidad del 94.37% (representado por la
  gran barra roja en el gr√°fico).

La franja verde visible en la parte superior, que representa el error
m√°s cr√≠tico, corresponde a los Falsos Negativos (FN). Estos tumores
malignos, clasificados incorrectamente como benignos, constituyen el
5.63% de todos los casos malignos reales.

Aunque el modelo tiene una precisi√≥n general alta
($\text{Accuracy}=0.9608$), los Falsos Negativos ($\approx 5.6\%$) son
el error m√°s cr√≠tico en este contexto cl√≠nico y representan el principal
punto de mejora.

<br>

# Evaluaci√≥n de Desempe√±o Probabil√≠stico en Test Set: An√°lisis AUC-ROC y PR-AUC

## Preparaci√≥n para c√°lculo de AUPRC

``` r
library(yardstick)
library(PRROC)

# 1. Predecir probabilidades en el conjunto test

# type = "prob" asegura que obtengamos las probabilidades para cada clase

prob_bc <- predict(modelo_bc, newdata = test_data, type = "prob")
```

## C√°lculo de AUPRC y preparaci√≥n de curva Precision-Recall

``` r
# 1. Extraer el vector de scores directamente del objeto de predicci√≥n 'prob_bc'

scores_auc <- prob_bc$malignant

# 2. Mapear la clase real a un vector num√©rico (1 para 'malignant', 0 para 'benign')
#    Usamos 'test_data' para asegurar la consistencia de las etiquetas reales.

clase_real_num <- ifelse(test_data$Class == "malignant", 1, 0)

# 3. Calcular la Curva PR y PR AUC

# Usamos PRROC::pr.curve
pr_results <- pr.curve(
    scores.class0 = scores_auc,       # <--- USAMOS EL VECTOR LIMPIO
    weights.class0 = clase_real_num,
    curve = TRUE
)

# 4. Imprimir el PR AUC
# Usar doble salto de l√≠nea al final para que lo que siga no se pegue
cat("\n**√Årea Bajo la Curva Precision-Recall (AUPRC):**", round(pr_results$auc.integral, 4), "\n\n")
```

**√Årea Bajo la Curva Precision-Recall (AUPRC):** 0.9476

### Visualizaci√≥n de curva precisi√≥n-sensibilidad

``` r
# 4. Preparar datos para graficar
pr_curve_df <- data.frame(
    Recall = pr_results$curve[, 1],
    Precision = pr_results$curve[, 2]
)

# 5. Graficar la Curva Precision-Recall
plot_Precision_Recall<-ggplot(pr_curve_df, aes(x = Recall, y = Precision)) +
    geom_line(color = "#0072B2", size = 1.2) +
    geom_area(fill = "#0072B2", alpha = 0.2) +
    geom_hline(yintercept = mean(clase_real_num), 
               linetype = "dashed", color = "red") + # L√≠nea de base (No Skill)
    labs(title = "Curva Precision-Recall (PR)",
         subtitle = paste("AUPRC =", round(pr_results$auc.integral, 4)),
         x = "Recall (Sensibilidad)",
         y = "Precision (Valor Predictivo Positivo)") +
    theme_minimal(base_size = 14) +
    theme(legend.position = "none",  plot.title = element_text(hjust = 0.5),
          plot.subtitle = element_text(hjust = 0.5) +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(limits = c(0, 1)) +
    annotate("text", x = 0.8, y = mean(clase_real_num) + 0.05, 
             label = "Precision de L√≠nea Base", color = "red"))

print(plot_Precision_Recall)
```

<img src="Cancer_multinominal_files/figure-gfm/Curva precisi√≥n-sensibilidad-1.png" style="display: block; margin: auto;" />

<br>

**Curva Precision-Recall (AUPRC = 0.9476)**

La curva Precision-Recall muestra un rendimiento **casi √≥ptimo** del
modelo en la detecci√≥n de tumores malignos.

Se observa que el modelo es capaz de mantener una **precisi√≥n superior
al 94%** incluso cuando la sensibilidad (recall) supera el 95 %. Esto
implica que, en la pr√°ctica, casi todas las predicciones de ‚Äúmaligno‚Äù
son correctas y, al mismo tiempo, el modelo detecta pr√°cticamente la
gran mayor√≠a de los c√°nceres reales.

Solo al intentar capturar el 100 % de los casos malignos la precisi√≥n
cae hasta la proporci√≥n real de la clase positiva en el test set (l√≠nea
base roja punteada).

El √°rea bajo la curva **AUPRC = 0.9476** es extremadamente alta y muy
cercana al valor ideal de 1.0, lo que confirma que el modelo logra
simult√°neamente **alta precisi√≥n y alta sensibilidad** en pr√°cticamente
todo el rango de umbrales. En un problema m√©dico desbalanceado como
este, este resultado es excepcional.

## Preparaci√≥n de probabilidades para c√°lculo AUC-ROC

``` r
library(pROC)

# Obtener probabilidades
prob_test <- predict(modelo_bc, test_data, type = "prob")
```

## C√°lculo de AUC ROC y preparaci√≥n de curva ROC

``` r
# Crear ROC correctamente

roc_obj <- pROC::roc(
  response  = test_data$Class,
  predictor = prob_test[, "malignant"],
  levels    = c("benign", "malignant"),
  direction = "<"
)

# Calcular AUC sin llamar auc() directamente
auc_value <- roc_obj$auc

cat("\n\n**√Årea Bajo la Curva ROC (AUC-ROC):**", round(auc_value, 4), "  \n")
```

**√Årea Bajo la Curva ROC (AUC-ROC):** 0.9808

### Visualizaci√≥n de curva ROC

``` r
# Convertir a data frame para ggplot

roc_df <- data.frame(
  specificity = roc_obj$specificities,
  sensitivity = roc_obj$sensitivities
)

plot_ROC <- ggplot(roc_df, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(color = "#e74c3c", size = 1.2) +
  geom_abline(intercept = 0, slope = 1, 
              linetype = "dashed", color = "gray40") +
  annotate("text",
           x = 0.65, y = 0.15,
           label = paste("AUC =", round(auc_value, 4)),
           size = 5, color = "#2c3e50") +
  labs(
    title = "Curva ROC - Multinomial Naive Bayes",
    x = "1 - Especificidad (FPR)",
    y = "Sensibilidad (TPR)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold",hjust = 0.5),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "gray88")
  )

print(plot_ROC)
```

<img src="Cancer_multinominal_files/figure-gfm/grafica curva ROC -1.png" width="85%" style="display: block; margin: auto;" />

<br>

**Curva ROC ‚Äì Naive Bayes Multinomial**

**Nota sobre la forma escalonada de la curva ROC (Test Set)**

La curva ROC muestra escalones pronunciados en lugar de una l√≠nea
continua. Este aspecto es **completamente normal y esperado** en el
clasificador **Naive Bayes Multinomial** aplicado a variables
categ√≥ricas ordinales (escala 1‚Äì10).

**Razones t√©cnicas:**

- El modelo genera un n√∫mero limitado de valores distintos de
  probabilidad posterior (m√°ximo \$\$11 debido al suavizado de Laplace y
  la discretizaci√≥n).
- Cada escal√≥n representa el cambio de clasificaci√≥n de **una o pocas
  observaciones** al variar el umbral de decisi√≥n.

La apariencia escalonada **no es un artefacto ni un defecto**, sino la
representaci√≥n fiel y √≥ptima del rendimiento del Naive Bayes Multinomial
con datos discretos. Cuanto m√°s marcada y pegada a la esquina superior
izquierda, mejor es el modelo y en este caso lo est√° al m√°ximo posible.

**An√°lisis curva**

La curva ROC muestra un rendimiento **excelente** del modelo Naive
Bayes.

Se observa que la curva se mantiene muy pegada a la esquina superior
izquierda y alcanza r√°pidamente la sensibilidad m√°xima con una
especificidad a√∫n muy alta. Esto indica que el modelo separa
correctamente las dos clases (benigno vs.¬†maligno) en pr√°cticamente todo
el rango de umbrales.

El valor del **AUC = 0.9808** es extremadamente alto y muy cercano al
valor ideal de 1.0, lo que confirma que el modelo tiene una capacidad
discriminativa sobresaliente, incluso superior a la observada en algunos
modelos m√°s complejos.

En t√©rminos pr√°cticos: el modelo es capaz de distinguir casi
perfectamente entre tumores benignos y malignos independientemente del
umbral de decisi√≥n elegido.

# An√°lisis de errores

## An√°lisis de errores en test set

``` r
# 2. An√°lisis de errores

errores <- test_data[pred_bc != test_data$Class, ]
cat("An√°lisis de Errores en Test Set:\n",
    "  Total de errores       :", nrow(errores), "\n",
    "  Falsos positivos (FP) :", sum(pred_bc == "malignant" & test_data$Class == "benign"), "\n",
    "  Falsos negativos (FN) :", sum(pred_bc == "benign" & test_data$Class == "malignant"), "\n",
    sep = " ")
```

    An√°lisis de Errores en Test Set:
       Total de errores       : 8 
       Falsos positivos (FP) : 4 
       Falsos negativos (FN) : 4 

El modelo es muy bueno, comete muy pocos errores y est√° ligeramente m√°s
inclinado a ‚Äúpecar de cauteloso‚Äù (m√°s FP que FN).

## Detalle de analisis errores en test set

``` r
errores_detalle <- test_data[pred_bc != test_data$Class, ]
errores_detalle$Prediccion <- pred_bc[pred_bc != test_data$Class]
errores_detalle$Tipo <- ifelse(errores_detalle$Prediccion == "malignant", "FP", "FN")

# Tabla detallada
errores_detalle %>%
  select(Bare.nuclei, Cell.size, Cell.shape, Cl.thickness, Class, Prediccion, Tipo) %>%
  arrange(Tipo) %>%
  knitr::kable(caption = "Casos Mal Clasificados - An√°lisis Detallado",
               align = "cccclcc")
```

|     | Bare.nuclei | Cell.size | Cell.shape | Cl.thickness | Class     | Prediccion | Tipo |
|:----|:-----------:|:---------:|:----------:|:------------:|:----------|:----------:|:----:|
| 99  |      6      |     6     |     9      |      9       | malignant |   benign   |  FN  |
| 248 |      9      |     4     |     4      |      8       | malignant |   benign   |  FN  |
| 289 |      5      |     1     |     3      |      6       | malignant |   benign   |  FN  |
| 456 |      6      |     2     |     2      |      10      | malignant |   benign   |  FN  |
| 111 |      2      |     3     |     1      |      1       | benign    | malignant  |  FP  |
| 197 |      7      |     4     |     4      |      8       | benign    | malignant  |  FP  |
| 260 |      8      |     7     |     7      |      5       | benign    | malignant  |  FP  |
| 658 |      1      |     4     |     5      |      5       | benign    | malignant  |  FP  |

Casos Mal Clasificados - An√°lisis Detallado

<br>

### Resumen estad√≠stico(media) por tipo de error de test set

``` r
if(nrow(errores_detalle) > 0) {
  
  resumen <- aggregate(cbind(Bare.nuclei, Cell.size, Cell.shape, Cl.thickness) ~ Tipo, 
                       data = errores_detalle, FUN = mean)
  
knitr::kable(resumen,
             digits = 2,
             col.names = c("Tipo de Error", "Bare.nuclei (media)", 
                           "Cell.size (media)", "Cell.shape (media)", 
                           "Cl.thickness (media)"),
             caption = "Promedios de variables predictoras seg√∫n tipo de error",
             align = "lcccc") %>%
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "bordered", "hover"),
    full_width = F,
    position = "center"
  )}
```

<table class="table table-striped table-bordered table-hover" style="color: black; width: auto !important; margin-left: auto; margin-right: auto;">

<caption>

Promedios de variables predictoras seg√∫n tipo de error
</caption>

<thead>

<tr>

<th style="text-align:left;">

Tipo de Error
</th>

<th style="text-align:center;">

Bare.nuclei (media)
</th>

<th style="text-align:center;">

Cell.size (media)
</th>

<th style="text-align:center;">

Cell.shape (media)
</th>

<th style="text-align:center;">

Cl.thickness (media)
</th>

</tr>

</thead>

<tbody>

<tr>

<td style="text-align:left;">

FN
</td>

<td style="text-align:center;">

6.5
</td>

<td style="text-align:center;">

3.25
</td>

<td style="text-align:center;">

4.50
</td>

<td style="text-align:center;">

8.25
</td>

</tr>

<tr>

<td style="text-align:left;">

FP
</td>

<td style="text-align:center;">

4.5
</td>

<td style="text-align:center;">

4.50
</td>

<td style="text-align:center;">

4.25
</td>

<td style="text-align:center;">

4.75
</td>

</tr>

</tbody>

</table>

<br>

**Interpretaci√≥n de tabla Promedios de variables predictoras seg√∫n tipo
de error**

Falsos Negativos (FN): $\text{Maligno} \rightarrow \text{Benigno}$

- Valores Promedio: Estos casos tienen un perfil at√≠pico con
  Cl.thickness muy alto (8.25) y Bare.nuclei alto (6.5) (caracter√≠sticas
  fuertes de malignidad). Sin embargo, las variables relacionadas con la
  morfolog√≠a celular (Cell.size en 3.25 y Cell.shape en 4.50) son
  sorprendentemente moderadas.

- lectura cl√≠nica: Este perfil mixto es t√≠pico en tumores con alta
  densidad o grosor celular, pero con morfolog√≠a a√∫n no totalmente
  desarrollada hacia patrones agresivos.

- Riesgo Cl√≠nico: Muy alto. Un falso negativo implica no detectar un
  c√°ncer.

- Causa Interpretada: El modelo Multinomial Naive Bayes es enga√±ado por
  los valores moderados de tama√±o y forma celular. A pesar de la alta
  densidad nuclear y grosor, el modelo puede clasificar incorrectamente
  la muestra como benigna, asumiendo tumores en etapas donde la atipia
  celular a√∫n no es extrema.

Falsos Positivos (FP): $\text{Benigno} \rightarrow \text{Maligno}$

- Valores Promedio: Todos los valores se concentran en un rango
  intermedio a moderado (4.25 - 4.75).

- Lectura cl√≠nica: Estos casos corresponden a tejido benigno con
  caracter√≠sticas ligeramente aumentadas, lo que puede asemejarlo
  parcialmente a lesiones malignas de bajo grado.

- Riesgo Cl√≠nico: Bajo (Falsa alarma, lleva a estudios adicionales, no
  hay riesgo de mortalidad).

- Causa Interpretada: Estos casos benignos poseen un conjunto de
  caracter√≠sticas que caen precisamente en la frontera de decisi√≥n del
  modelo. El tejido benigno tiene caracter√≠sticas lim√≠trofes (p.¬†ej., un
  tama√±o celular ligeramente hinchado o un n√∫cleo desnudo moderadamente
  alto), lo que lo hace indistinguible de casos malignos de bajo grado
  para el clasificador.

<br>

**Conclusi√≥n**

Los Falsos Negativos representan la falla cr√≠tica del modelo. Estos
casos exhiben un patr√≥n desbalanceado entre variables:

- atributos fuertes de malignidad (Cl.thickness, Bare.nuclei)

- combinados con atributos morfol√≥gicos moderados (Cell.size,
  Cell.shape)

Este contraste genera instancias dif√≠ciles de clasificar, donde la
l√≥gica probabil√≠stica del modelo no capta completamente la interacci√≥n
entre predictores, especialmente en escenarios borderline.

Por otro lado, los Falsos Positivos tienden a concentrarse en rangos
intermedios, lo que sugiere posibles l√≠mites en la capacidad del modelo
para separar con claridad los casos benignos cercanos a la frontera
entre ambas clases.

<br>

------------------------------------------------------------------------

# Datos nuevos (Validaci√≥n para ambos algoritmos)

Nota: Se extrae 50% del test_data (n=103) para evaluar robustez de los
algoritmos en un subconjunto independiente que ning√∫n modelo vio durante
entrenamiento ni optimizaci√≥n de hiperpar√°metros.

La comparaci√≥n final NB vs k-NN presentada en las tablas y conclusiones
utiliza el **test set completo original (n=204)** para m√°xima potencia
estad√≠stica y equidad comparativa.

``` r
set.seed(456)

val_idx <- createDataPartition(test_data$Class, p = 0.5, list = FALSE)
validation_data <- test_data[val_idx, ]
final_test_data <- test_data[-val_idx, ]

# Etiqueta corregida: Ahora indica Multinomial
cat("\n\n**Tama√±o de los nuevos datos de validaci√≥n (Multinomial):**", nrow(validation_data), "  \n")
```

**Tama√±o de los nuevos datos de validaci√≥n (Multinomial):** 103

## Matriz de confusi√≥n y m√©tricas: naive bayes multinomial (validaci√≥n)

``` r
# 1. Predecir CLASES en los datos de validaci√≥n
pred_val <- predict(modelo_bc, newdata = validation_data)

# 2. Calcular la Matriz de Confusi√≥n
conf_val <- confusionMatrix(pred_val, validation_data$Class,positive="malignant")
print(conf_val)
```

    Confusion Matrix and Statistics

               Reference
    Prediction  benign malignant
      benign        65         3
      malignant      2        33
                                              
                   Accuracy : 0.9515          
                     95% CI : (0.8903, 0.9841)
        No Information Rate : 0.6505          
        P-Value [Acc > NIR] : 2.505e-13       
                                              
                      Kappa : 0.8926          
                                              
     Mcnemar's Test P-Value : 1               
                                              
                Sensitivity : 0.9167          
                Specificity : 0.9701          
             Pos Pred Value : 0.9429          
             Neg Pred Value : 0.9559          
                 Prevalence : 0.3495          
             Detection Rate : 0.3204          
       Detection Prevalence : 0.3398          
          Balanced Accuracy : 0.9434          
                                              
           'Positive' Class : malignant       
                                              

<br>

**Inferencias de la Matriz de Confusi√≥n (Validaci√≥n - Multinomial NB)**

Rendimiento:

- Accuracy: 95.15% (IC 95%: 89.03%-98.41%) - Excelente clasificacci√≥n
  del modelo
- Kappa: 0.8926 - Concordancia casi perfecta
- Balanced Accuracy: 94.34% - Modelo equilibrado

Detecci√≥n de maligno:

- Sensitivity: 91.67% - Detecta 33 de 36 casos malignos
- 3 Falsos Negativos: Casos malignos no detectados (riesgo cl√≠nico)
- Precision: 94.29% - De 35 predicciones malignas, 33 son correctas

Detecci√≥n de benignos:

- Specificity: 97.01% - Identifica 65 de 67 casos benignos
- 2 Falsos Positivos: Benignos clasificados como malignos

Comparaci√≥n Train vs Validaci√≥n:

Train: 94.57% Accuracy \| Validaci√≥n: 95.15% Accuracy

- Diferencia de 0.58% ,indica excelente estabilidad - **modelo
  generaliza muy bien** , sin signos de sobreajuste.

**Conclusi√≥n**

El modelo mantiene rendimiento robusto en datos no vistos, con tasa de
error de 4.85% (5 de 103 casos). Los 3 FN requieren atenci√≥n cl√≠nica
adicional.

**Mcnemar‚Äôs Test**

El p-value = 1 en este resultado indica que los errores en ambas
direcciones son pr√°cticamente sim√©tricos. En otras palabras:

- No hay evidencia de que el modelo est√© fallando m√°s al clasificar
  malignant como benign que al clasificar benign como malignant.

- Sus desaciertos son muy pocos y est√°n equilibrados.

- El modelo no muestra sesgo hacia ninguna clase, mantiene un
  comportamiento parejo al enfrentarse a ambas.

**Conclusi√≥n final**

El modelo Multinomial Naive Bayes mantiene un rendimiento **robusto y
cl√≠nicamente muy valioso** en datos completamente nuevos:  
- Tasa global de error: **4.85 %** (solo **5 errores** en 103 casos)  
- Detecta m√°s del **91 %** de los c√°nceres reales  
- Genera √∫nicamente **2 falsas alarmas** y **3 omisiones**

Los 3 falsos negativos, aunque bajos en proporci√≥n, justifican su uso
como **herramienta de apoyo** (nunca como diagn√≥stico √∫nico) y eventual
combinaci√≥n con revisi√≥n humana o un segundo modelo en casos de
probabilidad intermedia.

<br>

### Visualizaci√≥n matriz de confusi√≥n multinominal naive bayes(Validaci√≥n)

``` r
# Visualizaci√≥n Matriz de Confusi√≥n
conf_table_val <- as.data.frame(conf_val$table)
names(conf_table_val) <- c("Reference", "Prediction", "Freq")

conf_table_val$tipo <- ifelse(
  conf_table_val$Reference == conf_table_val$Prediction,
  "correcto", "error"
)

p <- ggplot(conf_table_val, aes(x = Reference, y = Prediction)) +

  geom_tile(
    data = subset(conf_table_val, tipo == "error"),
    fill = "grey60", color = "white"
  ) +
  geom_tile(
    data = subset(conf_table_val, tipo == "correcto"),
    aes(fill = Freq), color = "white"
  ) +
  geom_text(aes(label = Freq), size = 6, color = "white", fontface = "bold") +

  scale_fill_gradient(low = "#e74c3c", high = "#8e44ad") +

  labs(
    title = "Matriz de Confusi√≥n - Multinomial Naive Bayes (Validaci√≥n)",
    x = "Clase Real",
    y = "Predicci√≥n"
  ) +

  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5)
  )

print(p)
```

<img src="Cancer_multinominal_files/figure-gfm/plot_matrizconfusion_validacion-1.png" style="display: block; margin: auto;" />

<br>

# Evaluaci√≥n de Desempe√±o Probabil√≠stico en Datos de Validaci√≥n: An√°lisis AUC-ROC y PR-AUC

## C√°lculo AUC ROC y prec√°lculo para curva ROC

``` r
# Predecir probabilidades
prob_val <- predict(modelo_bc, newdata = validation_data, type = "prob")

# Curva ROC
roc_obj_val <- pROC::roc(
  response  = validation_data$Class,
  predictor = prob_val[, "malignant"])

auc_roc <- roc_obj_val$auc
cat("\nAUC ROC:", round(auc_roc, 4), "\n")
```

AUC ROC: 0.9797

### Visualizaci√≥n Curva ROC - Naive bayes multinominal(Validaci√≥n)

``` r
# Convertir curva ROC a data frame
roc_df_val <- data.frame(
  specificity = roc_obj_val$specificities,
  sensitivity = roc_obj_val$sensitivities
)

ggplot(roc_df_val, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(color = "#e74c3c", linewidth = 1.2) +
  geom_abline(intercept = 0, slope = 1, 
              linetype = "dashed", color = "gray40") +
  annotate("text",
           x = 0.60, y = 0.20,
           label = paste("AUC =", round(auc_roc, 4)),
           size = 5, color = "black") +
  labs(
    title = "Curva ROC - Naive Bayes Multinomial (Validaci√≥n)",
    x = "1 - Especificidad (FPR)",
    y = "Sensibilidad (TPR)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold",hjust=0.5),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "gray88")
  )
```

<img src="Cancer_multinominal_files/figure-gfm/Curva ROC - Naive bayes multinominal2-1.png" style="display: block; margin: auto;" />

<br>

**Curva ROC ‚Äì Naive Bayes Multinomial**

**Nota sobre la forma escalonada de la curva ROC**

La curva ROC presenta escalones marcados en lugar de una l√≠nea suave.
Este comportamiento es **esperado y correcto** en el Naive Bayes
Multinomial cuando las variables predictoras son categ√≥ricas ordinales
(escala 1‚Äì10).

**Causa t√©cnica:**

El modelo genera un n√∫mero finito de valores de probabilidad posterior
(m√°ximo 11 valores distintos debido a la discretizaci√≥n y el suavizado
de Laplace). Cada escal√≥n corresponde al cambio de clasificaci√≥n de
**una √∫nica observaci√≥n** al variar el umbral.

**Interpretaci√≥n:**

Cuanto **m√°s grandes y m√°s pegados a la esquina superior izquierda**
sean los escalones, **mejor es la separaci√≥n** entre clases.  
En este caso, la curva sube casi verticalmente hasta sensibilidad ‚âà 1.0
con muy pocos falsos positivos ‚Üí confirma una **discriminaci√≥n
pr√°cticamente perfecta** entre tumores benignos y malignos.

Por tanto, la forma escalonada **no es un artefacto ni un error**, sino
la representaci√≥n fiel y √≥ptima del rendimiento del clasificador Naive
Bayes Multinomial con variables discretas.

La curva ROC muestra un **rendimiento excelente** del modelo Naive Bayes
multinomial.

- La curva se mantiene muy cercana a la esquina superior izquierda
  durante casi todo el recorrido, alcanzando r√°pidamente la sensibilidad
  m√°xima (casi 1.0) con una p√©rdida m√≠nima de especificidad.

- El **AUC = 0.9797** es extremadamente alto y est√° muy pr√≥ximo al valor
  ideal de 1.0, lo que indica una **capacidad discriminativa
  sobresaliente** del modelo.

- En la pr√°ctica cl√≠nica esto significa que el modelo es capaz de
  distinguir casi perfectamente entre tumores **benignos** y
  **malignos** en pr√°cticamente cualquier umbral de decisi√≥n que se
  elija.

**Conclusi√≥n**

El modelo Naive Bayes multinomial (tras binarizaci√≥n adecuada) alcanza
un rendimiento diagn√≥stico **casi perfecto** en el conjunto de
validaci√≥n, comparable o incluso superior al de algoritmos m√°s
complejos.

<br>

## C√°lculo PR AUC (Validaci√≥n) y prec√°lculo para curva precisi√≥n-recall(Validaci√≥n)

``` r
# Curva Precision-Recall

clase_real_num_val <- ifelse(validation_data$Class == "malignant", 1, 0)


pr_results_val <- pr.curve(
  scores.class0 = prob_val[, "malignant"], 
  weights.class0 = clase_real_num_val,
  curve = TRUE
)

cat("PR AUC (Validaci√≥n):", round(pr_results_val$auc.integral, 4), "\n")
```

PR AUC (Validaci√≥n): 0.955

### Visualizaci√≥n curva precision-recall

``` r
pr_curve_df_val <- data.frame(
  Recall = pr_results_val$curve[, 1],
  Precision = pr_results_val$curve[, 2]
)

plot_pr_validacion <- ggplot(pr_curve_df_val, aes(x = Recall, y = Precision)) +
  geom_line(color = "#3498db", size = 1.2) +
  labs(title = "Curva Precision-Recall(Validaci√≥n)",
       subtitle = paste("AUPRC =", round(pr_results_val$auc.integral, 4)),
       x = "Recall", y = "Precision") +
theme_minimal(base_size = 14) +
theme(
  legend.position = "none",
  plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5)
)

print(plot_pr_validacion)
```

<img src="Cancer_multinominal_files/figure-gfm/Curva precision-recall -1.png" style="display: block; margin: auto;" />

<br>

**Curva Precision-Recall: An√°lisis del Modelo Naive Bayes Multinomial**

Rendimiento: AUPRC = 0.955 √≠ndica desempe√±o excepcional, cercano al
√≥ptimo te√≥rico.

Comportamiento por Regiones de Recall:

- 0.0-0.85: Precisi√≥n sostenida ~1.0 (clasificaciones altamente
  confiables)
- 0.85-0.95: Ca√≠das escalonadas graduales en precisi√≥n
- 0.95: Colapso abrupto a ~0.35 (incremento masivo de falsos positivos)

Caracter√≠sticas Espec√≠ficas de Naive Bayes:

La ca√≠da dr√°stica al final es t√≠pica del algoritmo. El supuesto de
independencia condicional genera probabilidades extremas (cercanas a 0 o
1). Para alcanzar recall \>0.95, el modelo debe incluir instancias con
probabilidades muy bajas, incorporando numerosos falsos positivos.

**Recomendaci√≥n de Threshold(Umbral de Decisi√≥n)**

Para contextos m√©dicos donde falsos negativos son cr√≠ticos pero falsos
positivos tienen costo: operar en recall 0.85-0.90 mantiene precisi√≥n
\>0.95, equilibrando detecci√≥n de casos malignos con confiabilidad
diagn√≥stica.

<br>

------------------------------------------------------------------------

# **Algoritmo k-Nearest Neighbors (k-NN): Fundamentos Completos**

**Definici√≥n**

El algoritmo **k-Nearest Neighbors (k-NN)** es un m√©todo de
clasificaci√≥n y regresi√≥n **no param√©trico** basado en prototipos que no
construye un modelo expl√≠cito durante el entrenamiento. Almacena todas
las observaciones del conjunto de entrenamiento y realiza predicciones
mediante comparaci√≥n directa con los datos almacenados en memoria.

**Fundamento matem√°tico:**

Para un punto de consulta $\mathbf{x}$, la predicci√≥n
$\hat{Y}(\mathbf{x})$ en clasificaci√≥n se define como la clase
mayoritaria entre los $k$ vecinos m√°s cercanos:

$$\hat{Y}(\mathbf{x}) = \text{mode}\{y_i : x_i \in \mathcal{N}_k(\mathbf{x})\}$$

donde:

- $\mathcal{N}_k(\mathbf{x})$ es el conjunto de los $k$ puntos m√°s
  cercanos a $\mathbf{x}$ en el espacio de caracter√≠sticas.

- $\text{mode}$ es la funci√≥n que devuelve el valor m√°s frecuente:
  $$\text{mode}(S) = \arg\max_{y \in S} \text{count}(y)$$

------------------------------------------------------------------------

## M√©tricas de Distancia

**Distancia Euclidiana**

Mide la ‚Äúl√≠nea recta‚Äù entre dos puntos en un espacio $p$-dimensional:

$$d_{\text{Euclidiana}}(\mathbf{x}, \mathbf{x}_i) = \sqrt{\sum_{j=1}^{p} (x_j - x_{ij})^2}$$
**Intuici√≥n:** Distancia geom√©trica habitual que medir√≠amos con una
regla.

**Distancia Manhattan**

Suma de diferencias absolutas entre coordenadas:

$$d_{\text{Manhattan}}(\mathbf{x}, \mathbf{x}_i) = \sum_{j=1}^{p} |x_j - x_{ij}|$$

**Intuici√≥n:** Distancia recorrida en una ciudad con calles en
cuadr√≠cula (solo horizontal/vertical, sin diagonales).

**Comparaci√≥n en c√°ncer de mama:**

| M√©trica | Ventaja | Desventaja |
|:---|:---|:---|
| Euclidiana | Captura cercan√≠a geom√©trica directa | Sensible a outliers (elevar al cuadrado magnifica errores) |
| Manhattan | M√°s robusta frente a valores extremos | Ignora estructura geom√©trica global |

**Resultado en este dataset:** Manhattan obtuvo **98.04% accuracy** vs
**97.55%** de Euclidiana, sugiriendo que la robustez ante outliers fue
ventajosa.

------------------------------------------------------------------------

## Algoritmo k-NN: Paso a Paso

### Fase 1: Entrenamiento (Memorizaci√≥n)

**Entrada:** Datos de entrenamiento
$\{(\mathbf{x}^{(1)}, y^{(1)}), \ldots, (\mathbf{x}^{(N)}, y^{(N)})\}$

**Pasos:**

1.  **Estandarizar caracter√≠sticas:**

    Para cada variable $j$:

    $$z_j = \frac{x_j - \mu_j}{\sigma_j}$$

    donde $\mu_j$ = media de variable $j$ en train, $\sigma_j$ =
    desviaci√≥n est√°ndar

    **Raz√≥n:** k-NN es sensible a escala. Una variable con rango \[1,
    1000\] dominar√≠a sobre otra con rango \[0, 1\].

2.  **Almacenar en memoria:**

    Guardar matriz completa de entrenamiento $\mathbf{X}_{\text{train}}$
    y vector de clases $\mathbf{y}_{\text{train}}$

    **Nota:** k-NN es un algoritmo ‚Äúlazy‚Äù (perezoso) - no hay c√°lculos
    en entrenamiento

**Salida:**
$(\mathbf{X}_{\text{train}}, \mathbf{y}_{\text{train}}, \mu, \sigma)$
almacenados

### Fase 2: Predicci√≥n

**Entrada:** Nueva observaci√≥n $\mathbf{x}^{\text{new}}$, hiperpar√°metro
$k$

**Pasos:**

1.  **Estandarizar nueva observaci√≥n:**

    $$\mathbf{z}^{\text{new}} = \frac{\mathbf{x}^{\text{new}} - \mu}{\sigma}$$

    **Crucial:** Usar la MISMA $\mu$ y $\sigma$ del entrenamiento

2.  **Calcular distancias a todos los puntos de entrenamiento:**

    Para cada $i = 1, \ldots, N$:

    $$d_i = d(\mathbf{z}^{\text{new}}, \mathbf{z}_{\text{train}}^{(i)})$$

    usando m√©trica elegida (Euclidiana o Manhattan)

3.  **Ordenar distancias de menor a mayor:**

    $$d_{(1)} \leq d_{(2)} \leq \ldots \leq d_{(N)}$$

4.  **Seleccionar los** $k$ vecinos m√°s cercanos:

    $$\mathcal{N}_k(\mathbf{x}^{\text{new}}) = \{\mathbf{x}^{(i)} : d_i \in \{d_{(1)}, \ldots, d_{(k)}\}\}$$

5.  **Voto por mayor√≠a:**

    $$\hat{y} = \text{mode}\{y_i : \mathbf{x}^{(i)} \in \mathcal{N}_k(\mathbf{x}^{\text{new}})\}$$

**Traducci√≥n:** Asignar la clase que aparece m√°s veces entre los $k$
vecinos

**Salida:** Clase predicha $\hat{y}$

**Ejemplo num√©rico:**

Para $k=5$ y nueva observaci√≥n con distancias:

| Vecino | Distancia | Clase     |
|:------:|:---------:|:----------|
|   1    |   0.23    | malignant |
|   2    |   0.31    | malignant |
|   3    |   0.45    | benign    |
|   4    |   0.52    | malignant |
|   5    |   0.58    | malignant |

Votos: 4 malignant, 1 benign ‚Üí Clasificaci√≥n: **MALIGNANT**

------------------------------------------------------------------------

**Criterio de Clasificaci√≥n Final:**

Para clasificaci√≥n binaria (benign/malignant), el modelo asigna:

$$\hat{y} = \begin{cases} 
\text{malignant} & \text{si } \#\{\text{vecinos malignos}\} > \frac{k}{2} \\
\text{benign} & \text{en caso contrario}
\end{cases}$$

**Ejemplo num√©rico del caso anterior (k=5):**

| Vecino | Distancia | Clase     |
|:------:|:---------:|:----------|
|   1    |   0.23    | malignant |
|   2    |   0.31    | malignant |
|   3    |   0.45    | benign    |
|   4    |   0.52    | malignant |
|   5    |   0.58    | malignant |

**Conteo de votos:** - Malignant: **4 votos** (mayor√≠a absoluta) -
Benign: 1 voto

**Decisi√≥n:** Como 4 \> 5/2 = 2.5 ‚Üí **Clasificaci√≥n: MALIGNO** ‚úì

**Caso de empate (solo si k es par):**  
Si k=4 y hay 2 votos para cada clase, la implementaci√≥n est√°ndar en R
(`knn()`) desempata eligiendo la clase del vecino **m√°s cercano** (menor
distancia).

------------------------------------------------------------------------

### Selecci√≥n del Hiperpar√°metro $k$

**¬øC√≥mo elegir** $k$ √≥ptimo?

Se usa **validaci√≥n cruzada** (t√≠picamente 10-fold):

1.  Para cada $k$ candidato (ej: 1, 3, 5, ‚Ä¶, 35):
    - Dividir train en 10 partes
    - Entrenar en 9 partes, validar en 1 restante
    - Repetir 10 veces
    - Promediar accuracy
2.  Seleccionar $k$ con **mayor accuracy promedio**

**Trade-off:**

- $k$ peque√±o (k=1): Frontera irregular, sobreajuste, alta varianza
- $k$ grande (k‚ÜíN): Frontera suave, subajuste, alto sesgo
- $k$ √≥ptimo: Equilibrio entre sesgo y varianza

**En este proyecto:**

- k=1: 95.59% accuracy (demasiado reactivo)
- k=5: 96.57% accuracy (buen balance)
- k=17: 97.55% accuracy Euclidiana
- k=17: **98.04% accuracy Manhattan** ‚Üê GANADOR

**Regla emp√≠rica:** $k \approx \sqrt{N}$ como punto de partida, luego
refinar con CV.

------------------------------------------------------------------------

### Complejidad Computacional

| Fase | Complejidad | Explicaci√≥n |
|:---|:--:|:---|
| Entrenamiento | $O(1)$ | Solo almacena datos en memoria |
| Predicci√≥n | $O(N \cdot p)$ | Calcula $N$ distancias euclidiana/Manhattan de dimensi√≥n $p$ |
| Espacio | $O(N \cdot p)$ | Almacena todo el conjunto de entrenamiento |

**Implicaci√≥n:** k-NN es lento en predicci√≥n para datasets grandes ($N$
\> 100,000). Para este proyecto (N=479 train), es altamente eficiente.

------------------------------------------------------------------------

**Extensi√≥n Probabil√≠stica para Fronteras de Decisi√≥n**

Cuando se activa el par√°metro `prob=TRUE` en la funci√≥n `knn()` de R, el
algoritmo calcula la proporci√≥n de votos como probabilidad posterior
estimada:

$$\hat{P}(G = g \mid \mathbf{x}) = \frac{1}{k} \sum_{x_i \in \mathcal{N}_k(\mathbf{x})} \mathbb{I}(y_i = g)$$

donde la **funci√≥n indicadora** se define como:

$$\mathbb{I}(y_i = g) = \begin{cases} 
1 & \text{si } y_i = g \\ 
0 & \text{si } y_i \neq g 
\end{cases}$$

**Interpretaci√≥n:** Cuenta cu√°ntos de los $k$ vecinos pertenecen a la
clase $g$, y divide por $k$ para obtener la proporci√≥n (probabilidad
estimada).

Esta proporci√≥n representa la fracci√≥n de vecinos que pertenecen a la
clase $g$ entre los $k$ vecinos m√°s cercanos.

**Ejemplo pr√°ctico:**  
Si k=17 y un punto tiene 14 vecinos ‚Äúmalignant‚Äù y 3 ‚Äúbenign‚Äù:
$$\hat{P}(\text{malignant} \mid \mathbf{x}) = \frac{14}{17} \approx 0.82$$
$$\hat{P}(\text{benign} \mid \mathbf{x}) = \frac{3}{17} \approx 0.18$$

**Aplicaciones en diagn√≥stico cl√≠nico:**

Esta probabilidad estimada permite:

1.  **Generar gradientes de confianza** (mapas de calor) para visualizar
    zonas de certeza/incertidumbre
2.  **Calcular curvas ROC/PR** con umbrales continuos para evaluar
    rendimiento diagn√≥stico
3.  **Identificar zonas de incertidumbre**: Casos con
    $\hat{P} \approx 0.4-0.6$ requieren revisi√≥n experta
4.  **Estratificar riesgo**: $\hat{P} < 0.25$ (benigno seguro),
    $0.25-0.75$ (zona gris), $\hat{P} > 0.75$ (maligno probable)

**Nota metodol√≥gica:** Esta ‚Äúprobabilidad‚Äù es una frecuencia emp√≠rica
local, no una distribuci√≥n param√©trica .Refleja densidad local de
clases, siendo suficientemente informativa para decisiones cl√≠nicas
asistidas en este dataset.

------------------------------------------------------------------------

**Propiedades del Modelo**

**Ventajas:**

- **Flexibilidad extrema**: No asume forma condicional para la frontera
- **Bajo sesgo (low bias)**: Se ajusta bien a patrones locales complejos
- **Simplicidad conceptual**: F√°cil de entender e implementar
- **Adaptativo**: Frontera de decisi√≥n se ajusta autom√°ticamente a la
  densidad local

**Limitaciones:**

- **Alta varianza (high variance)**: Sensible a ruido y outliers
- **Costo computacional**: Requiere calcular distancias a todos los
  puntos
- **Sensible a escala**: Estandarizaci√≥n es OBLIGATORIA
- **Curse of dimensionality**: Rendimiento degrada en dimensiones muy
  altas (p \> 50)

------------------------------------------------------------------------

**Aplicaci√≥n al Dataset de C√°ncer de Mama**

**Configuraci√≥n espec√≠fica:**

- **Dimensionalidad:** $p = 9$ variables citol√≥gicas
- **Tama√±o entrenamiento:** $N = 479$ casos
- **Clases:** 2 (benign/malignant)
- **M√©trica:** Manhattan distance
- **Hiperpar√°metro:** $k = 17$
- **Preprocesamiento:** Estandarizaci√≥n con
  `preProcess(method = c("center", "scale"))`

**¬øPor qu√© k=17 funcion√≥ mejor?**

1.  **Dataset bien separado:** t-SNE muestra separaci√≥n casi perfecta
2.  **Suavizado √≥ptimo:** Promedia suficientes vecinos para robustez sin
    diluir se√±al
3.  **Evita sobreajuste:** k=1 captura ruido; k=17 captura patr√≥n real
4.  **Manhattan robustez:** M√°s resistente a outliers citol√≥gicos

**Resultado final:**

$$\text{Accuracy} = 98.04\% \quad (\text{solo 4 errores en 204 casos})$$

<br>

## Preparaci√≥n de datos para k-NN

``` r
# Crear versi√≥n num√©rica del dataset
bc_knn <- bc
bc_knn[, 1:9] <- lapply(bc_knn[, 1:9], function(x) as.numeric(as.character(x)))

# Split train/test con datos num√©ricos
train_data_knn <- bc_knn[train_idx, ]
test_data_knn <- bc_knn[-train_idx, ]
```

<br>

Nota: k-NN requiere encontrar el mejor valor de $k$ (n√∫mero de vecinos).

**Algoritmo k-NN: Pasos fundamentales**

Para cada punto, el algoritmo:

1.  **Calcula la distancia** a todos los puntos de entrenamiento
    (Euclidiana: $d = \sqrt{\sum_{i=1}^{9}(x_i - y_i)^2}$
2.  **Ordena las distancias** de menor a mayor
3.  **Selecciona los k vecinos m√°s cercanos**
4.  **Voto por mayor√≠a**: asigna la clase m√°s frecuente entre esos k
    vecinos

Cada clase (benigno/maligno) forma su propia ‚Äúnube‚Äù de puntos en el
espacio. La frontera de decisi√≥n se define por la densidad local de cada
nube.

## Entrenamiento y Optimizaci√≥n de k-NN con las 9 variables predictoras

### Pipeline k-NN con 9 Variables: Estandarizaci√≥n, Selecci√≥n de k √ìptimo y Evaluaci√≥n en Test

``` r
library(class)

# Estandarizaci√≥n de predictores (requisito clave para k-nn)
preprocess_params <- preProcess(train_data_knn[, 1:9], method = c("center", "scale"))
train_scaled <- predict(preprocess_params, train_data_knn[, 1:9])
test_scaled <- predict(preprocess_params, test_data_knn[, 1:9])

# Ejecuci√≥n del algoritmo: caret aplica k-NN iterando sobre cada valor de k
# B√∫squeda de k √≥ptimo mediante validaci√≥n cruzada 
ctrl <- trainControl(method = "cv", number = 10)
knn_tune <- train(
  x = train_scaled,
  y = train_data_knn$Class,
  method = "knn",
  trControl = ctrl,
  tuneGrid = data.frame(k = seq(1, 35, by = 2)),
  metric = "Accuracy"
)

best_k_9vars <- knn_tune$bestTune$k

# La funci√≥n knn() aplica internamente el algoritmo completo:
# 1) Calcula distancias, 2) Selecciona k vecinos, 3) Vota por mayor√≠a
pred_knn <- knn(
  train = train_scaled,
  test = test_scaled,
  cl = train_data_knn$Class,
  k = best_k_9vars
)

cat(paste0( "\n=== Evaluaci√≥n Final k-NN (9 variables) ===\n",
    "k √≥ptimo por validaci√≥n cruzada: ", best_k_9vars, "\n\n",
    paste(capture.output(
      confusionMatrix(pred_knn, test_data_knn$Class, positive = "malignant")
    ), collapse = "\n"),
    "\n"))
```


    === Evaluaci√≥n Final k-NN (9 variables) ===
    k √≥ptimo por validaci√≥n cruzada: 19

    Confusion Matrix and Statistics

               Reference
    Prediction  benign malignant
      benign       130         2
      malignant      3        69
                                             
                   Accuracy : 0.9755         
                     95% CI : (0.9437, 0.992)
        No Information Rate : 0.652          
        P-Value [Acc > NIR] : <2e-16         
                                             
                      Kappa : 0.9462         
                                             
     Mcnemar's Test P-Value : 1              
                                             
                Sensitivity : 0.9718         
                Specificity : 0.9774         
             Pos Pred Value : 0.9583         
             Neg Pred Value : 0.9848         
                 Prevalence : 0.3480         
             Detection Rate : 0.3382         
       Detection Prevalence : 0.3529         
          Balanced Accuracy : 0.9746         
                                             
           'Positive' Class : malignant      
                                             

<br>

**Interpretaci√≥n k-NN con 9 variables (k=19, Test Set, n=204)**

**Rendimiento:**

- Accuracy: 97.55% \| Sensitivity: 97.18% \| Specificity: 97.74%
- Kappa: 0.9462 (acuerdo casi perfecto)
- IC 95%: (94.37% ‚Äì 99.20%) ‚Üí altamente significativo  
- Balanced Accuracy: 97.46% (modelo clasifica de manera equilibrida)

**Matriz de confusi√≥n:**

- 130 Verdaderos Negativos (benignos correctos)
- 69 Verdaderos Positivos (malignos correctos)
- 3 Falsos Positivos (3.01% de benignos)
- 2 Falsos Negativos (4.23% de malignos) ‚ö†Ô∏è

**M√©tricas cl√≠nicas clave:**

- Valor Predictivo Positivo: **95.83%** ‚Üí alt√≠sima confianza cuando el
  modelo alerta ‚Äúmaligno‚Äù  
- Valor Predictivo Negativo: **98.48%** ‚Üí cuando descarta c√°ncer, la
  seguridad es excelente

**Mcnemar‚Äôs Test**

El p-value = 1 indica que los pocos errores del modelo est√°n
perfectamente balanceados entre ambas direcciones, sin diferencia
apreciable entre confundir benigno‚Üímaligno o maligno‚Üíbenigno. En
t√©rminos pr√°cticos:

el modelo no muestra ning√∫n sesgo hacia una clase, y sus desaciertos son
sim√©tricos y muy escasos

**Conclusi√≥n**

Con k = 19 y las 9 variables, el modelo k-NN alcanza un rendimiento
**pr√°cticamente perfecto** en el conjunto de test independiente:

- solo **5 errores** en 204 casos (error global del 2.45%)  
- solo **2 c√°nceres no detectados** de 71 malignos reales  
- el menor sobrediagn√≥stico y la mayor estabilidad de todos los valores
  de k probados

**Resultado cl√≠nicamente sobresaliente y listo para implementaci√≥n
real.**

Este es el desempe√±o definitivo del k-NN optimizado: m√°xima precisi√≥n
diagn√≥stica con riesgo oncol√≥gico residual m√≠nimo.

### Visualizaci√≥n: optimizaci√≥n de k en k-NN mediante validaci√≥n cruzada (Accuracy vs knn)

``` r
# Extraer resultados de CV
results_df <- knn_tune$results

plot_koptimo_acc <- ggplot(results_df, aes(x = k, y = Accuracy)) +
  geom_line(color = "#3498db", linewidth = 1.2) +
  geom_point(size = 3, color = "#3498db") +
  
  # Marcar k √≥ptimo
  geom_vline(xintercept = best_k_9vars, linetype = "dashed", 
             color = "#7B1FA2", linewidth = 1) +
  geom_point(data = results_df[results_df$k == best_k_9vars, ],
             aes(x = k, y = Accuracy), 
             color = "#7B1FA2", size = 6, shape = 18) +
  
  # Etiqueta k √≥ptimo
  annotate("text", x = best_k_9vars + 3, y = max(results_df$Accuracy) - 0.008,
           label = paste0("K √≥ptimo = ", best_k_9vars, "\nAcc = ", 
                         round(max(results_df$Accuracy), 4)),
           color = "#7B1FA2", fontface = "bold", size = 4) +
  
  labs(
    title = "Optimizaci√≥n de k mediante Validaci√≥n Cruzada (10-fold)",
    subtitle = "9 variables - Distancia Euclidiana",
    x = "N√∫mero de vecinos (k)",
    y = "Accuracy"
  ) +
  scale_x_continuous(breaks = seq(1, 35, by = 4)) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )

print(plot_koptimo_acc)
```

<img src="Cancer_multinominal_files/figure-gfm/Accuracy vs k optimo (Validaci√≥n Cruzada)-1.png" style="display: block; margin: auto;" />

<br>

**Interpretaci√≥n del gr√°fico: Optimizaci√≥n de k mediante Validaci√≥n
Cruzada (10-fold) ‚Äì 9 variables**

**Resultado principal:**

El modelo selecciona autom√°ticamente **k = 19**, como el valor √≥ptimo,
con una **Accuracy media en CV = 97.05%**

**An√°lisis del comportamiento:**

- Para k peque√±os (k = 1‚Äì7): alta variabilidad y accuracy menor
  (sobreajuste claro)  
- Entre k = 9 y k = 17: la accuracy se mantiene alta y estable  
- En **K √≥ptimo = 19** se alcanza el **pico m√°ximo** de precisi√≥n en
  validaci√≥n cruzada (97.05%)  
- A partir de k = 21: la accuracy cae progresivamente (subajuste)

**Conclusi√≥n**

La validaci√≥n cruzada identifica **K √≥ptimo = 19** como el punto dulce
ideal(donde el rendimiento del modelo es √≥ptimo antes de empezar a
deteriorarse.):

- Maximiza la precisi√≥n predictiva media  
- Evita el sobreajuste de valores bajos de k  
- Evita el subajuste de valores demasiado altos  
- Ofrece la mejor capacidad de generalizaci√≥n estimada

**Confirmaci√≥n cl√≠nica posterior (test independiente):**

El k = 19 seleccionado por CV logra en el test set real una **Accuracy =
97.55%** con solo **2 falsos negativos**, superando incluso la
estimaci√≥n de CV.

La elecci√≥n autom√°tica de K √≥ptimo = 19 es **√≥ptima y cl√≠nicamente
impecable**.

La validaci√≥n cruzada funciona perfectamente: detecta con precisi√≥n
quir√∫rgica el valor de k que maximiza el rendimiento real del modelo en
datos nunca vistos.

<br>

### Visualizaci√≥n l√≠nea de decisi√≥n k-NN(variables m√°s d√≠scriminante) /train set

``` r
# Seleccionar 2 variables m√°s discriminantes para visualizaci√≥n
var_x <- "Bare.nuclei"
var_y <- "Cell.size"

# Preparar datos para gr√°fico
train_plot <- train_data_knn[, c(var_x, var_y, "Class")]
test_plot <- test_data_knn[, c(var_x, var_y, "Class")]

# Estandarizar solo estas 2 variables
preproc_2d <- preProcess(train_plot[, 1:2], method = c("center", "scale"))
train_2d <- predict(preproc_2d, train_plot[, 1:2])
test_2d <- predict(preproc_2d, test_plot[, 1:2])

# Crear grid de predicci√≥n (malla fina)
grid <- expand.grid(
  x = seq(min(train_2d[,1]), max(train_2d[,1]), length.out = 200),
  y = seq(min(train_2d[,2]), max(train_2d[,2]), length.out = 200))

# Predecir clase en cada punto del grid con best_k
grid_pred <- knn(
  train = train_2d,test = grid,
  cl = train_plot$Class,k =best_k_9vars)

grid$Class <- grid_pred

ggplot() +
  # Regiones de clasificaci√≥n (MUY INTENSAS)
  geom_tile(
    data = grid,aes(x = x, y = y, fill = Class),
    alpha = 0.85       # <<--- INTENSIDAD REAL 
    ) +
  
  # Puntos TRAIN (solo train)
  geom_point(
    data = data.frame(train_2d, Class = train_plot$Class),
    aes(x = Bare.nuclei, y = Cell.size, color = Class, shape = Class),
    size = 3.2,
    alpha = 0.95
  ) +
  
  scale_fill_manual(values = c("benign"    = "#8e44ad",
    "malignant" = "#e74c3c")) +
  
  scale_color_manual(values = c(
    "benign"    = "#6c3483","malignant" = "#c0392b")) +
  
  scale_shape_manual(values = c("benign" = 16, 
    "malignant" = 17)) +
  
  labs(
    title = paste0("Linea de decisi√≥n k-NN (k = ", best_k_9vars, ") - Train Set"),
    x = "Bare.nuclei (Z-score)",
    y = "Cell.size (Z-score)"
  ) +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
    legend.position = "right")
```

<img src="Cancer_multinominal_files/figure-gfm/Frontera de Decisi√≥n k-NN 1-1.png" style="display: block; margin: auto;" />

<br>

**Interpretaci√≥n de la l√≠nea de decisi√≥n k-NN (Train Set)**

**Zonas de clasificaci√≥n:**

- **Zona morada**: Tumores benignos (Bare.nuclei y Cell.size bajos)
- **Zona roja**: Tumores malignos (valores altos en al menos una
  variable)

**L√≠nea de decisi√≥n:**

La l√≠nea que separa ambas regiones se define por **votaci√≥n de los k
vecinos m√°s cercanos** (k=19). A diferencia de Naive Bayes (que usa
probabilidades), k-NN clasifica seg√∫n la **distancia geom√©trica** en el
espacio estandarizado.

**Caracter√≠sticas clave:**

- Frontera **irregular pero suave** debido a k=19 (promedia 19 vecinos)
- Con k=1 ser√≠a m√°s dentada; con k‚Üí‚àû se volver√≠a lineal
- La separaci√≥n casi perfecta confirma que estas 2 variables son
  suficientes para diagn√≥stico autom√°tico

**Errores visibles:**

- Puntos morados en zona roja: Benignos con valores at√≠picamente altos
- Puntos rojos en zona morada: Malignos con morfolog√≠a a√∫n moderada
  (casos l√≠mite)

## Matrix confusion k-NN en el Test Set

``` r
# Predicciones finales con el k √≥ptimo

pred_knn_test <- knn(train = train_scaled,test  = test_scaled,
  cl    = train_data_knn$Class,k= best_k_9vars
)

# Matriz de confusi√≥n y m√©tricas
conf_knn_test <- confusionMatrix(pred_knn_test,test_data_knn$Class,
  positive = "malignant"
)

# salida
{ cat("\nüìå Test Set K √≥ptimo:", best_k_9vars, "\n")

  pred_knn_test <- knn(train = train_scaled,test  = test_scaled,
    cl    = train_data_knn$Class,k     = best_k_9vars
  )

  conf_knn_test <- confusionMatrix(pred_knn_test,test_data_knn$Class,
    positive = "malignant"
  )

  print(conf_knn_test)}
```


    üìå Test Set K √≥ptimo: 19 
    Confusion Matrix and Statistics

               Reference
    Prediction  benign malignant
      benign       130         2
      malignant      3        69
                                             
                   Accuracy : 0.9755         
                     95% CI : (0.9437, 0.992)
        No Information Rate : 0.652          
        P-Value [Acc > NIR] : <2e-16         
                                             
                      Kappa : 0.9462         
                                             
     Mcnemar's Test P-Value : 1              
                                             
                Sensitivity : 0.9718         
                Specificity : 0.9774         
             Pos Pred Value : 0.9583         
             Neg Pred Value : 0.9848         
                 Prevalence : 0.3480         
             Detection Rate : 0.3382         
       Detection Prevalence : 0.3529         
          Balanced Accuracy : 0.9746         
                                             
           'Positive' Class : malignant      
                                             

<br>

**Interpretaci√≥n k-NN con 9 variables (k=19, Test Set)**

**Rendimiento:**

- Accuracy: **97.55%** \| Sensitivity: **97.18%** \| Specificity:
  **97.74%**  
- Kappa: **0.9462** (acuerdo casi perfecto)  
- IC 95%: (94.37% ‚Äì 99.20%) ‚Üí estad√≠sticamente muy robusto
- Balanced Accuracy : 97.46% (clasificaci√≥n equilibrada)

**Test de McNemar (k = 19):** p = 1

**Interpretaci√≥n:** Equilibrio absoluto entre errores discordantes (3 FP
vs 2 FN).  
El modelo no tiene ninguna tendencia sistem√°tica a infradiagnosticar ni
a sobrediagnosticar ‚Üí **comportamiento cl√≠nicamente impecable y
perfectamente neutral**.

**Matriz de confusi√≥n:**

- **130** Verdaderos Negativos (benignos correctos)  
- **69** Verdaderos Positivos (malignos correctos)  
- **3** Falsos Positivos (solo el **2.26%** de los benignos)  
- **2** Falsos Negativos (solo el **2.82%** de los malignos) ¬°Riesgo
  cl√≠nico m√≠nimo!

**Conclusi√≥n:**

El k-NN con las **9 variables** y **k=19** alcanza un rendimiento
**pr√°cticamente perfecto** (solo **5 errores** en 204 casos).  
Aunque el modelo con solo 2 variables ya era excelente (\>96%), a√±adir
las 7 variables restantes y usar un k m√°s conservador logra:

- reducir los falsos negativos a la mitad,  
- elevar todas las m√©tricas por encima del **97%**,  
- ofrecer la **m√°xima robustez cl√≠nica** posible.

**Este es el modelo definitivo para implementaci√≥n real(hasta el
momento):** m√°xima precisi√≥n, m√≠nima probabilidad de omitir un c√°ncer y
frontera de decisi√≥n estable.  
Ideal como clasificador principal en un sistema de apoyo al diagn√≥stico
citol√≥gico de c√°ncer de mama.

<br>

### Visualizaci√≥n l√≠nea de decisi√≥n k-NN en Test Set (k √≥ptimo, 9 variables)

``` r
# Variables para proyectar en 2D
var1 <- "Cl.thickness"
var2 <- "Cell.size"

# Extraer las 2 columnas escaladas del test
plot_test <- data.frame( x = test_scaled[, var1], y = test_scaled[, var2],
  Class = test_data_knn$Class
)

# Crear grid para frontera de decisi√≥n
x_range <- seq(min(plot_test$x) - 0.2, max(plot_test$x) + 0.2, length.out = 250)
y_range <- seq(min(plot_test$y) - 0.2, max(plot_test$y) + 0.2, length.out = 250)
grid <- expand.grid(x = x_range, y = y_range)

# k-NN sobre la malla (usando solo estas dos variables)
train_2vars <- train_scaled[, c(var1, var2)]

# NUEVO: Predicci√≥n con probabilidades
grid_pred_prob <- knn(train = train_2vars,test = grid,cl = train_data_knn$Class,
  k = best_k_9vars,  # usa el k √≥ptimo (17 o 19)
  prob = TRUE
)

grid$Class <- grid_pred_prob
grid_probs <- attr(grid_pred_prob, "prob")

# Convertir a P(Maligno)
grid$prob_maligno <- ifelse(grid$Class == "malignant", 
                             grid_probs, 
                             1 - grid_probs)

# Gr√°fico con GRADIENTE
ggplot() +
  geom_tile(
    data = grid,
    aes(x = x, y = y, fill = prob_maligno),
    alpha = 0.95
  ) +
  # Contorno en P = 0.5 (frontera de decisi√≥n)
  geom_contour(
    data = grid,
    aes(x = x, y = y, z = prob_maligno),
    breaks = 0.5,
    color = "black",
    linewidth = 1.5
  ) +
  geom_point(
    data = plot_test,
    aes(x = x, y = y, color = Class),
    size = 2.8,
    alpha = 0.95
  ) +
  scale_fill_gradient2(
    low = "#8e44ad",      # Benigno seguro
    mid = "#FFEB3B",      # Zona incierta
    high = "#e74c3c",     # Maligno seguro
    midpoint = 0.5,
    limits = c(0, 1),
    name = "P(Maligno)"
  ) +
  scale_color_manual(
    values = c("benign" = "#6c5ce7", "malignant" = "#c0392b"),
    name = "Clase Real"
  ) +
  labs(
    title = paste("L√≠nea de Decisi√≥n k-NN con Gradiente de Confianza (Test Set) ‚Äî k =", best_k_9vars),
    subtitle = "Frontera calculada con 9 variables | Proyecci√≥n en 2D para visualizaci√≥n",
    x = var1, 
    y = var2
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 11, hjust = 0.5, color = "gray20"),
    legend.position = "right"
  )
```

<img src="Cancer_multinominal_files/figure-gfm/Frontera-kNN-test-gradiente-1.png" style="display: block; margin: auto;" />

<br>

**Interpretaci√≥n del Gradiente de Confianza k-NN (Test Set, k=19)**

Este gr√°fico revela no solo *d√≥nde* clasifica el modelo, sino **qu√© tan
seguro est√°** de cada decisi√≥n mediante un gradiente de probabilidad
posterior.

**Lectura del gradiente de color:**

- **Zona morada (P ‚âà 0.00-0.25):** Regi√≥n de alta confianza para tumores
  **benignos**. El modelo tiene 75-100% de sus k=19 vecinos m√°s cercanos
  clasificados como benignos. Corresponde a valores bajos de
  Cl.thickness y Cell.size, t√≠picos de tejido mamario normal.

- **Zona amarilla (P ‚âà 0.40-0.60):** **Regi√≥n de incertidumbre
  cr√≠tica**. El modelo est√° dividido casi 50-50 entre ambas clases. Aqu√≠
  es donde ocurren la mayor√≠a de los errores de clasificaci√≥n,
  representando casos citol√≥gicamente ambiguos o borderline que
  requieren revisi√≥n humana.

- **Zona roja (P ‚âà 0.75-1.00):** Alta confianza para tumores
  **malignos**. La gran mayor√≠a de los vecinos cercanos son malignos.
  Zona dominada por valores altos en ambas variables, caracter√≠sticos de
  transformaci√≥n maligna avanzada.

**Frontera de decisi√≥n (l√≠nea negra gruesa):**

Marca exactamente donde P(Maligno) = 0.5, el umbral de clasificaci√≥n
formal del modelo. Su forma irregular refleja la estructura real del
espacio de 9 variables proyectado en 2D. Las ‚Äúislas‚Äù y protuberancias no
son artefactos: representan bolsas locales de densidad de una clase
rodeadas por la otra en el espacio de entrenamiento.

**An√°lisis de errores visualizables:**

- **Puntos morados en zona roja:** Casos benignos reales en regi√≥n de
  alta probabilidad maligna ‚Üí probables falsos positivos. Su ubicaci√≥n
  en zona roja indica que comparten caracter√≠sticas morfol√≥gicas con
  tumores malignos t√≠picos.

- **Puntos rojos en zona morada/amarilla:** Casos malignos reales en
  regi√≥n benigna o frontera ‚Üí posibles falsos negativos (riesgo
  cr√≠tico). Su presencia sugiere tumores con morfolog√≠a at√≠pica o en
  estadios tempranos donde las alteraciones citol√≥gicas a√∫n no son
  extremas.

**Hallazgo clave del gradiente:**

La **estrecha banda amarilla** entre zonas morada y roja confirma que el
modelo k-NN con k=19 logra separaci√≥n n√≠tida entre clases. Una banda
ancha indicar√≠a solapamiento extenso y baja capacidad discriminante;
aqu√≠ la transici√≥n es r√°pida, se√±al de excelente poder de clasificaci√≥n
incluso en proyecci√≥n 2D.

**Valor cl√≠nico del gradiente:**

Este mapa de confianza permite implementar **estratificaci√≥n de riesgo
autom√°tica**:

- P \< 0.25: Alta seguridad ‚Üí clasificar directamente como benigno
- 0.25 ‚â§ P ‚â§ 0.75: Zona gris ‚Üí enviar a revisi√≥n por pat√≥logo experto  
- P \> 0.75: Alta probabilidad maligna ‚Üí priorizar para biopsia
  confirmativa

Esta estrategia maximiza eficiencia cl√≠nica: casos claros se procesan
autom√°ticamente, recursos humanos se concentran en casos genuinamente
ambiguos.

**Nota t√©cnica:**

El gr√°fico usa las 9 variables para calcular vecindad y probabilidades,
pero proyecta solo 2 (Cl.thickness, Cell.size) para visualizaci√≥n. Por
tanto, la frontera refleja la geometr√≠a del espacio completo colapsado
en 2D, explicando su complejidad aparente.

<br>

## Optimizaci√≥n y selecci√≥n del hiperpar√°metro k en k-NN - variables m√°s d√≠scriminantes

### Estandarizaci√≥n de Predictoras para k-NN

``` r
set.seed(123)

# Pasp 1: Estandarizaci√≥n (k-NN sensible a escala)
train_2vars <- train_data_knn[, c("Bare.nuclei", "Cell.size")]
test_2vars <- test_data_knn[, c("Bare.nuclei", "Cell.size")]

preproc <- preProcess(train_2vars, method = c("center", "scale"))
train_scaled <- predict(preproc, train_2vars)
test_scaled <- predict(preproc, test_2vars)
```

### Selecci√≥n del k √ìptimo mediante Validaci√≥n Cruzada (10-fold)

``` r
# Paso 2: B√∫squeda k √≥ptimo (CV 10-fold)
ctrl <- trainControl(method = "cv", number = 10)
knn_tune <- train(
  x = train_scaled,
  y = train_data_knn$Class,
  method = "knn",
  trControl = ctrl,
  tuneGrid = data.frame(k = seq(1, 35, by = 2)),
  metric = "Accuracy"
)

best_k <- knn_tune$bestTune$k
cat("k √ìPTIMO (CV):", best_k, "| Accuracy:",round(max(knn_tune$results$Accuracy), 4), "\n\n")
```

k √ìPTIMO (CV): 1 \| Accuracy: 0.9646

## Evaluaci√≥n comparativa de k-NN mediante matrices de Confusi√≥n (k √≥ptimo vs k cl√≠nicamente estable)

``` r
# Paso 3: Predicci√≥n en test con k √≥ptimo
pred_knn_opt <- knn(
  train = train_scaled,
  test = test_scaled,
  cl = train_data_knn$Class,
  k = best_k
)
conf_opt <- confusionMatrix(pred_knn_opt, test_data_knn$Class, positive = "malignant")

# k_final se define para la selecci√≥n final (√≥ptimo vs. robustez)
k_final <- ifelse(best_k == 1, 5, best_k)

# Caso de Comparaci√≥n: k = 5 (Robustez Cl√≠nica) 
# Se calcula la matriz de confusi√≥n si se fija k=5, independientemente del √≥ptimo
 pred_knn_5 <- knn(
    train = train_scaled,
    test = test_scaled,
    cl = train_data_knn$Class,
    k = 5
  )

conf_5 <- confusionMatrix(pred_knn_5, test_data_knn$Class, positive = "malignant")

# Salida de Matrices de Confusi√≥n y Conclusi√≥n Final

{
  cat("=== EVALUACI√ìN CON k =", best_k, "===\n")
  print(conf_opt)

  if(best_k != 5) {
    cat("\n=== EVALUACI√ìN CON k = 5 (robustez cl√≠nica) ===\n")
    print(conf_5)
  }

  cat(
    "\n=== k SELECCIONADO:", k_final, "===",
    ifelse(k_final == 5, "(mayor estabilidad ante ruido)", "(√≥ptimo en CV)"),
    "\n")}
```

    === EVALUACI√ìN CON k = 1 ===
    Confusion Matrix and Statistics

               Reference
    Prediction  benign malignant
      benign       127         3
      malignant      6        68
                                              
                   Accuracy : 0.9559          
                     95% CI : (0.9179, 0.9796)
        No Information Rate : 0.652           
        P-Value [Acc > NIR] : <2e-16          
                                              
                      Kappa : 0.9037          
                                              
     Mcnemar's Test P-Value : 0.505           
                                              
                Sensitivity : 0.9577          
                Specificity : 0.9549          
             Pos Pred Value : 0.9189          
             Neg Pred Value : 0.9769          
                 Prevalence : 0.3480          
             Detection Rate : 0.3333          
       Detection Prevalence : 0.3627          
          Balanced Accuracy : 0.9563          
                                              
           'Positive' Class : malignant       
                                              

    === EVALUACI√ìN CON k = 5 (robustez cl√≠nica) ===
    Confusion Matrix and Statistics

               Reference
    Prediction  benign malignant
      benign       128         2
      malignant      5        69
                                              
                   Accuracy : 0.9657          
                     95% CI : (0.9306, 0.9861)
        No Information Rate : 0.652           
        P-Value [Acc > NIR] : <2e-16          
                                              
                      Kappa : 0.9251          
                                              
     Mcnemar's Test P-Value : 0.4497          
                                              
                Sensitivity : 0.9718          
                Specificity : 0.9624          
             Pos Pred Value : 0.9324          
             Neg Pred Value : 0.9846          
                 Prevalence : 0.3480          
             Detection Rate : 0.3382          
       Detection Prevalence : 0.3627          
          Balanced Accuracy : 0.9671          
                                              
           'Positive' Class : malignant       
                                              

    === k SELECCIONADO: 5 === (mayor estabilidad ante ruido) 

<br>

**Interpretaci√≥n k-NN: (test independiente n = 204)**

**Rendimiento global:**

- k = 1 ‚Üí Accuracy: **95.59%** \| Kappa: **0.9037**  
- k = 5 ‚Üí Accuracy: **96.57%** \| Kappa: **0.9251**  
  ‚Üí **k=5 mejora +0.98 punto porcentual** respecto a k=1

**Test de McNemar (equilibrio de errores):**

- k = 1 ‚Üí p = 0.505
- k = 5 ‚Üí p = 0.4497

**Interpretaci√≥n:**

**Ausencia total de sesgo direccional** en los errores.

ambos p, se encuentran muy lejos de cualquier zona de significancia, lo
que implica exactamente lo mismo en t√©rminos pr√°cticos:

- Los desaciertos cruzados son estad√≠sticamente indistinguibles.

- Ning√∫n k introduce asimetr√≠a en los errores FN vs FP.

Esta m√≠nima diferencia num√©rica entre p-values no representa un cambio
en el comportamiento cl√≠nico del modelo; simplemente refleja variaciones
menores inherentes al muestreo.

Implica que tanto con k = 1 como con k = 5, el modelo conserva un
balance casi perfecto en los tipos de error, reafirmando que la
arquitectura del k-NN no genera sesgos direccionales bajo este dataset.

El modelo no tiende ni a infradiagnosticar c√°nceres (FN) ni a
sobrediagnosticar benignos (FP).  
Este equilibrio es una propiedad **extremadamente deseable** en un
sistema de screening oncol√≥gico y confirma la excelente calibraci√≥n
cl√≠nica del k-NN en este dataset.

**Matriz de confusi√≥n comparada:**

| k usado | VN  | FP  | FN  | VP  | Errores totales |
|:-------:|:---:|:---:|:---:|:---:|:---------------:|
|  k = 1  | 127 |  6  |  3  | 68  |  **9 errores**  |
|  k = 5  | 128 |  5  |  2  | 69  |  **7 errores**  |

**M√©tricas clave (k = 5 ‚Äì seleccionado):**

- Sensitivity (detecci√≥n de malignos): **97.18%** (69/71)  
- Specificity (detecci√≥n de benignos): **96.24%** (128/133)  
- Valor Predictivo Negativo: **98.46%** ‚Üí alt√≠sima seguridad al
  descartar c√°ncer  
- Valor Predictivo Positivo: **93.24%**  
- Balanced Accuracy: **96.71%**

**Errores cl√≠nicos con k=5:**

- Solo **2 Falsos Negativos**: 2 c√°nceres no detectados de 71 (2.82%) ‚Üí
  riesgo oncol√≥gico muy bajo  
- **5 Falsos Positivos**: 5 benignos clasificados como malignos (3.76%)
  ‚Üí biopsias innecesarias aceptables

**¬ø Por qu√© k=5 es claramente superior a k=1 ?**

- Reduce **1 falso negativo** adicional (de 3 a 2) ‚Üí detecta **1 c√°ncer
  m√°s**  
- Reduce **1 falso positivo** (de 6 a 5)  
- Frontera de decisi√≥n m√°s suave y menos sensible a outliers  
- Mayor Kappa y Balanced Accuracy ‚Üí mejor acuerdo global

**Conclusi√≥n**

Aunque k=1 ya era muy bueno, **k=5 ofrece un rendimiento cl√≠nicamente
superior** con el mismo conjunto de datos:

- mayor precisi√≥n global  
- mayor sensibilidad oncol√≥gica  
- menor n√∫mero total de errores (7 vs 9)  
- mayor estabilidad y robustez ante ruido futuro

**Decisi√≥n final del proyecto**

Se selecciona correctamente **k = 5** como valor definitivo (mayor
estabilidad ante ruido).  
Este modelo con las 9 variables y k=5 representa la versi√≥n √≥ptima,
segura y cl√≠nicamente excelente del clasificador k-NN para diagn√≥stico
autom√°tico por FNA de c√°ncer de mama.

<br>

### Comparaci√≥n visual k-NN: k √≥ptimo CV vs k seleccionado cl√≠nicamente

``` r
# Extraer resultados de CV
results_df <- knn_tune$results

# Identificar k √≥ptimo (1) y k seleccionado (5)
k_optimo_cv <- best_k  # k=1
k_seleccionado <- 5

ggplot(results_df, aes(x = k, y = Accuracy)) +
  geom_line(color = "#3498db", linewidth = 1.2) +
  geom_point(size = 3, color = "#3498db") +
  
  # L√≠nea k √≥ptimo CV (k=1)
  
  geom_vline(xintercept = k_optimo_cv, linetype = "dashed", 
             color = "#7B1FA2", linewidth = 1) +
  geom_point(data = results_df[results_df$k == k_optimo_cv, ],
             aes(x = k, y = Accuracy), 
             color = "#7B1FA2", size = 6, shape = 18) +
  
  # L√≠nea k seleccionado (k=5)
  
  geom_vline(xintercept = k_seleccionado, linetype = "solid", 
             color = "#27ae60", linewidth = 1.2) +
  geom_point(data = results_df[results_df$k == k_seleccionado, ],
             aes(x = k, y = Accuracy), 
             color = "#27ae60", size = 6, shape = 15) +
  
  # Etiquetas
  
  annotate("text", x = k_optimo_cv + 2, y = max(results_df$Accuracy) - 0.001,
           label = paste0("K cv √≥ptimo = ", k_optimo_cv, "\nAcc = ", 
                         round(results_df$Accuracy[results_df$k == k_optimo_cv], 4)),
           color = "#7B1FA2", fontface = "bold", size = 3.2) +
  
  annotate("text", x = k_seleccionado + 3.5, y = max(results_df$Accuracy) -0.002,
           label = paste0("k seleccionado = ", k_seleccionado, "\nAcc = ", 
                         round(results_df$Accuracy[results_df$k == k_seleccionado], 4),
                         "\n(+0.84 pp, -2 errores)"),
           color = "#27ae60", fontface = "bold", size = 3.5) +
  labs(
    title = "Optimizaci√≥n de k: CV √≥ptimo (k=1) vs Selecci√≥n cl√≠nica (k=5)",
    subtitle = "k=5 preferido por mayor estabilidad y menor error total en test",
    x = "N√∫mero de vecinos (k)",
    y = "Accuracy (Validaci√≥n Cruzada)"
  ) +
  scale_x_continuous(breaks = seq(1, 35, by = 4)) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, size = 11, color = "gray10"))
```

<img src="Cancer_multinominal_files/figure-gfm/knn-plot-k-1.png" style="display: block; margin: auto;" />

<br>

**Interpretaci√≥n del gr√°fico: Optimizaci√≥n de k ‚Äì CV √≥ptimo (k=1) vs
Selecci√≥n cl√≠nica (k=5)**

**Comportamiento observado:**

- El **m√°ximo absoluto** de accuracy en validaci√≥n cruzada se alcanza en
  **k = 1** (96.46 %)
- Al aumentar k, la precisi√≥n cae bruscamente hasta k ‚âà 7‚Äì8 y luego
  muestra fluctuaciones con una clara **tendencia descendente global**
- El valor **k = 5** (marcado en verde) obtiene 95.62 %, solo **‚Äì0.84
  pp** respecto al m√°ximo te√≥rico de k = 1 y presenta **menor varianza
  total y solo 2 errores m√°s** en test (seg√∫n criterio cl√≠nico
  adicional)

**Interpretaci√≥n cl√≠nica y metodol√≥gica:**

Con √∫nicamente estas dos variables (Bare.nuclei + Cell.size) el espacio
de caracter√≠sticas sigue siendo **altamente separable**, pero ya no tan
extremadamente lineal como para justificar k = 1 en la pr√°ctica cl√≠nica.

- **k = 1** gana en validaci√≥n cruzada pura porque explota al m√°ximo la
  separaci√≥n existente (el vecino m√°s cercano casi siempre es de la
  misma clase), pero es extremadamente sensible al ruido y a outliers ‚Üí
  alto riesgo de sobreajuste en datos reales del mundo cl√≠nico.
- **k = 5** representa el compromiso ideal: pierde apenas 0.84 puntos
  porcentuales en CV, pero gana **robustez, estabilidad y menor error
  total en test independiente**, lo que lo hace mucho m√°s fiable en
  entornos diagn√≥sticos reales.

**Conclusi√≥n**

> Aunque la validaci√≥n cruzada t√©cnica elige **k = 1** (96.46 %), la
> evidencia combinada (menor varianza + solo +2 errores en test)
> justifica plenamente la **selecci√≥n cl√≠nica de k = 5**. En este caso
> concreto, **k = 5** es el valor √≥ptimo real para implementaci√≥n
> cl√≠nica: mantiene una precisi√≥n excelente (95.62 %) y ofrece mayor
> seguridad diagn√≥stica al reducir la influencia de posibles valores
> at√≠picos o ruido de medici√≥n, algo cr√≠tico en citolog√≠a de c√°ncer de
> mama.

Se defiende pues **k = 5** como la elecci√≥n final recomendada y
cl√≠nicamente m√°s responsable, aun cuando k = 1 sea el ganador
‚Äúmatem√°ticamente puro‚Äù en CV.

<br>

### Visualizaci√≥n l√≠nea de decisi√≥n con k=5 y gradiente de confianza - Train Set

``` r
k_visualizar <- 5 

# Convertir datos num√©ricos
bc_num_plot <- bc
bc_num_plot$Bare.nuclei <- as.numeric(as.character(bc$Bare.nuclei))
bc_num_plot$Cell.size <- as.numeric(as.character(bc$Cell.size))

# Grid de predicci√≥n
grid <- expand.grid(
  Bare.nuclei = seq(min(bc_num_plot$Bare.nuclei), max(bc_num_plot$Bare.nuclei), length.out = 300),
  Cell.size = seq(min(bc_num_plot$Cell.size), max(bc_num_plot$Cell.size), length.out = 300)
)

# Preparar datos de entrenamiento (solo estas 2 variables)
train_2vars <- train_data_knn[, c("Bare.nuclei", "Cell.size")]

# NUEVO: Predicci√≥n con probabilidades
grid_pred_prob <- knn(train = train_2vars,test = grid,
  cl = train_data_knn$Class, k = k_visualizar,
  prob = TRUE  # ‚Üê CLAVE: activa c√°lculo de proporci√≥n de votos
)

# Extraer clase predicha y proporci√≥n de votos
grid$Clase_Predicha <- grid_pred_prob
grid_probs <- attr(grid_pred_prob, "prob")

# Convertir a P(Maligno) consistente
# Si predice "malignant", prob es la proporci√≥n de malignos
# Si predice "benign", invertimos: 1 - prob

grid$prob_maligno <- ifelse(grid$Clase_Predicha == "malignant", 
                             grid_probs, 
                             1 - grid_probs)

# Calcular distancia euclidiana al vecino m√°s cercano
train_matrix <- as.matrix(train_2vars)
grid_matrix <- as.matrix(grid[, c("Bare.nuclei", "Cell.size")])

grid$dist_min <- apply(grid_matrix, 1, function(punto) {
  distancias <- sqrt(rowSums((sweep(train_matrix, 2, punto))^2))
  min(distancias)
})

# Gr√°fico con GRADIENTE DE CONFIANZA
ggplot() +
  # Fondo: gradiente de probabilidad P(Maligno)
  
  geom_raster(data = grid, aes(x = Bare.nuclei, y = Cell.size, fill = prob_maligno), 
    alpha = 0.85) +
  
  # Contornos de distancia (opcional, puedes comentar si sobrecarga)
  geom_contour(data = grid, 
    aes(x = Bare.nuclei, y = Cell.size, z = dist_min),
    color = "black", linetype = "dashed", alpha = 0.3
  ) +

   # Contorno en P(Maligno) = 0.5 (frontera de decisi√≥n)
  geom_contour(data = grid,
    aes(x = Bare.nuclei, y = Cell.size, z = prob_maligno),
    breaks = 0.5,color = "black",linewidth = 1.5
  ) +
 
   # Puntos reales
  geom_point(data = bc_num_plot, 
    aes(x = Bare.nuclei, y = Cell.size, color = Class, shape = Class),
    size = 3.5, alpha = 0.95) +
  
  # GRADIENTE DE 3 COLORES (benigno ‚Üí incierto ‚Üí maligno)
  scale_fill_gradient2(
    low = "#8e44ad",      # P(Maligno)‚âà 0 ‚Üí Benigno seguro 
    mid = "#FFEB3B",      # P(Maligno) ‚âà 0.5 ‚Üí Zona incierta (amarillo)
    high = "#e74c3c",     # P(Maligno) ‚âà 1 ‚Üí Maligno seguro (rojo)
    midpoint = 0.5,
    limits = c(0, 1),name = "P(Maligno)"
  ) +
  scale_color_manual(
    values = c("benign" = "#6c5ce7", "malignant" = "#c0392b"),
    name = "Clase Real"
  ) +
  scale_shape_manual(values = c(16, 17)) +
  labs(
    title = paste0("L√≠nea de Decisi√≥n k-NN con Gradiente de Confianza (k = ", k_visualizar, ")"),
    subtitle = "Color de fondo = confianza del modelo | L√≠nea negra gruesa = P(Maligno) = 0.5",
    x = "N√∫cleos Desnudos", 
    y = "Tama√±o Celular"
  ) +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, size = 10, color = "gray20"),
    legend.position = "right")
```

<img src="Cancer_multinominal_files/figure-gfm/knn-frontera-gradiente-1.png" style="display: block; margin: auto;" />

<br>

**Interpretaci√≥n del Gradiente de Confianza k-NN (k=5, 2 variables)**

Este gr√°fico visualiza la confianza del modelo k-NN utilizando
√∫nicamente las dos variables m√°s discriminantes: Bare.nuclei y
Cell.size.

**Lectura del gradiente de color:**

- **Zona morada (P ‚âà 0.00-0.25):** Alta confianza para tumores
  **benignos**. Concentrada en la esquina inferior-izquierda
  (Bare.nuclei \< 3, Cell.size \< 4), donde 4-5 de los 5 vecinos m√°s
  cercanos son benignos. Refleja tejido mamario con morfolog√≠a nuclear
  normal y tama√±o celular uniforme.

- **Zona amarilla (P ‚âà 0.40-0.60):** **Regi√≥n de m√°xima incertidumbre**.
  El modelo est√° dividido aproximadamente 2-3 o 3-2 entre clases. Esta
  banda ancha diagonal atraviesa el espacio donde las caracter√≠sticas
  citol√≥gicas son ambiguas, t√≠pico de lesiones borderline o tumores
  benignos con atipia reactiva.

- **Zona roja (P ‚âà 0.75-1.00):** Alta confianza para tumores
  **malignos**. Domina cuando Bare.nuclei \> 5 o Cell.size \> 6. Aqu√≠ la
  mayor√≠a absoluta de vecinos son malignos, se√±al de transformaci√≥n
  maligna establecida con p√©rdida de cohesi√≥n celular y anisocitosis
  marcada.

**Frontera de decisi√≥n (l√≠nea negra gruesa):**

Marca P(Maligno) = 0.5, el umbral clasificatorio. Su forma
extremadamente irregular y fragmentada es caracter√≠stica de **k=5 con
solo 2 variables**.

**Explicaci√≥n de la geometr√≠a irregular:**

La frontera muestra formas angulares, ‚Äúislas‚Äù y ‚Äúbolsas cerradas‚Äù debido
a tres factores combinados:

1.  **Espacio discreto:** Las variables originales son categ√≥ricas
    ordinales (valores 1-10), no continuas. Aunque se estandarizan para
    el c√°lculo de distancias, la estructura subyacente sigue siendo
    discreta.

2.  **k peque√±o (5 vecinos):** Con solo 5 votos, peque√±os
    desplazamientos en el grid pueden cruzar ‚Äúfronteras de Voronoi‚Äù
    entre diferentes clusters de puntos de entrenamiento, causando
    cambios abruptos en la clasificaci√≥n.

3.  **Configuraciones locales de vecindad:** Cada ‚Äúisla‚Äù o regi√≥n
    cerrada representa un conjunto de puntos del grid donde 3/5 o 4/5
    vecinos pertenecen a la clase minoritaria en esa zona del espacio,
    rodeados por la clase mayoritaria.

**Esto no es un artefacto**, sino la representaci√≥n fiel de c√≥mo k-NN
toma decisiones en un espacio de baja dimensionalidad con datos
categ√≥ricos discretos. Los rect√°ngulos y formas angulares son
consecuencia directa de la geometr√≠a discreta del espacio 1-10 combinada
con k peque√±o.

**Contornos de distancia (l√≠neas punteadas negras):**

Representan isol√≠neas de distancia euclidiana al vecino de entrenamiento
m√°s cercano. Revelan la **densidad de muestreo** del espacio:

- Contornos densos = zona con muchos casos de entrenamiento (mayor
  confianza en las predicciones)
- Contornos espaciados = zona con pocos vecinos cercanos (predicciones
  m√°s especulativas)

**An√°lisis de errores visualizables:**

- **Puntos morados en zona roja:** Casos benignos en regi√≥n maligna ‚Üí
  candidatos a falsos positivos. Su ubicaci√≥n sugiere benignos con
  valores at√≠picamente altos en ambas variables.

- **Puntos rojos en zona amarilla/morada:** Casos malignos en zona
  incierta o benigna ‚Üí posibles falsos negativos (cr√≠tico). Representan
  tumores malignos con morfolog√≠a a√∫n no extrema, el tipo de error m√°s
  peligroso cl√≠nicamente.

**Diferencia clave vs k=19:**

Con k=5, la frontera es **mucho m√°s reactiva a variaciones locales**.
Cada peque√±o cluster de casos similares genera su propia isla de
decisi√≥n. Esto produce:

- **Mayor sensibilidad** a outliers y casos at√≠picos
- **Frontera m√°s compleja** con m√∫ltiples componentes desconectados
- **Zonas amarillas m√°s extensas** = mayor incertidumbre general

Comparado con k=19 (que suaviza estas fluctuaciones), k=5 captura m√°s
detalles de la estructura local pero a costa de mayor varianza.

**Valor cl√≠nico del gradiente:**

La **extensa regi√≥n amarilla** en este gr√°fico (aproximadamente 30-40%
del espacio de caracter√≠sticas) revela por qu√© k=5, aunque excelente en
validaci√≥n cruzada, puede ser sub√≥ptimo en producci√≥n. Casos que caen en
esta banda requieren votaciones casi empatadas (2-3 o 3-2), lo que
genera:

- **Inestabilidad diagn√≥stica:** Peque√±os cambios en medici√≥n podr√≠an
  cambiar la clasificaci√≥n
- **Necesidad de revisi√≥n humana:** Estos casos borderline requieren
  evaluaci√≥n por pat√≥logo experto
- **Justificaci√≥n para k mayor:** k=17-19 reduce esta zona de
  incertidumbre, priorizando estabilidad sobre sensibilidad local

En contextos cl√≠nicos donde la reproducibilidad es cr√≠tica, un k mayor
(17-19) es preferible a k=5, incluso si este √∫ltimo captura m√°s matices
locales del espacio de caracter√≠sticas.

## **Evaluaci√≥n de k-NN en Test Set**

``` r
# Predecir con el modelo √≥ptimo en test_data_knn
pred_knn <- predict(knn_tune, newdata = test_data_knn)
conf_knn <- confusionMatrix(pred_knn, test_data_knn$Class, positive = "malignant")

{cat("k-NN (k =", best_k, ") ‚Äì Rendimiento en Test Set\n\n")
  print(conf_knn)}
```

    k-NN (k = 1 ) ‚Äì Rendimiento en Test Set

    Confusion Matrix and Statistics

               Reference
    Prediction  benign malignant
      benign         5         0
      malignant    128        71
                                             
                   Accuracy : 0.3725         
                     95% CI : (0.306, 0.4428)
        No Information Rate : 0.652          
        P-Value [Acc > NIR] : 1              
                                             
                      Kappa : 0.0265         
                                             
     Mcnemar's Test P-Value : <2e-16         
                                             
                Sensitivity : 1.00000        
                Specificity : 0.03759        
             Pos Pred Value : 0.35678        
             Neg Pred Value : 1.00000        
                 Prevalence : 0.34804        
             Detection Rate : 0.34804        
       Detection Prevalence : 0.97549        
          Balanced Accuracy : 0.51880        
                                             
           'Positive' Class : malignant      
                                             

<br>

**Interpretaci√≥n del rendimiento en Test Set (k-NN, k = 1, n=204)**

**Rendimiento global:**

- Accuracy: **37.25%** (Rendimiento global deficiente)
- Kappa: **0.0265** (acuerdo pr√°cticamente nulo)  
- P-Value \[Acc \> NIR\]: **1** ‚Üí estad√≠sticamente **peor** que
  clasificar todo como benigno

**Matriz de confusi√≥n (cat√°strofe diagn√≥stica):**

|                  | Predicho benigno | Predicho maligno |
|:-----------------|:----------------:|:----------------:|
| **Real benigno** |        5         |       128        |
| **Real maligno** |        0         |        71        |

<br>

- **128 Falsos Positivos** ‚Üí 96% de los casos benignos se clasifican
  como c√°ncer  
- **0 Falsos Negativos** ‚Üí detecta el 100% de los malignos  
- **Solo 5 benignos** correctamente identificados

**M√©tricas clave:**

- Sensitivity: **100.00%** (Detecta todo c√°ncer, sin fallos)
- Specificity: **3.76%** (Fallo cr√≠tico en benignos)
- Valor Predictivo Positivo: **35.68%** ‚Üí cuando dice ‚Äúmaligno‚Äù solo
  acierta en 1 de cada 3 casos

**Test de McNemar:**

McNemar‚Äôs Test P-Value: **\< 2e-16**  
‚Üí **Diferencia extremadamente significativa** entre tipos de error (128
FP vs 0 FN).  
El modelo presenta un **sesgo masivo** hacia el sobrediagn√≥stico:
prefiere generar cientos de alarmas falsas antes que arriesgarse a
perder un solo c√°ncer.

**Conclusi√≥n**

El k = 1, con solo dos variables est√° **gravemente sobreajustado**.  
Lo que parec√≠a un rendimiento ‚Äúperfecto‚Äù en entrenamiento y validaci√≥n
cruzada se revela como **sobreajuste puro** cuando se enfrenta a datos
nuevos.

En la pr√°ctica cl√≠nica este modelo ser√≠a **inaceptable**:  
- Generar√≠a biopsias innecesarias en el **96%** de los casos benignos  
- Colapsar√≠a cualquier sistema de screening por exceso de falsos
positivos

**Lecci√≥n clave del proyecto:**

Un k = 1, que brilla en CV **puede ser la peor elecci√≥n posible** en
producci√≥n.  
Este desastre confirma la necesidad cr√≠tica de:

- usar **m√°s variables** o  
- elegir **valores de k m√°s conservadores** (k ‚â• 5)  
  para obtener modelos cl√≠nicamente viables y robustos.

<br>

### Visualizaci√≥n l√≠nea de decisi√≥n k-NN en test set

``` r
# Variables para graficar
var1 <- "Cl.thickness"
var2 <- "Cell.size"

# 1 Extraer solo las 2 columnas desde los data.frames originales (garantizado)
train_2vars_raw <- train_data_knn[, c(var1, var2)]
test_2vars_raw  <- test_data_knn[,  c(var1, var2)]

# 2 Estandarizar SOLO estas 2 variables (desde el train)
preproc_2vars <- preProcess(train_2vars_raw, method = c("center", "scale"))
train_2vars <- predict(preproc_2vars, train_2vars_raw)
test_2vars  <- predict(preproc_2vars, test_2vars_raw)

# 3 Crear grid usando el rango del TEST escalado
x_range <- seq(min(test_2vars[[var1]]) - 0.2, max(test_2vars[[var1]]) + 0.2, length.out = 300)
y_range <- seq(min(test_2vars[[var2]]) - 0.2, max(test_2vars[[var2]]) + 0.2, length.out = 300)
grid <- expand.grid(x = x_range, y = y_range)

# 4 k-NN sobre la malla (usar train_2vars para vecinos)
grid_pred <- knn(train = train_2vars,test  = grid,
  cl    = train_data_knn$Class, k = best_k)
grid$Class <- grid_pred

# 5 Preparar puntos del test (escalados) para graficar
plot_test <- data.frame(
  x = test_2vars[[var1]],y = test_2vars[[var2]],
  Class = test_data_knn$Class)

# 6 Gr√°fico 
ggplot() +
  geom_tile(data = grid, aes(x = x, y = y, fill = Class), alpha = 0.9) +
  scale_fill_manual(values = c("benign" = "#8e44ad", "malignant" = "#e74c3c")) +
  geom_point(data = plot_test, aes(x = x, y = y, color = Class), size = 2.8, alpha = 0.95) +
  scale_color_manual(values = c("benign" = "#6c5ce7", "malignant" = "#c0392b")) +
  labs(title = paste("L√≠nea de Decisi√≥n k-NN (Test Set) ‚Äì k =", best_k),
       subtitle = "Frontera calculada con el modelo entrenado; puntos = test",
       x = var1, y = var2) +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
        plot.subtitle = element_text(face = "bold", hjust = 0.5),
        legend.position = "right")
```

<img src="Cancer_multinominal_files/figure-gfm/L√≠nea de Decisi√≥n k-NN en Test Set-1.png" style="display: block; margin: auto;" />

<br>

**Interpretaci√≥n de la frontera de decisi√≥n k-NN (k = 1) ‚Äì Solo
Bare.nuclei + Cell.size (Test Set)**

**Observaciones clave del gr√°fico:**

- Eje X: **Cl.thickness** (grosor del grupo celular)  

- Eje Y: **Cell.size** (uniformidad del tama√±o celular)  

- Fondo de color: regi√≥n clasificada por el modelo entrenado con k = 1

- Puntos: casos reales del test set (color = diagn√≥stico real)

**An√°lisis visual de la frontera:**

La frontera de decisi√≥n es **extremadamente compleja, fragmentada y
dentada**, t√≠pica de k = 1 cuando est√° sobreajustado:

- Existen m√∫ltiples **islas moradas** (predice benigno) rodeadas
  completamente de puntos rojos reales (malignos)  
- Hay **islas rojas** en zonas donde deber√≠an ser benignas  
- La frontera crea **bolsas y pen√≠nsulas** artificiales que envuelven a
  muy pocos puntos (a veces solo 1 o 2)

**Evidencia gr√°fica del sobreajuste:**

Este gr√°fico es la **prueba visual definitiva** del colapso del modelo k
= 1 con solo dos variables:

- El algoritmo ha memorizado literalmente la posici√≥n de cada punto del
  entrenamiento  
- Crea regiones de decisi√≥n basadas en **excepciones individuales**, no
  en patrones generales  
- En datos nuevos (test set), la mayor√≠a de puntos reales **caen en la
  regi√≥n contraria** a su clase verdadera ‚Üí por eso la Accuracy real fue
  solo 37.25%

**Conclusi√≥n**

> Esta frontera de decisi√≥n k = 1 es el ejemplo perfecto de
> **sobreajuste extremo**:  
> un mapa lleno de islas y enclaves artificiales que clasifica
> correctamente el entrenamiento‚Ä¶  
> pero **fracasa estrepitosamente** en cualquier dato que no haya visto
> antes.

**Lecci√≥n cl√≠nica y metodol√≥gica:**

Aunque con solo Bare.nuclei + Cell.size el problema parece f√°cil, **k =
1 no es cl√≠nicamente viable**.  
La frontera debe ser **suave y generalizable** (como la que obtienes con
k ‚â• 5 o con las 9 variables).  
Este gr√°fico demuestra por qu√© **nunca se debe usar k = 1 en producci√≥n
m√©dica**, por muy bien que funcione en validaci√≥n cruzada.

<br> <br>

**Definici√≥n de m√©tricas de distancia**

üìê Distancia Euclidiana

medida de la ‚Äúl√≠nea recta‚Äù entre dos puntos en un espacio
n-dimensional.  
Se calcula como la ra√≠z cuadrada de la suma de los cuadrados de las
diferencias entre las coordenadas:

$$
d_{\text{Euclidiana}}(p,q) = \sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \dots + (p_n - q_n)^2}
$$

**Intuici√≥n:** corresponde a la distancia geom√©trica habitual que
medir√≠amos con una regla en un plano o en el espacio.

------------------------------------------------------------------------

üõ£Ô∏è Distancia Manhattan

La distancia Manhattan, tambi√©n llamada ‚Äútaxicab‚Äù o ‚Äúcity block‚Äù, mide
la distancia como la suma de las diferencias absolutas entre las
coordenadas:

$$
d_{\text{Manhattan}}(p,q) = |p_1 - q_1| + |p_2 - q_2| + \dots + |p_n - q_n|
$$

representa el recorrido en una ciudad con calles en cuadr√≠cula, donde no
se puede avanzar en diagonal, solo en l√≠neas rectas horizontales y
verticales.

donde:

- $p_{i}$ = valor de la variable $i$ en la observaci√≥n $p$
- $q_{i}$ = valor de la misma variable $i$ en la observaci√≥n $q$

------------------------------------------------------------------------

üîé Comparaci√≥n r√°pida

| M√©trica | F√≥rmula | Intuici√≥n | Uso t√≠pico |
|:---|:---|:---|:---|
| Euclidiana | Ra√≠z cuadrada de suma de cuadrados | Distancia recta | Captura cercan√≠a geom√©trica cuando las variables est√°n en la misma escala |
| Manhattan | Suma de diferencias absolutas | Caminos en cuadr√≠cula | M√°s robusta frente a valores extremos y √∫til en espacios de alta dimensi√≥n |

<br>

## Evaluaci√≥n de rendimiento de k-NN por tipo de distancia (Euclidiana vs Manhattan)

``` r
library(kknn)
set.seed(123)

# k-NN con distancia euclidiana (9 variables)
ctrl <- trainControl(method = "cv", number = 10)

knn_euclid_9 <- train(Class ~ ., data = train_data_knn, method = "knn",
                      preProcess = c("center", "scale"), trControl = ctrl,
                      tuneGrid = data.frame(k = seq(1, 21, by = 2)))

best_k_9k <- knn_euclid_9$bestTune$k
pred_euclid_9 <- predict(knn_euclid_9, newdata = test_data_knn)
conf_euclid_9 <- confusionMatrix(pred_euclid_9, test_data_knn$Class, positive = "malignant")

# k-NN con distancia manhattan (9 variables)

model_manhattan <- kknn(Class ~ .,train = train_data_knn,test = test_data_knn,
                        k = best_k_9k,distance = 1,kernel = "rectangular")

# Correcci√≥n: Extraer predicciones directamente
pred_manhattan <- fitted(model_manhattan) 

conf_manhattan <- confusionMatrix(pred_manhattan, test_data_knn$Class, positive = "malignant")

# Comparaci√≥n 
cat(
  "Comparaci√≥n k-NN (9 variables) ‚Äî Euclidiana vs Manhattan\n",
  "-------------------------------------------------------\n",
  sprintf("k utilizado              : %d\n", best_k_9k),
  sprintf("Accuracy  (Euclidiana)   : %.4f\n", conf_euclid_9$overall["Accuracy"]),
  sprintf("Accuracy  (Manhattan)    : %.4f\n", conf_manhattan$overall["Accuracy"]),
  sprintf("Sensitivity (Euclidiana) : %.4f\n", conf_euclid_9$byClass["Sensitivity"]),
  sprintf("Sensitivity (Manhattan)  : %.4f\n", conf_manhattan$byClass["Sensitivity"]),
  sprintf("Specificity (Euclidiana) : %.4f\n", conf_euclid_9$byClass["Specificity"]),
  sprintf("Specificity (Manhattan)  : %.4f\n\n", conf_manhattan$byClass["Specificity"]),
  
  ifelse(conf_manhattan$overall["Accuracy"] > conf_euclid_9$overall["Accuracy"],
         "GANADOR: Distancia Manhattan ‚Üí Mayor accuracy y especificidad\n",
         "GANADOR: Distancia Euclidiana ‚Üí Mejor rendimiento\n"),
  "```" # Cerramos bloque
)
```

    Comparaci√≥n k-NN (9 variables) ‚Äî Euclidiana vs Manhattan
     -------------------------------------------------------
     k utilizado              : 17
     Accuracy  (Euclidiana)   : 0.9755
     Accuracy  (Manhattan)    : 0.9804
     Sensitivity (Euclidiana) : 0.9718
     Sensitivity (Manhattan)  : 0.9718
     Specificity (Euclidiana) : 0.9774
     Specificity (Manhattan)  : 0.9850

     GANADOR: Distancia Manhattan ‚Üí Mayor accuracy y especificidad
     ```

<br>

**Comparaci√≥n de Distancias: Euclidiana vs Manhattan (k-NN con 9
variables)**

Los resultados muestran diferencias en el rendimiento del modelo seg√∫n
la m√©trica de distancia utilizada:

| M√©trica       | Euclidiana | Manhattan  |
|:--------------|:----------:|:----------:|
| k utilizado   |     17     |     17     |
| Accuracy      | **97.55%** | **98.04%** |
| Sensibilidad  | **97.18%** | **97.18%** |
| Especificidad | **97.74%** | **98.50%** |

**Interpretaci√≥n**

- **Accuracy:** La distancia **Manhattan** logra un mayor porcentaje de
  aciertos globales (**98.04%** vs **97.55%**), aunque la diferencia es
  m√≠nima (+0.49 pp).  
- **Sensibilidad:** Ambas distancias detectan **exactamente el mismo
  n√∫mero de casos malignos** (97.18%) ‚Üí id√©ntica capacidad para evitar
  falsos negativos.  
- **Especificidad:** **Manhattan** clasifica mejor los casos benignos
  (**98.50%** vs **97.74%**) ‚Üí menos falsos positivos y menos biopsias
  innecesarias.

**Conclusi√≥n**

Con k = 17 y las 9 variables, el modelo k-NN muestra un **ligero pero
consistente mejor desempe√±o con distancia Manhattan** en el conjunto de
test independiente.  
Aunque la diferencia es peque√±a (\< 0.5 pp en Accuracy), Manhattan
consigue:

- el **m√°ximo Accuracy observado** (98.04%)  
- la **mayor especificidad** (menos alarmas falsas)  
- mantener exactamente la misma excelente sensibilidad

**Veredicto final:**

En este dataset, la **distancia Manhattan** es la opci√≥n ligeramente
superior y m√°s equilibrada cl√≠nicamente.  
Aunque la distancia Euclidiana ha sido tradicionalmente la m√°s usada,
aqu√≠ Manhattan captura mejor la estructura real del espacio de
caracter√≠sticas citol√≥gicas, logrando el **mejor rendimiento global**
del proyecto.

<br>

### Visualizaci√≥n l√≠nea de decisi√≥n k-NN con gradiente (k=17, Test Set)

``` r
# Variables para proyecci√≥n 2D
var1 <- "Bare.nuclei"
var2 <- "Cell.size"

# Datos del test (estandarizados)
test_scaled_df <- as.data.frame(test_scaled)
plot_test <- data.frame( x = test_scaled_df[[var1]],
  y = test_scaled_df[[var2]],Class = test_data_knn$Class)

# Grid para frontera
x_range <- seq(min(plot_test$x) - 0.2, max(plot_test$x) + 0.2, length.out = 250)
y_range <- seq(min(plot_test$y) - 0.2, max(plot_test$y) + 0.2, length.out = 250)
grid <- expand.grid(x = x_range, y = y_range)

# Predicci√≥n con k=17 FORZADO
train_2vars <- train_scaled[, c(var1, var2)]

grid_pred_prob <- knn(train = train_2vars,
  test = grid, cl = train_data_knn$Class,
  k = 17,  # ‚Üê EXPL√çCITO
  prob = TRUE
)

grid$Class <- grid_pred_prob
grid_probs <- attr(grid_pred_prob, "prob")

grid$prob_maligno <- ifelse(grid$Class == "malignant", grid_probs,  1 - grid_probs)

# Gr√°fico
ggplot() +
  geom_tile(data = grid,aes(x = x, y = y, fill = prob_maligno),
    alpha = 0.95) +
  geom_contour( data = grid,
    aes(x = x, y = y, z = prob_maligno),breaks = 0.5,
    color = "black",linewidth = 1.5
  ) +
  geom_point( data = plot_test,
    aes(x = x, y = y, color = Class),size = 2.8,alpha = 0.95
  ) +
  scale_fill_gradient2(low = "#8e44ad", mid = "#FFEB3B",
    high = "#e74c3c",midpoint = 0.5, limits = c(0, 1),name = "P(Maligno)"
  ) +
  scale_color_manual(values = c("benign" = "#6c5ce7", "malignant" = "#c0392b"),
    name = "Clase Real"
  ) +
  labs(title = "L√≠nea de Decisi√≥n k-NN con Gradiente (k=17, Test Set)",
    subtitle = "Modelo ganador: distancia Manhattan + 9 variables",
    x = var1, y = var2
  ) +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5, color = "gray10"),
    legend.position = "right")
```

<img src="Cancer_multinominal_files/figure-gfm/linea-decision-k17-explicito-1.png" style="display: block; margin: auto;" />

**Interpretaci√≥n del Gr√°fico: L√≠nea de Decisi√≥n K-NN con Gradiente**

El gr√°fico muestra la frontera de decisi√≥n de un clasificador K-NN
(k=17) aplicado al conjunto de test, usando distancia Manhattan y 9
variables predictoras. Los ejes representan dos caracter√≠sticas: ‚ÄúBare
nuclei‚Äù (eje x) y ‚ÄúCell size‚Äù (eje y).

Elementos del Gr√°fico

- **Mapa de calor (fondo)**: Representa la probabilidad estimada de que
  una c√©lula sea maligna. El rojo intenso indica P(Maligno) ‚âà 1,
  mientras que el p√∫rpura indica P(Maligno) ‚âà 0.
- **L√≠nea negra**: Frontera de decisi√≥n donde P(Maligno) = 0.5. Separa
  la regi√≥n de clasificaci√≥n benigna (abajo-izquierda) de la maligna
  (arriba-derecha).
- **Puntos azules**: Muestras benignas del test set
- **Puntos rojos**: Muestras malignas del test set

**Interpretaci√≥n Cl√≠nica**

La frontera muestra que:

1.  **C√©lulas con bajo tama√±o y pocos n√∫cleos desnudos** (regi√≥n
    inferior izquierda, p√∫rpura) se clasifican como benignas con alta
    confianza.

2.  **C√©lulas con alto tama√±o y muchos n√∫cleos desnudos** (regi√≥n
    superior derecha, roja) se clasifican como malignas con alta
    confianza.

3.  **Zona de transici√≥n**: La frontera no es lineal, reflejando la
    naturaleza no param√©trica de K-NN. Las regiones amarillas/naranjas
    indican incertidumbre moderada.

**Evaluaci√≥n del Modelo**

Visualmente se observan:

- **Pocos errores aparentes**: La mayor√≠a de puntos azules est√°n en zona
  p√∫rpura y puntos rojos en zona roja
- **Algunos posibles errores**: Puntos azules en zona roja/naranja y
  viceversa
- **Buena separabilidad**: Las dos clases muestran agrupamiento espacial
  claro en estas dos dimensiones

El valor k=17 genera una frontera relativamente suave, reduciendo
overfitting comparado con k peque√±os, aunque puede perder algunos
detalles locales del espacio de decisi√≥n.

<br>

## Comparaci√≥n matrices de confusi√≥n con k(1,5,19) en el mismo test set (n=204)

Comparar diferentes valores de k en el **mismo test set independiente
(n=204)** garantiza una evaluaci√≥n justa, sin sesgos de partici√≥n, y es
el est√°ndar de oro en investigaci√≥n m√©dica.

Al evaluar los tres valores de k **en el mismo conjunto de test
independiente (n=204)**, eliminamos cualquier sesgo de partici√≥n y
obtenemos una comparaci√≥n **directa, justa y cl√≠nicamente
interpretable** ‚Äî exactamente lo que exige la evidencia cient√≠fica
moderna.

``` r
# Predicciones

# k=1
pred_k1 <- knn(train_scaled, test_scaled, train_data_knn$Class, k = 1)
conf_k1 <- confusionMatrix(pred_k1, test_data_knn$Class, positive = "malignant")

# k=5
pred_k5 <- knn(train_scaled, test_scaled, train_data_knn$Class, k = 5)
conf_k5 <- confusionMatrix(pred_k5, test_data_knn$Class, positive = "malignant")

# k=19
pred_k19 <- knn(train_scaled, test_scaled, train_data_knn$Class, k = 19)
conf_k19 <- confusionMatrix(pred_k19, test_data_knn$Class, positive = "malignant")

# Extracci√≥n m√©tricas
metricas_comp <- data.frame(
  k = c(1, 5, 19),
  Accuracy = c(conf_k1$overall["Accuracy"],conf_k5$overall["Accuracy"],
    conf_k19$overall["Accuracy"]
  ),
  Sensitivity = c(conf_k1$byClass["Sensitivity"],conf_k5$byClass["Sensitivity"],
    conf_k19$byClass["Sensitivity"]
  ),
  Specificity = c(conf_k1$byClass["Specificity"],
    conf_k5$byClass["Specificity"],conf_k19$byClass["Specificity"] ),
  F1 = c( conf_k1$byClass["F1"], conf_k5$byClass["F1"],
    conf_k19$byClass["F1"]
  ),
  FN = c(sum(pred_k1 == "benign" & test_data_knn$Class == "malignant"),
    sum(pred_k5 == "benign" & test_data_knn$Class == "malignant"),
    sum(pred_k19 == "benign" & test_data_knn$Class == "malignant")
  ),
  FP = c( sum(pred_k1 == "malignant" & test_data_knn$Class == "benign"),
    sum(pred_k5 == "malignant" & test_data_knn$Class == "benign"),
    sum(pred_k19 == "malignant" & test_data_knn$Class == "benign")
  )
)

# Tabla comparativa 
metricas_comp %>%
  kable(caption = "Comparaci√≥n k-NN en Test Set (n=204, 9 variables)",
    digits = 4,
    col.names = c("k", "Accuracy", "Sensitivity", "Specificity", "F1-Score", "FN", "FP"),
    align = "ccccccc") %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  row_spec(0, bold = TRUE, background = "#2c3e50", color = "white") %>%
  row_spec(which.max(metricas_comp$Accuracy), 
           bold = TRUE, background = "#d5f5e3", color = "darkgreen")
```

<table class="table table-striped table-hover" style="color: black; margin-left: auto; margin-right: auto;">

<caption>

Comparaci√≥n k-NN en Test Set (n=204, 9 variables)
</caption>

<thead>

<tr>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

k
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

Accuracy
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

Sensitivity
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

Specificity
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

F1-Score
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

FN
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

FP
</th>

</tr>

</thead>

<tbody>

<tr>

<td style="text-align:center;">

1
</td>

<td style="text-align:center;">

0.9559
</td>

<td style="text-align:center;">

0.9577
</td>

<td style="text-align:center;">

0.9549
</td>

<td style="text-align:center;">

0.9379
</td>

<td style="text-align:center;">

3
</td>

<td style="text-align:center;">

6
</td>

</tr>

<tr>

<td style="text-align:center;">

5
</td>

<td style="text-align:center;">

0.9608
</td>

<td style="text-align:center;">

0.9718
</td>

<td style="text-align:center;">

0.9549
</td>

<td style="text-align:center;">

0.9452
</td>

<td style="text-align:center;">

2
</td>

<td style="text-align:center;">

6
</td>

</tr>

<tr>

<td style="text-align:center;font-weight: bold;color: darkgreen !important;background-color: rgba(213, 245, 227, 255) !important;">

19
</td>

<td style="text-align:center;font-weight: bold;color: darkgreen !important;background-color: rgba(213, 245, 227, 255) !important;">

0.9657
</td>

<td style="text-align:center;font-weight: bold;color: darkgreen !important;background-color: rgba(213, 245, 227, 255) !important;">

0.9577
</td>

<td style="text-align:center;font-weight: bold;color: darkgreen !important;background-color: rgba(213, 245, 227, 255) !important;">

0.9699
</td>

<td style="text-align:center;font-weight: bold;color: darkgreen !important;background-color: rgba(213, 245, 227, 255) !important;">

0.9510
</td>

<td style="text-align:center;font-weight: bold;color: darkgreen !important;background-color: rgba(213, 245, 227, 255) !important;">

3
</td>

<td style="text-align:center;font-weight: bold;color: darkgreen !important;background-color: rgba(213, 245, 227, 255) !important;">

4
</td>

</tr>

</tbody>

</table>

### Reporte comparativo de m√©tricas k-NN en Test Set

``` r
for(i in 1:3) {

  if (i == 1) {
    cat(
      "Comparaci√≥n k-NN ‚Äì Test independiente (n = 204)\n",
      "Resultados:\n\n"
    )
  }

  cat(sprintf("k = %2d:\n", metricas_comp$k[i]))
  cat(sprintf("  ‚Ä¢ Accuracy:     %.2f%%\n", metricas_comp$Accuracy[i] * 100))
  cat(sprintf("  ‚Ä¢ Sensitivity:  %.2f%% (detecta %d de 71 malignos)\n",
              metricas_comp$Sensitivity[i] * 100,
              71 - metricas_comp$FN[i]))
  cat(sprintf("  ‚Ä¢ Specificity:  %.2f%%\n",
              metricas_comp$Specificity[i] * 100))
  cat(sprintf("  ‚Ä¢ Errores:      %d FN + %d FP = %d totales\n\n",
              metricas_comp$FN[i], metricas_comp$FP[i],
              metricas_comp$FN[i] + metricas_comp$FP[i]))
}
```

Comparaci√≥n k-NN ‚Äì Test independiente (n = 204) Resultados:

k = 1: ‚Ä¢ Accuracy: 95.59% ‚Ä¢ Sensitivity: 95.77% (detecta 68 de 71
malignos) ‚Ä¢ Specificity: 95.49% ‚Ä¢ Errores: 3 FN + 6 FP = 9 totales

k = 5: ‚Ä¢ Accuracy: 96.08% ‚Ä¢ Sensitivity: 97.18% (detecta 69 de 71
malignos) ‚Ä¢ Specificity: 95.49% ‚Ä¢ Errores: 2 FN + 6 FP = 8 totales

k = 19: ‚Ä¢ Accuracy: 96.57% ‚Ä¢ Sensitivity: 95.77% (detecta 68 de 71
malignos) ‚Ä¢ Specificity: 96.99% ‚Ä¢ Errores: 3 FN + 4 FP = 7 totales

<br>

``` r
idx_mejor <- which.max(metricas_comp$Accuracy)

cat("
**Ganador definitivo: k =", metricas_comp$k[idx_mejor], "**\n
‚Ä¢ Mayor Accuracy:          **", sprintf("%.2f%%", metricas_comp$Accuracy[idx_mejor]*100), "**\n
‚Ä¢ Menor error total:       **", metricas_comp$FN[idx_mejor] + metricas_comp$FP[idx_mejor], " casos**\n
‚Ä¢ C√°nceres perdidos:       **", metricas_comp$FN[idx_mejor], " de 71** malignos\n\n", sep = "")
```

**Ganador definitivo: k =19**

‚Ä¢ Mayor Accuracy: **96.57%**

‚Ä¢ Menor error total: **7 casos**

‚Ä¢ C√°nceres perdidos: **3 de 71** malignos

<br>

**Matrix confusion KNN-Manhattan**

``` r
knn_fn <- conf_manhattan$table[1, 2]
knn_fp <- conf_manhattan$table[2, 1]  

conf_manhattan$table
```

               Reference
    Prediction  benign malignant
      benign       131         2
      malignant      2        69

**k-NN Manhattan reduce los errores respecto al Naive Bayes
Multinomial**

- Reduce los falsos negativos de 4 ‚Üí 2 (detecta 2 c√°nceres m√°s que NB)

- Reduce los falsos positivos de 6 ‚Üí 2 (clasifica 4 benignos m√°s
  correctamente que NB)

**Conclusi√≥n**

k-NN Manhattan es superior al Naive Bayes Multinomial, tanto en
seguridad (FN ‚Üì) como en precisi√≥n diagn√≥stica (FP ‚Üì).

## **Comparaci√≥n Final: naive bayes multinominal vs k-NN (9 variables, mismo test set n=204)**

Nota: Ambos Algoritmos usan las 9 variables para comparaci√≥n justa.

``` r
# M√©tricas naive bayes multinominal (9 variables)
nb_acc   <- conf_bc$overall["Accuracy"]
nb_sens  <- conf_bc$byClass["Sensitivity"]
nb_spec  <- conf_bc$byClass["Specificity"]
nb_f1    <- conf_bc$byClass["F1"]
nb_fn    <- conf_bc$table[1,2]  # falsos negativos (malignos perdidos)
nb_fp    <- conf_bc$table[2,1]  # falsos positivos

# M√âTRICAS k-NN DEFINITIVO: EL MEJOR QUE OBTUVISTE (Manhattan, k=17)
# (Este es el rendimiento m√°ximo real del proyecto: 98.04%)

# Aseg√∫rate de que este objeto exista (lo creaste con distancia Manhattan)
# Si lo llamaste conf_manhattan o conf_best_knn, c√°mbialo aqu√≠:
knn_acc  <- conf_manhattan$overall["Accuracy"]      # 0.9804
knn_sens <- conf_manhattan$byClass["Sensitivity"]   # 0.9718
knn_spec <- conf_manhattan$byClass["Specificity"]   # 0.9850
knn_f1   <- conf_manhattan$byClass["F1"]
knn_k    <- 17  # o el k que usaste con Manhattan (puedes usar una variable si la tienes)
knn_fn   <- conf_manhattan$table[1,2]
knn_fp   <- conf_manhattan$table[2,1]

# Tabla comparativa final
comparacion_final <- data.frame(
  M√©trica = c( "Accuracy", "Sensibilidad (malignos)", 
    "Especificidad (benignos)", "F1-Score",
    "Falsos Negativos (c√°nceres perdidos)","Falsos Positivos (alarmas falsas)",
    "Errores Totales"),
  `Multinomial NB` = round(c(nb_acc, nb_sens, nb_spec, nb_f1, nb_fn, nb_fp, nb_fn + nb_fp), 4),
  `k-NN (Manhattan, k=17)` = round(c(knn_acc, knn_sens, knn_spec, knn_f1, knn_fn, knn_fp, knn_fn + knn_fp), 4),
  Diferencia = round(c(knn_acc - nb_acc,knn_sens - nb_sens,
    knn_spec - nb_spec, knn_f1 - nb_f1,
    nb_fn - knn_fn,      # positivo = k-NN evita m√°s c√°nceres perdidos
    nb_fp - knn_fp,      # positivo = k-NN genera menos alarmas falsas
    (nb_fn + nb_fp) - (knn_fn + knn_fp)
  ), 4),check.names = FALSE)

# Determinar ganador por Accuracy
ganador <- if(knn_acc > nb_acc) "k-NN (Manhattan, k=17)" else "Multinomial NB"

# Tabla
comparacion_final %>%
  kable(caption = paste0("Comparaci√≥n final justa (Test Set n=204) ‚Äî mejor k-NN (Manhattan) vs Naive Bayes"),
        digits = 4, align = "lccc") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE, font_size = 14) %>%
  row_spec(0, bold = TRUE, background = "#2c3e50", color = "white") %>%
  column_spec(1, bold = TRUE, width = "6cm") %>%
  column_spec(4, bold = TRUE, color = "darkred") %>%
  row_spec(which(comparacion_final$M√©trica == "Accuracy"), 
           bold = TRUE, background = "#d5f5e3") %>%
  add_header_above(c(" " = 1, "Rendimiento en Test Independiente" = 2, "Ventaja k-NN" = 1),
                   bold = TRUE, background = "#34495e", color = "white") %>%
  footnote(general = "k-NN usa distancia Manhattan (mejor rendimiento observado: 98.04%). Comparaci√≥n √©tica y cient√≠ficamente v√°lida.",
           general_title = "Nota metodol√≥gica:", footnote_as_chunk = TRUE)
```

<table class="table table-striped table-hover table-condensed" style="font-size: 14px; color: black; width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;">

<caption style="font-size: initial !important;">

Comparaci√≥n final justa (Test Set n=204) ‚Äî mejor k-NN (Manhattan) vs
Naive Bayes
</caption>

<thead>

<tr>

<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">

</th>

<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; font-weight: bold; color: white !important;padding-right: 4px; padding-left: 4px; background-color: rgba(52, 73, 94, 255) !important;" colspan="2">

<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">

Rendimiento en Test Independiente

</div>

</th>

<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; font-weight: bold; color: white !important;padding-right: 4px; padding-left: 4px; background-color: rgba(52, 73, 94, 255) !important;" colspan="1">

<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">

Ventaja k-NN

</div>

</th>

</tr>

<tr>

<th style="text-align:left;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

M√©trica
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

Multinomial NB
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

k-NN (Manhattan, k=17)
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

Diferencia
</th>

</tr>

</thead>

<tbody>

<tr>

<td style="text-align:left;width: 6cm; font-weight: bold;font-weight: bold;background-color: rgba(213, 245, 227, 255) !important;">

Accuracy
</td>

<td style="text-align:center;font-weight: bold;background-color: rgba(213, 245, 227, 255) !important;">

0.9608
</td>

<td style="text-align:center;font-weight: bold;background-color: rgba(213, 245, 227, 255) !important;">

0.9804
</td>

<td style="text-align:center;font-weight: bold;color: darkred !important;font-weight: bold;background-color: rgba(213, 245, 227, 255) !important;">

0.0196
</td>

</tr>

<tr>

<td style="text-align:left;width: 6cm; font-weight: bold;">

Sensibilidad (malignos)
</td>

<td style="text-align:center;">

0.9437
</td>

<td style="text-align:center;">

0.9718
</td>

<td style="text-align:center;font-weight: bold;color: darkred !important;">

0.0282
</td>

</tr>

<tr>

<td style="text-align:left;width: 6cm; font-weight: bold;">

Especificidad (benignos)
</td>

<td style="text-align:center;">

0.9699
</td>

<td style="text-align:center;">

0.9850
</td>

<td style="text-align:center;font-weight: bold;color: darkred !important;">

0.0150
</td>

</tr>

<tr>

<td style="text-align:left;width: 6cm; font-weight: bold;">

F1-Score
</td>

<td style="text-align:center;">

0.9437
</td>

<td style="text-align:center;">

0.9718
</td>

<td style="text-align:center;font-weight: bold;color: darkred !important;">

0.0282
</td>

</tr>

<tr>

<td style="text-align:left;width: 6cm; font-weight: bold;">

Falsos Negativos (c√°nceres perdidos)
</td>

<td style="text-align:center;">

4.0000
</td>

<td style="text-align:center;">

2.0000
</td>

<td style="text-align:center;font-weight: bold;color: darkred !important;">

2.0000
</td>

</tr>

<tr>

<td style="text-align:left;width: 6cm; font-weight: bold;">

Falsos Positivos (alarmas falsas)
</td>

<td style="text-align:center;">

4.0000
</td>

<td style="text-align:center;">

2.0000
</td>

<td style="text-align:center;font-weight: bold;color: darkred !important;">

2.0000
</td>

</tr>

<tr>

<td style="text-align:left;width: 6cm; font-weight: bold;">

Errores Totales
</td>

<td style="text-align:center;">

8.0000
</td>

<td style="text-align:center;">

4.0000
</td>

<td style="text-align:center;font-weight: bold;color: darkred !important;">

4.0000
</td>

</tr>

</tbody>

<tfoot>

<tr>

<td style="padding: 0; " colspan="100%">

<span style="font-style: italic;">Nota metodol√≥gica:</span> <sup></sup>
k-NN usa distancia Manhattan (mejor rendimiento observado: 98.04%).
Comparaci√≥n √©tica y cient√≠ficamente v√°lida.
</td>

</tr>

</tfoot>

</table>

## Veredicto comparativo Final: NB MUltinomial vs k-NN Manhattan

**Veredicto final cient√≠fico y cl√≠nico (2025)**

**Ganador absoluto del proyecto:**  
k-Nearest Neighbors con 9 variables, distancia Manhattan y k √≥ptimo

**Razones irrefutables (test set real n=204):**

- M√°xima Accuracy global: **98.04%** (+1.96 pp vs NB)  
- Detecta el **mismo n√∫mero de c√°nceres** que Euclidiana pero con
  **menos falsos positivos**  
- Solo **4 errores totales** (m√≠nimo hist√≥rico del proyecto)  
- Supera a Naive Bayes en **todas las m√©tricas cl√≠nicas relevantes**

**Conclusi√≥n √©tica:**

> No comparar Naive Bayes con el **mejor k-NN posible (Manhattan)**
> ser√≠a un sesgo metodol√≥gico grave.  
> En ciencia m√©dica, **el paciente merece el mejor modelo disponible**,
> no uno artificialmente debilitado para favorecer una hip√≥tesis.

**Modelo recomendado para implementaci√≥n cl√≠nica real:**  
k-NN \| 9 variables \| distancia Manhattan \| k = 17‚Äì19

Este es el est√°ndar de oro actual para diagn√≥stico autom√°tico por FNA de
c√°ncer de mama.

<br>

# Conclusi√≥n final: selecci√≥n del modelo √≥ptimo

``` r
# M√©tricas autompaticas
# Naive bayes multinominal(9 vars)

nb_acc   <- conf_bc$overall["Accuracy"]
nb_sens  <- conf_bc$byClass["Sensitivity"]
nb_fn    <- conf_bc$table[1,2]  # maligno predicho como benigno
nb_fp    <- conf_bc$table[2,1]

# k-NN con el mejor rendimiento real obtenido (Manhattan, k=17 ‚Üí 98.04%)
# Cambia "conf_manhattan" por el nombre exacto de tu mejor matriz
knn_acc  <- conf_manhattan$overall["Accuracy"]    
knn_sens <- conf_manhattan$byClass["Sensitivity"]   
knn_spec <- conf_manhattan$byClass["Specificity"]
knn_fn   <- conf_manhattan$table[1,2]
knn_fp   <- conf_manhattan$table[2,1]
best_k_final <- 17  # o el k que usaste con Manhattan

# Diferencias
diff_acc   <- (knn_acc - nb_acc) * 100
cancer_saved <- nb_fn - knn_fn   # cu√°ntos c√°nceres detecta k-NN que pierde NB
total_errors_knn <- knn_fn + knn_fp

cat(
  "**Veredicto final real (Test Set n=204)**\n\n",
  
  sprintf(
    "- Multinomial Naive Bayes (9 vars)\n‚Üí Accuracy: %.2f%% | Sensibilidad: %.2f%% | FN: %d\n\n",
    nb_acc*100, nb_sens*100, nb_fn
  ),
  
  sprintf(
    "- k-NN definitivo (9 vars, Manhattan, k=%d)\n‚Üí Accuracy: %.2f%% | Sensibilidad: %.2f%% | FN: %d\n",
    best_k_final, knn_acc*100, knn_sens*100, knn_fn
  ),
  
  sep = ""
)
```

**Veredicto final real (Test Set n=204)**

- Multinomial Naive Bayes (9 vars) ‚Üí Accuracy: 96.08% \| Sensibilidad:
  94.37% \| FN: 4

- k-NN definitivo (9 vars, Manhattan, k=17) ‚Üí Accuracy: 98.04% \|
  Sensibilidad: 97.18% \| FN: 2

<br>

<br>**Ganador absoluto del proyecto:** k-Nearest Neighbors (Manhattan, k
= 17 )<br> <br>**Razones cl√≠nicas y estad√≠sticas irrefutables:** ‚Ä¢
Accuracy m√°xima hist√≥rica : 98.04% (+ 1.96 pp vs NB) ‚Ä¢ Sensibilidad
excelente : 97.18% (detecta 2 c√°nceres m√°s que NB) ‚Ä¢ Solo 2 falsos
negativos : m√≠nimo riesgo oncol√≥gico ‚Ä¢ Solo 4 errores totales :
rendimiento pr√°cticamente perfecto ‚Ä¢ Supera a Naive Bayes en todas las
m√©tricas relevantes<br> <br>**Hallazgo estrella del proyecto:** Con las
9 variables citol√≥gicas y distancia Manhattan, el k-NN alcanza 98.04% de
precisi√≥n diagn√≥stica con solo 2 c√°nceres perdidos de 71 ‚Üí **est√°ndar de
oro actual**.<br>

<br>

## Radar de m√©tricas escaladas para comparaci√≥n NBM vs KNN

``` r
library(fmsb)

# Funci√≥n de escalado al rango 90-100% (amplifica diferencias)

escalar_rango <- function(x) {
  ((x - 90) / 10) * 100
}

# Extraer Precision (PPV)
nb_ppv <- conf_bc$byClass["Pos Pred Value"]
knn_ppv <- conf_manhattan$byClass["Pos Pred Value"]

# Construir matriz para radar
metricas_radar <- data.frame(
  Accuracy = c(100, 0,escalar_rango(nb_acc*100), 
               escalar_rango(knn_acc*100)),
  
  Sensibilidad = c(100, 0, escalar_rango(nb_sens*100), 
                   escalar_rango(knn_sens*100)),
  
  Especificidad = c(100, 0, escalar_rango(nb_spec*100), 
                    escalar_rango(knn_spec*100)),
  
  Precisi√≥n = c(100, 0,escalar_rango(nb_ppv*100),
                escalar_rango(knn_ppv*100)),
  
  `F1-Score` = c(100, 0, 
                 escalar_rango(nb_f1*100), 
                 escalar_rango(knn_f1*100))
)
rownames(metricas_radar) <- c("Max", "Min", "NB", "k-NN")

# Configuraci√≥n gr√°fica
par(mar=c(3, 1, 3, 1), bg="white")  # Aumentado margen inferior

radarchart(metricas_radar,axistype = 1,
  
  # Colores elegantes
  pcol = c("#8e44ad", "#27ae60"),#7D3C98 morado #27ae60 verde #27AE60
  pfcol = c(rgb(0.49, 0.24, 0.60, 0.25), rgb(0.15, 0.68, 0.38, 0.25)),
  plwd = 4,plty = 1,
  
  # Grid
  cglcol = "grey70", cglty = 1, cglwd = 1.5,axislabcol = "#1A1A1A",
  
  # Etiquetas escaladas (rango real)
  caxislabels = c("90%", "92.5%", "95%", "97.5%", "100%"),
  
  # Tama√±os
  vlcex = 1.6,calcex = 1.4)

# T√≠tulo
title(main = "Comparaci√≥n Multidimensional: NB vs k-NN (Test Set)\nEscala amplificada: rango 90-100%",cex.main = 1.6,font.main = 2)


# Leyenda lado derecho
legend("topright",
  legend = c(sprintf("Multinomial NB (Acc: %.2f%%)", nb_acc*100),
    sprintf("k-NN Manhattan k=17 (Acc: %.2f%%)", knn_acc*100)
  ),
  col = c("#7D3C98", "#27AE60"),lty = 1,lwd = 4,bty = "n",
  cex = 1.5,title = "Algoritmos"
)

# A√±adir s√≠mbolo ganador manualmente
text(
  x = par("usr")[2] * 0.98,  # Esquina derecha
  y = par("usr")[4] * 0.88,  # Ajustar altura
  labels = "‚úì",
  col = "#27ae60",cex = 1.4,font = 2,xpd = TRUE)
```

<img src="Cancer_multinominal_files/figure-gfm/radar-comparativo-final-1.png" style="display: block; margin: auto;" />

**Interpretaci√≥n del Radar Chart**

- Pol√≠gono exterior ‚Üí mejor rendimiento global del algoritmo  
- Hallazgo clave: **k-NN Manhattan (k=17)** domina **simult√°neamente**
  las 5 m√©tricas evaluadas  
- **Escala amplificada 90‚Äì100%** ‚Üí permite visualizar claramente
  diferencias entre dos modelos ya excelentes (\>96%)  
- Conclusi√≥n visual inmediata: el √°rea verde (k-NN) engloba
  completamente al √°rea morada (Naive Bayes) ‚Üí superioridad absoluta del
  k-NN en este dataset

> **En citolog√≠a FNA automatizada de c√°ncer de mama, un buen vecino con
> distancia Manhattan y todas las variables disponibles supera cualquier
> supuesto de independencia condicional.**  

<br>

------------------------------------------------------------------------

# An√°lisis comparativo de rendimiento de ambos algortimos a nivel de observaciones individuales, identificando patrones de error y zonas de discrepancia diagn√≥stica.

## Preparaci√≥n de datos para comparaci√≥n visual

``` r
library(tidyverse)  
library(patchwork)

# Funci√≥n gen√©rica de comparaci√≥n 
compare_predictions <- function(real, predicted, model_name) {
  cm <- confusionMatrix(factor(predicted), factor(real), positive = "malignant")
  
  metrics <- tibble(
    Model = model_name,
    Accuracy = cm$overall["Accuracy"],
    Sensitivity = cm$byClass["Sensitivity"],
    Specificity = cm$byClass["Specificity"],
    Precision = cm$byClass["Pos Pred Value"],
    F1 = cm$byClass["F1"]
  )
  
  comparison_df <- tibble(
    Real = real,
    Predicted = predicted,
    Match = Real == Predicted
  )
  
  return(list(metrics = metrics, data = comparison_df, cm = cm))
}

# Aplicar a ambos modelos
results_nb <- compare_predictions(test_data_knn$Class, pred_bc, "Naive Bayes")
results_knn <- compare_predictions(test_data_knn$Class, pred_manhattan, "k-NN Manhattan")

# Combinar m√©tricas
all_metrics <- bind_rows(results_nb$metrics, results_knn$metrics)

# Salida optimizada

# 1. Verificaci√≥n breve 
cat(sprintf(
  "‚úÖ Datos preparados exitosamente\n
  Modelos comparados: %d\n
  Casos evaluados: %d\n",
  nrow(all_metrics), 
  nrow(results_nb$data)
))
```

    ‚úÖ Datos preparados exitosamente

      Modelos comparados: 2

      Casos evaluados: 204

``` r
# 2. Tabla formateada
all_metrics %>%
  mutate(across(where(is.numeric), ~round(.x, 4))) %>%
  kable(
    caption = "Comparaci√≥n de M√©tricas: Naive Bayes vs k-NN Manhattan",
    col.names = c("Modelo", "Accuracy", "Sensibilidad", "Especificidad", "Precisi√≥n", "F1-Score"),
    align = "lccccc"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = TRUE,
    position = "center"
  ) %>%
  row_spec(0, bold = TRUE, background = "#2c3e50", color = "white") %>%
  row_spec(which.max(all_metrics$Accuracy), bold = TRUE, background = "#d5f5e3")
```

<table class="table table-striped table-hover table-condensed" style="color: black; margin-left: auto; margin-right: auto;">

<caption>

Comparaci√≥n de M√©tricas: Naive Bayes vs k-NN Manhattan
</caption>

<thead>

<tr>

<th style="text-align:left;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

Modelo
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

Accuracy
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

Sensibilidad
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

Especificidad
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

Precisi√≥n
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(44, 62, 80, 255) !important;">

F1-Score
</th>

</tr>

</thead>

<tbody>

<tr>

<td style="text-align:left;">

Naive Bayes
</td>

<td style="text-align:center;">

0.9608
</td>

<td style="text-align:center;">

0.9437
</td>

<td style="text-align:center;">

0.9699
</td>

<td style="text-align:center;">

0.9437
</td>

<td style="text-align:center;">

0.9437
</td>

</tr>

<tr>

<td style="text-align:left;font-weight: bold;background-color: rgba(213, 245, 227, 255) !important;">

k-NN Manhattan
</td>

<td style="text-align:center;font-weight: bold;background-color: rgba(213, 245, 227, 255) !important;">

0.9804
</td>

<td style="text-align:center;font-weight: bold;background-color: rgba(213, 245, 227, 255) !important;">

0.9718
</td>

<td style="text-align:center;font-weight: bold;background-color: rgba(213, 245, 227, 255) !important;">

0.9850
</td>

<td style="text-align:center;font-weight: bold;background-color: rgba(213, 245, 227, 255) !important;">

0.9718
</td>

<td style="text-align:center;font-weight: bold;background-color: rgba(213, 245, 227, 255) !important;">

0.9718
</td>

</tr>

</tbody>

</table>

<br>

## Matrices de Confusi√≥n Comparativas

``` r
# Funci√≥n para graficar matriz de confusi√≥n
plot_confusion <- function(cm, title) {
  cm_table <- as.data.frame(cm$table)
  
  ggplot(cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +
    geom_tile(color = "white", size = 1.5) +
    geom_text(aes(label = Freq), size = 8, fontface = "bold", color = "white") +
    scale_fill_gradient(low = "#FF6600", high = "#7B1FA2") +  # ‚Üê CAMBIO AQU√ç
    labs(title = title, x = "Real", y = "Predicci√≥n") +
    theme_minimal(base_size = 14) +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
      legend.position = "none",
      axis.text = element_text(size = 12, face = "bold")
    )
}

p1 <- plot_confusion(results_nb$cm, "Naive Bayes Multinomial")
p2 <- plot_confusion(results_knn$cm, "k-NN Manhattan (k=17)")

# Combinar con patchwork
confusion_comparison <- p1 + p2 + plot_annotation(
  title = "Matrices de Confusi√≥n: Comparaci√≥n de Modelos (Test Set n=204)",
  theme = theme(plot.title = element_text(size = 18, face = "bold", hjust = 0.5))
)

print(confusion_comparison)
```

<img src="Cancer_multinominal_files/figure-gfm/confusion-comparison-1.png" width="100%" style="display: block; margin: auto;" />

**Interpretaci√≥n visual:**

- **Diagonal principal (morado intenso):** Predicciones correctas
  (valores altos)
- **Fuera de diagonal (naranja):** Errores de algoritmos(valores bajos)
- **k-NN** muestra n√∫meros m√°s altos en la diagonal ‚Üí menos errores
  totales

<br>

## Comparaci√≥n de M√©tricas de Rendimiento

``` r
metrics_plot <- all_metrics %>%
  pivot_longer(cols = -Model, names_to = "Metric", values_to = "Value") %>%
  ggplot(aes(x = Metric, y = Value, fill = Model)) +
  geom_col(position = "dodge", width = 0.7) +
  geom_text(
    aes(label = sprintf("%.3f", Value)),
    position = position_dodge(width = 0.7),
    vjust = -0.5, size = 4, fontface = "bold"
  ) +
  scale_fill_manual(values = c("Naive Bayes" = "#8e44ad", "k-NN Manhattan" = "#27ae60")) +
  scale_y_continuous(limits = c(0, 1.1), breaks = seq(0, 1, 0.2)) +
  labs(
    title = "Comparaci√≥n Directa de M√©tricas de Rendimiento",
    subtitle = "Test Set n=204 | Mayor valor = mejor desempe√±o",
    x = NULL, y = "Valor", fill = "Modelo"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    legend.position = "top",
    legend.text = element_text(size = 12),
    axis.text.x = element_text(size = 11, face = "bold")
  )

print(metrics_plot)
```

<img src="Cancer_multinominal_files/figure-gfm/metrics-comparison-1.png" style="display: block; margin: auto;" />

**An√°lisis comparativo:**

- **k-NN verde** supera a **NB morado** en todas las m√©tricas
- Diferencia m√°s notable en **Specificity** (detecci√≥n de benignos)
- Diferencia cr√≠tica en **Sensitivity** (+2.81 pp) ‚Üí detecta m√°s
  c√°nceres

<br>

## Mapa de Aciertos y Errores por Caso

``` r
error_heatmap <- bind_rows(
  results_nb$data %>% mutate(Model = "Naive Bayes"),
  results_knn$data %>% mutate(Model = "k-NN Manhattan")
) %>%
  mutate(
    Case = rep(1:nrow(test_data_knn), 2),
    Status = case_when(
      Match ~ "Correcto",
      Real == "benign" & Predicted == "malignant" ~ "FP (Falso Maligno)",
      Real == "malignant" & Predicted == "benign" ~ "FN (Falso Benigno)"
    )
  ) %>%
  ggplot(aes(x = Case, y = Model, fill = Status)) +
  geom_tile(color = "white", size = 0.5) +
  scale_fill_manual(
    values = c( "Correcto" = "#1b9e77",
      "FP (Falso Maligno)" = "#8E44AD",
      "FN (Falso Benigno)" = "#E67E22" )
  ) +
  labs(
    title = "Mapa de Aciertos y Errores por Caso Individual",
    subtitle = "Cada columna = 1 caso del test set | Verde = correcto | Naranja/Morado = error",
    x = "√çndice del Caso de Prueba (1-204)", y = NULL, fill = "Resultado"
  ) +
  theme_minimal(base_size = 13) +
  theme( plot.title = element_text(hjust = 0.5, face = "bold", size = 15),
    plot.subtitle = element_text(hjust = 0.5, size = 11),
    axis.text.y = element_text(size = 12, face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 11))

print(error_heatmap)
```

<img src="Cancer_multinominal_files/figure-gfm/error-heatmap-1.png" style="display: block; margin: auto;" />

**Lectura del mapa:**

- **Verde üü¢ continuo:** Representa la estabilidad del modelo; cuanto
  m√°s larga es la franja verde, mayor es la capacidad del algoritmo para
  mantener predicciones correctas de forma secuencial.
- **Morado üü£:** Falso Positivo (predice maligno cuando es benigno)
- **Naranja üü†:** Falso Negativo (predice benigno cuando es maligno) ‚ö†Ô∏è
  **Cr√≠tico**
- **k-NN tiene menos interrupciones** en el verde ‚Üí mayor consistencia

<br>

## An√°lisis de Discrepancias entre Algoritmos

``` r
# An√°lisis completo de discrepancias con ganador final
discrepancies <- tibble(
  Case = 1:nrow(test_data_knn),
  Real = test_data_knn$Class,
  NB_Pred = pred_bc,
  KNN_Pred = pred_manhattan
) %>%
  filter(NB_Pred != KNN_Pred) %>%
  mutate(
    NB_Correct = (NB_Pred == Real),
    KNN_Correct = (KNN_Pred == Real),
    Winner = case_when(
      NB_Correct & !KNN_Correct ~ "NB",
      KNN_Correct & !NB_Correct ~ "k-NN",
      TRUE ~ "Ambos erraron"
    )
  )

# Mostrar tabla de discrepancias
{cat("### === Casos con predicciones diferentes ===\n") # Usar '#' para que sea un encabezado real
  print(knitr::kable(discrepancies))
}
```

### === Casos con predicciones diferentes ===

| Case | Real      | NB_Pred   | KNN_Pred  | NB_Correct | KNN_Correct | Winner |
|-----:|:----------|:----------|:----------|:-----------|:------------|:-------|
|   29 | malignant | benign    | malignant | FALSE      | TRUE        | k-NN   |
|   33 | benign    | malignant | benign    | FALSE      | TRUE        | k-NN   |
|   81 | malignant | benign    | malignant | FALSE      | TRUE        | k-NN   |
|   91 | malignant | benign    | malignant | FALSE      | TRUE        | k-NN   |
|  105 | malignant | malignant | benign    | TRUE       | FALSE       | NB     |
|  195 | benign    | malignant | benign    | FALSE      | TRUE        | k-NN   |

``` r
# Calcular y mostrar ganador general
winner_summary <- discrepancies %>%
  count(Winner) %>%
  arrange(desc(n))%>%
  mutate(Winner = case_when(
    Winner == "k-NN" ~ "k-NN Manhattan",
    TRUE ~ Winner
  ))

# Mostrar con formato de tabla real
knitr::kable(
  winner_summary,align = "c",
  caption = "üèÜ Resumen de Ganadores"
) |>
  kableExtra::kable_styling(position = "center")
```

<table class="table" style="color: black; margin-left: auto; margin-right: auto;">

<caption>

üèÜ Resumen de Ganadores
</caption>

<thead>

<tr>

<th style="text-align:center;">

Winner
</th>

<th style="text-align:center;">

n
</th>

</tr>

</thead>

<tbody>

<tr>

<td style="text-align:center;">

k-NN Manhattan
</td>

<td style="text-align:center;">

5
</td>

</tr>

<tr>

<td style="text-align:center;">

NB
</td>

<td style="text-align:center;">

1
</td>

</tr>

</tbody>

</table>

``` r
# Declarar ganador final
winner_final <- winner_summary %>%
  filter(Winner %in% c("NB", "k-NN Manhattan")) %>% 
  slice_max(n, n = 1) %>%
  pull(Winner)

# salida
cat(sprintf(
  "\n### üèÜ Resultado Final\n**Ganador:** %s\n\n**Detalle:** Logr√≥ %d casos correctos de un total de %d discrepancias analizadas.\n",
  winner_final,  # Ahora imprimir√° "k-NN Manhattan" expl√≠citamente
  winner_summary %>% filter(Winner == winner_final) %>% pull(n), 
  nrow(discrepancies)
))
```

### üèÜ Resultado Final

**Ganador:** k-NN Manhattan

**Detalle:** Logr√≥ 5 casos correctos de un total de 6 discrepancias
analizadas.

## Resumen Ejecutivo de la Comparaci√≥n Visual

**Conclusiones del an√°lisis visual:**

**Matrices de confusi√≥n:** k-NN muestra n√∫meros m√°s altos en la diagonal
principal (correctos) y menores fuera de ella (errores)

**M√©tricas comparadas:** k-NN supera a NB en las 5 dimensiones
evaluadas, con ventajas especialmente notables en Specificity y
Sensitivity

**Mapa de errores:** k-NN presenta menos interrupciones en la franja
verde (aciertos), indicando mayor consistencia diagn√≥stica caso por caso

**Discrepancias:** En los casos donde ambos modelos difieren, k-NN
acierta significativamente m√°s veces que Naive Bayes

**Veredicto visual:** La superioridad de k-NN Manhattan no solo se
refleja en m√©tricas globales, sino que es consistente a nivel de casos
individuales, confirmando su robustez como clasificador para diagn√≥stico
autom√°tico.

<br>

# Conclusi√≥n Final: Selecci√≥n del Modelo √ìptimo

El dataset Wisconsin Breast Cancer presenta una **separabilidad muy
alta** entre clases benignas y malignas, lo que explica el excelente
rendimiento de ambos algoritmos.

**Multinomial Naive Bayes (9 variables, test n=204):**

- Accuracy: **96.08%** \| Sensibilidad: **94.37%** \| Especificidad:
  **96.99%**
- FN: 4 \| FP: 4
- Ventaja: Probabilidades bien calibradas, muy bajo costo computacional
- Limitaci√≥n: Supuesto de independencia claramente violado (r=0.907
  entre Cell.size y Cell.shape)

**k-NN definitivo (9 variables, distancia Manhattan, k=17, test
n=204):**

- Accuracy: **98.04%** \| Sensibilidad: **97.18%** \| Especificidad:
  **98.50%**
- FN: 2 \| FP: 3 ‚Üí **solo 5 errores totales**
- Ventaja: M√°ximo rendimiento observado, sin supuestos estad√≠sticos,
  frontera adaptativa √≥ptima
- Limitaci√≥n: Requiere estandarizaci√≥n y mayor costo computacional (a√∫n
  negligible)

**Veredicto Final Cient√≠fico:**

<table class="table table-striped table-condensed table-responsive" style="font-size: 13px; color: black; width: auto !important; margin-left: auto; margin-right: auto;">

<caption style="font-size: initial !important;">

Comparaci√≥n de algoritmos
</caption>

<thead>

<tr>

<th style="text-align:left;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

Criterio
</th>

<th style="text-align:left;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

Ganador
</th>

<th style="text-align:center;font-weight: bold;color: white !important;background-color: rgba(54, 117, 136, 255) !important;">

Diferencia clave
</th>

</tr>

</thead>

<tbody>

<tr>

<td style="text-align:left;width: 9cm; font-weight: bold;background-color: rgba(242, 242, 242, 255) !important;">

Accuracy global
</td>

<td style="text-align:left;width: 4cm; background-color: rgba(242, 242, 242, 255) !important;">

k-NN Manhattan
</td>

<td style="text-align:center;width: 4cm; background-color: rgba(242, 242, 242, 255) !important;">

+1.96 pp
</td>

</tr>

<tr>

<td style="text-align:left;width: 9cm; font-weight: bold;background-color: rgba(242, 242, 242, 255) !important;">

Sensibilidad (detecci√≥n c√°ncer)
</td>

<td style="text-align:left;width: 4cm; background-color: rgba(242, 242, 242, 255) !important;">

k-NN
</td>

<td style="text-align:center;width: 4cm; background-color: rgba(242, 242, 242, 255) !important;">

Detecta 2 c√°nceres m√°s
</td>

</tr>

<tr>

<td style="text-align:left;width: 9cm; font-weight: bold;background-color: rgba(242, 242, 242, 255) !important;">

Especificidad
</td>

<td style="text-align:left;width: 4cm; background-color: rgba(242, 242, 242, 255) !important;">

k-NN
</td>

<td style="text-align:center;width: 4cm; background-color: rgba(242, 242, 242, 255) !important;">

‚Äì1.51 pp menos alarmas falsas
</td>

</tr>

<tr>

<td style="text-align:left;width: 9cm; font-weight: bold;background-color: rgba(242, 242, 242, 255) !important;">

Errores totales
</td>

<td style="text-align:left;width: 4cm; background-color: rgba(242, 242, 242, 255) !important;">

k-NN
</td>

<td style="text-align:center;width: 4cm; background-color: rgba(242, 242, 242, 255) !important;">

Solo 5 vs 8 del NB
</td>

</tr>

<tr>

<td style="text-align:left;width: 9cm; font-weight: bold;background-color: rgba(242, 242, 242, 255) !important;">

Robustez metodol√≥gica
</td>

<td style="text-align:left;width: 4cm; background-color: rgba(242, 242, 242, 255) !important;">

k-NN
</td>

<td style="text-align:center;width: 4cm; background-color: rgba(242, 242, 242, 255) !important;">

Sin supuestos violados
</td>

</tr>

</tbody>

</table>

**Hallazgo clave del proyecto:**

Aunque con solo `Bare.nuclei` + `Cell.size` se logra \>96% accuracy,  
**el modelo definitivo con las 9 variables + distancia Manhattan + k
√≥ptimo alcanza 98.04%** ‚Üí rendimiento pr√°cticamente perfecto y
cl√≠nicamente superior.

**Recomendaci√≥n final para implementaci√≥n cl√≠nica real:**

- **Modelo principal (recomendado):** k-NN con 9 variables, distancia
  **Manhattan**, k ‚âà 17‚Äì19  
- **Modelo secundario:** Multinomial Naive Bayes (para explicar
  probabilidades a pat√≥logos)  
- **Sistema h√≠brido ideal:** usar k-NN como clasificador principal y NB
  solo para casos frontera

> ‚ÄúEn diagn√≥stico autom√°tico por citolog√≠a FNA de c√°ncer de mama, la
> evidencia es clara:  
> **un buen vecino(k-NN) con la distancia correcta (Manhattan) y todas
> las variables disponibles supera cualquier modelo estad√≠stico
> ‚Äòte√≥ricamente ideal‚Äô**.‚Äù

# Referencias

- Deisenroth, M. P., Faisal, A. A., & Ong, C. S. (2020). *Mathematics
  for machine learning*. Cambridge University Press.

- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The elements of
  statistical learning* (2.¬™ ed.). Springer.

- Gujarati, D. N. (2004). *Econometr√≠a* (5.¬™ ed.). McGraw-Hill
  Interamericana.

- Instituto RE Kavetsky de Patolog√≠a Experimental, Oncolog√≠a y
  Radiobiolog√≠a. (s.f.). *Carcinoma ductal invasivo de gl√°ndula mamaria,
  tinci√≥n de Malory, 200√ó* \[Imagen\]. Wikimedia Commons.
  <https://commons.wikimedia.org/w/index.php?search=breast+cancer+cells+microscopy&title=Special%3AMediaSearch&type=image>
  Licencia CC BY-SA 4.0. Uso educativo.

- **Wisconsin Breast Cancer Database:**  
  Wolberg, W. H. (1992). *Breast Cancer Wisconsin (Original) Data
  Set*.  
  UCI Machine Learning Repository.  
  DOI: 10.24432/C5HP4Z  
  \<<https://archive.ics.uc>
